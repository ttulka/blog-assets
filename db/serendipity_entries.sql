-- phpMyAdmin SQL Dump
-- version 3.4.10
-- http://www.phpmyadmin.net
--
-- Host: localhost:3306
-- Erstellungszeit: 06. Jan 2019 um 18:59
-- Server Version: 5.5.57
-- PHP-Version: 5.4.45-0+deb7u11

SET SQL_MODE="NO_AUTO_VALUE_ON_ZERO";
SET time_zone = "+00:00";


/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
/*!40101 SET NAMES utf8 */;

--
-- Datenbank: `net21blog`
--

-- --------------------------------------------------------

--
-- Tabellenstruktur für Tabelle `serendipity_entries`
--

CREATE TABLE IF NOT EXISTS `serendipity_entries` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `title` varchar(200) DEFAULT NULL,
  `timestamp` int(10) unsigned DEFAULT NULL,
  `body` longtext,
  `comments` int(4) unsigned DEFAULT '0',
  `trackbacks` int(4) unsigned DEFAULT '0',
  `extended` longtext,
  `exflag` int(1) DEFAULT NULL,
  `author` varchar(20) DEFAULT NULL,
  `authorid` int(11) DEFAULT NULL,
  `isdraft` enum('true','false') NOT NULL DEFAULT 'true',
  `allow_comments` enum('true','false') NOT NULL DEFAULT 'true',
  `last_modified` int(10) unsigned DEFAULT NULL,
  `moderate_comments` enum('true','false') NOT NULL DEFAULT 'true',
  PRIMARY KEY (`id`),
  KEY `date_idx` (`timestamp`),
  KEY `mod_idx` (`last_modified`),
  KEY `edraft_idx` (`isdraft`),
  KEY `eauthor_idx` (`authorid`),
  FULLTEXT KEY `entry_idx` (`title`,`body`,`extended`)
) ENGINE=MyISAM  DEFAULT CHARSET=utf8 AUTO_INCREMENT=123 ;

--
-- Daten für Tabelle `serendipity_entries`
--

INSERT INTO `serendipity_entries` (`id`, `title`, `timestamp`, `body`, `comments`, `trackbacks`, `extended`, `exflag`, `author`, `authorid`, `isdraft`, `allow_comments`, `last_modified`, `moderate_comments`) VALUES
(2, 'ActiveMQ + JAAS Custom Login Module', 1393000200, '<p>It is pretty easy to find how to run built-in JAAS plugin (<code>jaasAuthenticationPlugin</code>), but what shall you do when you want to your own JAAS LoginModule implementation for ActiveMQ broker authentication (for instance when you have the module already written)?</p> \r\n<p>This article will help with this task.</p>', 0, 0, '<h2>ActiveMQ + JAAS <br /></h2> \r\n<p>ActiveMQ messaging broker has several options how to deal with authentication and authorization. </p> \r\n<p>The easiest one is to use the <code>simpleAuthenticationPlugin</code>, but it is not very flexible.</p> \r\n<p>Another option is the <code>jaasAuthenticationPlugin </code>using\r\n two property files (users and groups), quite effective solution but \r\nstill very clumsy when you consider that all the information about users\r\n and groups are stored into files.</p> \r\n<p>Following text will describe how to use customer-defined JAAS LoginModule as an ActiveMQ plugin.</p> \r\n<h2>JAAS Custom Login Module for ActiveMQ</h2> \r\n<h3>Authentication</h3> \r\n<p>Once we have developed a JAAS login module we can build it and pack as a JAR library. To use it in the broker we need to put the JAR on the classpath of a running ActiveMQ instance. There are two ways how to do it:</p> \r\n<ol> \r\n<li> Copy the JAR into lib folder of the broker -<code>ACTIVEMQ_HOME/lib/extra</code> or <code>ACTIVEMQ_HOME/lib/optional</code></li> \r\n<li>Put a path to the JAR to the java classpath of the broker - edit <code>ACTIVEMQ_HOME/bin/activemq</code> (Unix) or <code>ACTIVEMQ_HOME/bin/activemq.bat</code> (Win) and extend the <code>ACTIVEMQ_CLASSPATH</code> parameter:<br /> \r\n<ul> \r\n<li><code>ACTIVEMQ_CLASSPATH=&quot;${ACTIVEMQ_CLASSPATH};/var/lib/auth-test.jar&quot;</code> (Unix)</li> \r\n<li><code>set ACTIVEMQ_CLASSPATH=%ACTIVEMQ_CONF%;%ACTIVEMQ_BASE%/conf;%ACTIVEMQ_HOME%/conf;%ACTIVEMQ_CLASSPATH%;c:/Develop/Java/lib/auth-test.jar</code> (Win)</li> \r\n</ul> \r\n<ul> </ul> \r\n</li> \r\n</ol> \r\n<h4>\r\n\r\nBroker Setting to use the Plugin\r\n</h4> \r\n<p>Edit the <code>ACTIVEMQ_HOME/conf/login.config</code> property file to use the plugin as following (consider the plugin class is <code>cz.net21.ActiveMqLoginModule</code>):</p> \r\n<p> </p> \r\n<pre class="brush: plain">MyLoginModule { \r\n  cz.net21.ActiveMqLoginModule&nbsp; required debug=true;\r\n};\r\n</pre> \r\n<p> </p> \r\n<p>Edit the <code>ACTIVEMQ_HOME/conf/activemq.xml</code> configuration file as following:</p> \r\n<p> </p> \r\n<pre class="brush: xml">&lt;broker … &gt; \r\n  …\r\n  &lt;plugins&gt;\r\n    &lt;jaasAuthenticationPlugin configuration="MyLoginModule" /&gt;\r\n  …\r\n  &lt;/plugins&gt;\r\n  …\r\n&lt;/broker&gt;\r\n</pre> \r\n<p> </p> \r\n<h4>Running the java code</h4> \r\n<p>Now we can run the java to see that the JAAS plugin is working:</p> \r\n<p> </p> \r\n<pre class="brush: java">ActiveMQConnectionFactory connectionFactory = new ActiveMQConnectionFactory("tcp://localhost:61616");\r\nConnection connection = connectionFactory.createConnection(username, password);\r\nconnection.start();\r\n</pre> \r\n<p> </p> \r\n<p>If the method <code>login()</code> from the module class <code>cz.net21.ActiveMqLoginModule</code> returns <em>false </em>for added credentials, the code will return by en exception:</p> \r\n<pre class="brush: plain">java.lang.SecurityException: User name [testuser] or password is invalid.\r\nCaused by: javax.security.auth.login.LoginException: Login Failure: all modules ignored</pre> \r\n<h3>Authorization</h3> \r\n<p>In this part we will look at a simple way how to authorize an user for broker''s resources (queues/topics).</p> \r\n<p>Via <code>authorizationPlugin </code>we can setup all the rights for queues/topics and users groups. <br /></p> \r\n<p> </p> \r\n<pre class="brush: xml">&lt;authorizationPlugin&gt;\r\n  &lt;map&gt;\r\n    &lt;authorizationMap&gt;\r\n      &lt;authorizationEntries&gt;\r\n        &lt;authorizationEntry queue="&gt;"\r\n          read="admins"&nbsp; write="admins"&nbsp; admin="admins" /&gt;\r\n  …\r\n</pre> \r\n<p> </p> \r\n<p> </p> \r\n<p>We can leave this settings and control the access via our custom JAAS module. All we need is to add an <code>UserPrincipal </code>object for the broker user and\r\na <code>GroupPrincipals </code>object  for the broker groups.</p> \r\n<p>Let''s extend our module to consume a file with groups used in the authorizationPlugin:</p> \r\n<p> </p> \r\n<pre class="brush: xml">MyLoginModule { \r\n  cz.net21.ActiveMqLoginModule required \r\n    debug=true\r\n    org.apache.activemq.jaas.properties.group="groups.properties";\r\n};</pre> \r\n<p> </p> \r\n<p>Here we use <code>org.apache.activemq.jaas.properties.group</code>  as a name of an option and <code>groups.properties</code> as a name of the property file with a list of groups. </p> \r\n<p> </p> \r\n<pre class="brush: java">public void initialize(Subject subject, CallbackHandler handler, Map&lt;String, ?&gt; state, Map&lt;String, ?&gt; options) {\r\n  this.subject = subject;\r\n  groupsFile = options.get("org.apache.activemq.jaas.properties.group") + "";\r\n  …\r\n</pre> \r\n<p> </p> \r\n<p>But we can use for instance <code>groupListFile </code>as the name and instead of the property file use a comma-separated file with just a list of group names.</p> \r\n<p>We will process the file and bind the logged user with one of the groups. </p> \r\n<pre class="brush: java">public boolean login() throws LoginException {\r\n  try {\r\n    File f = new File(baseDir, groupsFile);\r\n    groups.load(new java.io.FileInputStream(f));\r\n  } catch (IOException e) {\r\n    throw new LoginException("Unable to load group properties file " + groupsFile);\r\n  }\r\n  …\r\n</pre> \r\n<p>Then we need to put the <code>UserPrincipal </code>and <code>GroupPrincipals </code>objects into the subject''s principals:</p> \r\n<pre class="brush: java">principals.add(new UserPrincipal(user));\r\nprincipals.add(new GroupPrincipal(groupName));\r\nsubject.getPrincipals().addAll(principals);\r\n</pre> \r\n<p>If the <code>groupName</code> match the destination we will get the access, otherwise the code will return by en exception:</p> \r\n<p> </p> \r\n<pre class="brush: plain">java.lang.SecurityException: User guest is not authorized to read from: queue://TestQ\r\n</pre> \r\n<p> </p> \r\n<p> <br /></p> \r\n<p>Congratulation, we have a JAAS plugin for authentication and authorization of ActiveMQ broker!</p> \r\n<h2>Appendix <br /></h2> \r\n<p>I am working with Java 7, ActiveMQ 5.9.0</p> \r\n<p>Please see the discussed code <a href="/storage/ActiveMQ_JAAS_Custom_Login_Module.zip" title="The example code">in the attachment</a>. <br /></p> \r\n<p><br /></p>', 1, 'admin', 1, 'false', 'true', 1434608294, 'false'),
(34, 'Building a simple REST API', 1525591812, 'In my previous article I showed how to build a simple RESTful microservice. For sake of simplicity I skipped some good practices for building REST APIs and I feel a bit guilty about that. I think that topic deserves its own article. And here we go... we take a look at the previous API and try to do things better.', 0, 0, '<h2>API Requirements</h2> \r\n<p>What is the business case of our API? It''s a simple <strong>public</strong> API for a blog (actually this blog). The public here means, it allow the unauthorized uses to read the content. Not more, not less.</p> \r\n<ul> \r\n<li>information about the blog (name, description, menu items, ...)</li> \r\n<li>collection of articles (posts)</li> \r\n<li>filtered collection of articles&nbsp;(by the category and author)</li> \r\n<li>pagination of the articles (first, last, next and previous page)</li> \r\n<li>detail of an article (the whole text content)</li> \r\n</ul> \r\n<p>The administration API is built out of this scope and I will maybe talk about that in another article later. For the administration API we can expect:</p> \r\n<ul> \r\n<li>user management</li> \r\n<li>blog management</li> \r\n<li>articles management&nbsp;</li> \r\n</ul> \r\n<h2>Problems with the Old API</h2> \r\n<p>When we don''t talk about the missing AuthN/AuthZ, we find a lack of <strong>hyper-navigation in the API</strong>. Without knowing how the endpoints look like (even it follows the REST recommendations) there is no way <strong>how to navigate the client automatically</strong>.</p> \r\n<p>Calling the API self results to the response:</p> \r\n<pre>GET /api/ HTTP/1.1\r\nHTTP/1.1 403 Forbidden</pre> \r\n<p>This is not so bad, because we built a microservice API only for the articles management. In this case, we need a billboard endpoint. The billboard shows information about the blog and navigation to other endpoint.</p> \r\n<p>Another problem is with the navigation, resp. no navigation, within the API. When we call the <code>/api/articles</code> endpoint, the response look like:</p> \r\n<pre>[\r\n  {\r\n    "id" : 4,\r\n    "title" : "New article",\r\n    "summary" : "Lorem ipsum",\r\n    "body" : null,\r\n    "createdAt" : "2018-05-03",\r\n    "categoryId" : 1,\r\n    "author" : {\r\n      "id" : 1,\r\n      "name" : "Tomas Tulka",\r\n      "email" : "tomas.tulka@gmail.com"\r\n    }\r\n  },\r\n  ... another articles come here\r\n]</pre> \r\n<p>First problem is with the structure itself. What does the attribute <code>body</code> there? It''s always null because we expose the whole business object into the API even when some attributes are never set by the underlying service.</p> \r\n<p>Second, the response contains all the data, but we have no idea how to get the detail of an article, next page of the collection or how to filter the articles by the category ID.</p> \r\n<h2>New API&nbsp;</h2> \r\n<h3>The Billboad</h3> \r\n<p>To&nbsp;fulfill our needs we can design the response of the billboard endpoint <code>/api</code> as following:</p> \r\n<pre>{\r\n  "version" : "1.0",\r\n  "href" : "/api",\r\n  \r\n  "title" : "My Blog",\r\n  "description" : "A small blog about programming.",\r\n  \r\n  "categories" : [ {\r\n      "id" : 1, \r\n      "name" : "Programming"\r\n    }, {\r\n      "id" : 2,\r\n      "name" : "Another stuff"\r\n    } ],\r\n\r\n  "authors" : [ {\r\n      "name" : "Tomas Tulka",\r\n      "email" : "tomas.tulka@gmail.com",\r\n      "id" : 1 \r\n    } ],\r\n      \r\n  "links" : [ {\r\n      "rel" : "articles",\r\n      "href" : "/api/articles"\r\n    } ] }</pre> \r\n<p> </p> \r\n<p>The JSON document structure is pretty straightforward: the top-level entities are the blog content elements (<em>categories</em>&nbsp;and <em>authors</em>).</p> \r\n<p>The navigation is represented by the entity&nbsp;<code>links</code>, the&nbsp;<code>rel</code> attribute tells the logical name of the item and <code>href</code> attribute points to the resource URL.</p> \r\n<h3>The Articles Collection</h3> \r\n<p>Now, what we take a look at the <code>/api/articles</code> endpoint:&nbsp;</p> \r\n<pre>{\r\n  "version" : "1.0",\r\n  "href" : "/api/articles",\r\n  \r\n  "articles" : [ {\r\n      "href" : "/api/articles/4",\r\n      "data" : {\r\n        "id" : 4,\r\n        "title" : "New article",\r\n        "summary" : "Lorem ipsum",\r\n        "createdAt" : "2018-05-03",\r\n        "category" : {\r\n          "id" : 1,\r\n          "name" : "Programming"\r\n        },\r\n        "author" : {\r\n          "id" : 1,\r\n          "name" : "Tomas Tulka",\r\n          "email" : "tomas.tulka@gmail.com"\r\n        }\r\n      }      \r\n    },\r\n    ... another articles    \r\n  ],\r\n  \r\n  "queries" : [ {\r\n      "rel" : "page",\r\n      "name" : "page"\r\n    }, {\r\n      "rel" : "category",\r\n      "name" : "categoryId",\r\n    }, {\r\n      "rel" : "author",\r\n      "name" : "authorId",\r\n    } ],\r\n  \r\n  "links" : [ {\r\n      "rel" : "next",\r\n      "href" : "/api/articles?page=3"\r\n    }, {\r\n      "rel" : "previous",\r\n      "href" : "/api/articles?page=1"\r\n    }, {\r\n      "rel" : "first",\r\n      "href" : "/api/articles"\r\n    }, {\r\n      "rel" : "last",\r\n      "href" : "/api/articles?page=10"\r\n    } ] }</pre> \r\n<p> </p> \r\n<p> </p> \r\n<p> </p> \r\n<p>The endpoint have a set of query parameters listed in the <code>queries</code>. Practically it means you can filter the articles by calling the same endpoint with query parameters like <code>/api/articles?categoryId=1&amp;author=1</code>. The values for every query type are known already from the billboard response.</p> \r\n<p>The entity&nbsp;<code>links</code> brings the navigation (pagination).</p> \r\n<h3>The Article Detail&nbsp;</h3> \r\n<p>Last but not least is the <code>/api/articles/{id}</code> article detail endpoint:</p> \r\n<pre>{\r\n  "version" : "1.0",\r\n  "href" : "/api/articles/4",\r\n  \r\n  "data" : {\r\n    "id" : 4,\r\n    "title" : "New article",\r\n    "summary" : "Lorem ipsum dolor sit amet, consectetur adipiscing elit...",\r\n    "body" : "Lorem ipsum",\r\n    "createdAt" : "2018-05-03",\r\n    "category" : {\r\n      "id" : 1,\r\n      "name" : "Programming"\r\n    },\r\n    "author" : {\r\n      "id" : 1,\r\n      "name" : "Tomas Tulka",\r\n      "email" : "tomas.tulka@gmail.com"\r\n    }\r\n  } }</pre> \r\n<h2>Further Reading</h2> \r\n<p> </p> \r\n<ul> \r\n<li>The probably best source is the great book&nbsp;<a href="http://shop.oreilly.com/product/0636920028468.do" target="_blank" title="RESTful Web APIs book">RESTful Web APIs</a> by Leonard Richardson.</li> \r\n<li>If you are to build a more sophisticated search API you should consider using&nbsp;<a href="https://graphql.org/" target="_blank" title="GraphQL">GraphQL</a>.&nbsp;</li> \r\n</ul> \r\n<h2>Source Code</h2> \r\n<p>You can find the current implementation (PHP) on <a href="https://github.com/net21cz/blog-backend" title="Source code">GitHub</a>.</p> \r\n<p>Enjoy!&nbsp;&nbsp;</p> \r\n<p> </p>', 1, 'admin', 1, 'false', 'true', 1525788462, 'true'),
(3, 'ActiveMQ, HornetQ and RabbitMQ Performance Comparison', 1393267740, '<p>Messaging could be a great solution for a lot of projects regarding an inter-systems (and components) communication. But which vendor to choose? Which one is the best? </p> \r\n<p>There is no proper answer for this question, because each and every provider has some pros and cons. Please read the first description of all of them and figure out only those matching your requirements. </p> \r\n<p>If your results include <strong>ActiveMQ</strong>, <strong>HornetQ </strong>and <strong>RabbitMQ</strong>, you are propably interested in performace and some practical observations now. And that is what is this article all about.\r\n\r\n</p>', 0, 0, '<h2>What is tested</h2> \r\n<p>We leave all the brokers in the default setting, no additional tuning was done yet. If you have some special requirement, you should probably look deeply at the features of the brokers and count in the final results.</p> \r\n<p>We run the same performance test for several scenarios:<br /></p> \r\n<ol> \r\n<li>One broker, one producer, one consumer on the only one server.</li> \r\n<li>One broker running on the server one, one producer, one consumer running on the server 2.</li> \r\n<li>Two brokers running on <strong>different </strong>servers (forwarding messages / bridging), one producer&nbsp; running on the server 1, one consumer running on the server 2.</li> \r\n</ol> \r\n<p> \r\n<table cellspacing="0" cellpadding="0" border="0"> \r\n<tbody> \r\n<tr> \r\n<td><img alt="scenarios" src="/storage/ActiveMQ_HornetQ_and_RabbitMQ_Performance_Comparison_2.png" /></td> \r\n</tr> \r\n<tr> \r\n<td style="text-align: center; padding-top: 3px;"><em>Image 1:</em> Scenario 1, 2 and 3 architecture</td> \r\n</tr> \r\n</tbody> \r\n</table> \r\n</p> \r\nWe also run the test with different setting of clients:<br /> \r\n<ol> \r\n<li>queues, topics</li> \r\n<li>non-persistent, persistent massages</li> \r\n<li>one or ten threads for a queue/topic (one or ten message producers and consumers in parallel) </li> \r\n</ol>Because <strong>proportion of the results</strong> for the different scenarios is almost <strong>the same</strong>, we can focus only on the first scenario to invest the results and do the comparison. <br /> \r\n<h2>Results</h2>Parameters for the run:<br /> \r\n<ul> \r\n<li>non-persistent messages</li> \r\n<li>non-transacted</li> \r\n<li>sending messages in asynchronous mode</li> \r\n<li>receiving messages in asynchronous mode (AUTO_ACKNOWLEDGE)</li> \r\n<li>not encrypted</li> \r\n</ul> \r\n<p>Running on Linux system in virtual machine with 2 cores and 8 GB RAM.</p> \r\n<p> \r\n<table cellspacing="0" cellpadding="3" border="1" class="resultsTable" style="width: 701px;"> <caption>Results table</caption> \r\n<tbody> \r\n<tr> \r\n<td> queues<br /></td> \r\n<td> 1<br /></td> \r\n<td> 1<br /></td> \r\n<td> 1<br /></td> \r\n<td> 1<br /></td> \r\n<td> 10<br /></td> \r\n<td> 10<br /></td> \r\n<td> 10<br /></td> \r\n<td> 10<br /></td> \r\n</tr> \r\n<tr> \r\n<td> consumers (per queue)<br /></td> \r\n<td> 1<br /></td> \r\n<td> 1<br /></td> \r\n<td> 10<br /></td> \r\n<td> 10<br /></td> \r\n<td> 10<br /></td> \r\n<td> 10<br /></td> \r\n<td> 1<br /></td> \r\n<td> 1<br /></td> \r\n</tr> \r\n<tr> \r\n<td>  producers (per queue)</td> \r\n<td> 1<br /></td> \r\n<td> 1<br /></td> \r\n<td> 10<br /></td> \r\n<td> 10<br /></td> \r\n<td> 10<br /></td> \r\n<td> 10<br /></td> \r\n<td> 10<br /></td> \r\n<td> 10<br /></td> \r\n</tr> \r\n<tr> \r\n<td>message body size (bytes)<br /></td> \r\n<td> 128<br /></td> \r\n<td> 2048<br /></td> \r\n<td>  128</td> \r\n<td>  2048</td> \r\n<td>  128</td> \r\n<td>  2048</td> \r\n<td>  128</td> \r\n<td>  2048</td> \r\n</tr> \r\n<tr> \r\n<td><strong> ActiveMQ</strong> (msg/sec)</td> \r\n<td><em> 14590</em></td> \r\n<td><em> 14565</em></td> \r\n<td><em> 15700</em></td> \r\n<td><em> 15640</em></td> \r\n<td><em> 17920</em></td> \r\n<td><em> 17995</em></td> \r\n<td><em>  18180</em></td> \r\n<td><em>19220</em></td> \r\n</tr> \r\n<tr> \r\n<td><strong>HornetQ</strong> (msg/sec)</td> \r\n<td><em> 46605</em></td> \r\n<td><em> 47830</em></td> \r\n<td><em> 10140</em></td> \r\n<td><em> 10802</em></td> \r\n<td><em> 16165</em></td> \r\n<td><em> 18885</em></td> \r\n<td><em> 19852</em></td> \r\n<td><em> 19905</em></td> \r\n</tr> \r\n<tr> \r\n<td><strong>RabbitMQ</strong> (msg/sec)</td> \r\n<td><em> 20550</em></td> \r\n<td><em> 14680</em></td> \r\n<td><em> 14422</em></td> \r\n<td><em> 13065</em></td> \r\n<td><em> 13770</em></td> \r\n<td><em> 12150</em></td> \r\n<td><em>  13800</em></td> \r\n<td><em> 11930</em></td> \r\n</tr> \r\n</tbody> \r\n</table> \r\n</p> \r\n<p> \r\n<table cellspacing="0" cellpadding="0" border="0"> \r\n<tbody> \r\n<tr> \r\n<td><img alt="results" src="/storage/ActiveMQ_HornetQ_and_RabbitMQ_Performance_Comparison_1.png" /></td> \r\n</tr> \r\n<tr> \r\n<td style="text-align: center; padding-top: 3px;"><em>Image 2:</em> Results chart</td> \r\n</tr> \r\n</tbody> \r\n</table> \r\n</p> \r\n<h2>My point of view</h2> \r\n<p><strong>ActiveMQ </strong>is very good tool with lot of documentation, examples, support and a huge community. Is it not the best regarding the performance, but it is announced to be rapidly improved by the version 6 using Appolo module. We will see...<br /> <br /></p> \r\n<p><strong>HornetQ </strong>really shines in the performance and it is pretty useful with a good support as well, but a lot of features (for instance the management console) is tightly&nbsp; bound with running as a JBoss module. Running in a stand-alone mode (as I did) has several disadvantages and I would not recomment it. But if you are using (or going to use) the JBoss Application Server for running you web application, HornetQ could the right option for you. </p> \r\n<p>There is a bit mess in versioning of libraries, especially if you want to work with different vendors of components involved in the integration (Netty, Spring JMS, ...).</p> \r\n<p>Queues and topics must be declared in hornetq-jms.xml before and cannot be created and deleted dynamically using JMS API. <br /> <br /></p> \r\n<p><strong>RabbitMQ</strong> does not have a good performance and it is not very human-friendly (all the setting are written in Erlang, which makes longer configurations very unclear for a programmer). </p> \r\n<p>There is only a commercial implementation of JMS. You can use pure RabbitMQ libraries or the Spring AMQP, but it is a different approach from JMS and has several limitations, for instance AMQP 0-9-1 protocol used as native doesn''t support durable subscribers.</p> \r\n<p> <br /></p>', 1, 'admin', 1, 'false', '', 1434608285, 'false'),
(5, 'Synchronization with Modification of the Lock Reference', 1395764520, '<p>...is very <strong>very bad practice</strong>, nevertheless it is not so rare to meet it:<br /></p> \r\n<p>In <strong>legacy sources</strong> I have found a really tricky code causing an occasional error.</p> \r\n<p>Well, you can say all around synchronization is tricky, but good understanding is a clue to eliminate the magic - this article might help a bit.</p>', 0, 0, '<p>Let''s consider a very basic logic of the code: </p> \r\n<p><em>Thread-agents are dealing with a shared data of the singleton system.</em></p> \r\n<p>Alright, easy, the <strong>code working with the shared data must be synchronized</strong>.\r\n Yes, but don''t forget that the threads (the agents) are working with \r\ndata of another class (the system) - we can not use synchronized methods\r\n as they are using the instance of an agent as a mutex instead of the \r\nclass the data belongs to. Well, let''s use the shared system''s object as\r\n a lock and... we are ready... wait a minute: This is exactly the \r\nsolution implemented in the legacy code!</p> \r\n<p>Where''s the problem - this must work! Sure, but not in any case... <br /></p> \r\n<p>In a very simplified way the original code looks like this:</p> \r\n<pre class="brush: java">public class SystemApp {\r\n \r\n&nbsp;&nbsp;&nbsp; static Integer count = 0;\r\n\r\n&nbsp;&nbsp;&nbsp; static class AgentThread extends Thread {\r\n \r\n&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; public void run() {\r\n&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; try {\r\n&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; Thread.sleep(ThreadLocalRandom.current().nextInt(100));\r\n&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; } catch (InterruptedException e) { }&nbsp;&nbsp;&nbsp; \r\n \r\n&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; // do something\r\n&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; // ...\r\n \r\n&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; synchronized (count) {\r\n&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; count ++;\r\n&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; }\r\n \r\n&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; // do something else\r\n&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; // ...\r\n&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; }\r\n&nbsp;&nbsp;&nbsp; }\r\n \r\n&nbsp;&nbsp;&nbsp; public static void main(String[] argv) {&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; \r\n&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; // run agents\r\n&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; for (int i = 0; i &lt; 1000; i ++) {\r\n&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; new AgentThread().start();\r\n&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; } \r\n \r\n&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; // sleep for a while to let agents finish their work\r\n&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; try {\r\n&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; Thread.sleep(5000);\r\n&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; } catch (InterruptedException e) { }&nbsp;&nbsp;&nbsp; \r\n \r\n&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; // print the result\r\n&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; System.out.println(count);\r\n&nbsp;&nbsp;&nbsp; }\r\n}</pre> \r\n<p>What is the expected result printed on the screen? 1000? Right!</p> \r\n<p>But guess what we get by running it five times:</p> \r\n<p>955<br />979<br />973<br />959<br />963</p> \r\n<p>Of course, the pain is in here:</p> \r\n<pre class="brush: java">synchronized (count) {\r\n&nbsp;&nbsp;&nbsp; count ++;\r\n}</pre> \r\n<p>We are using as a lock an object referenced by the variable <em>count</em>. But this reference is changed inside the critical section. This means there is no guarantee that two or more parallel threads get the same lock object. And so sometimes happens this scenario: </p> \r\n<ol> \r\n<li>The thread A and the thread B are trying to enter the critical section.</li> \r\n<li>The thread A gets the access and the lock referenced by the variable <em>count </em>(currently for instance with a value of integer=2) gets locked up.</li> \r\n<li>The thread B is waiting for the release of the lock (integer=2).</li> \r\n<li>The thread A changes the reference of the variable <em>count </em>to the new value (integer=3) and releases the lock (integer=2).</li> \r\n<li>The thread B waiting for the lock (integer=2) gets that lock, enters the critical section and locks up the lock object (integer=2).</li> \r\n<li>The parallel thread C tries to enter the critical section with the lock object referenced by the variable <em>count </em>(integer=3 - changed by the thread&nbsp;A).</li> \r\n<li>The tread C gets the access to the critical section because its lock is now the object integer=3 while the thread B is being in the critical section as well (with the lock object integer=2).</li> \r\n</ol> \r\n<p>As you can see, by the seventh point we have <strong>two threads in the critical section</strong>.\r\n</p> \r\n<p>The lesson is: <u>never ever use a variable object as a lock!</u><br /></p> \r\n<p> <br /></p> \r\n<p> </p> \r\n<p>Synchronization is tricky and it is always good to think twice. </p> \r\n<p>By the way, using the API from the <em>java.util.concurrent</em> package is a good idea, too.\r\n</p> \r\n<p> <br /></p>', 1, 'admin', 1, 'false', '', 1434608263, 'false'),
(4, 'Principals from JAAS through CAS to Spring Security', 1394040780, '<p>This article is about a custom integration of:</p> \r\n<ul> \r\n<li><strong>Java Authentication and Authorization Service (JAAS)</strong></li> \r\n<li><strong>Central Authentication Service (CAS)</strong></li> \r\n<li><strong>Spring Security</strong> module</li> \r\n</ul> \r\n<p>Let''s imagine a situation we have  a developed username-password based JAAS Login Module implementing an authentication process.<br />The JAAS Login Module is used by CAS server as a authentication handler.<br />The CAS server is used by Spring Security via its CAS authentication provider plugin.</p> \r\n<p>So far it is easy to implement by a lot of existing manuals and HOWTOs using just provided libraries with no need to extend or modify a code.</p> \r\n<p>But what if the <strong>JAAS module contains also an authorization</strong>, implemented for instance by putting principals (roles) to a subject. To <strong>transmit the roles</strong> from JAAS module through CAS server to the Spring context we need to do some additional work as following.<br /></p>', 0, 0, '<p><em>Principal</em> is a term used by JAAS and CAS in a different meaning. Spring Security module uses rather a term <em>role</em>. We will use the term <em>a principal </em>or <em>a role </em>in the meaning of <strong>user''s group</strong>.</p> \r\n<h2>Collaboration</h2> \r\n<p> The collaboration among nodes is shown in the picture:</p> \r\n<p><img src="/storage/Principals_from_JAAS_through_CAS_to_Spring_Security_1.png" /><br /></p> \r\n<h2>JAAS Login Module</h2> \r\n<p> There is no big deal with JAAS, we need just to implement the <code>javax.security.auth.spi.LoginModule</code> interface and put our logic to authenticate a user.</p> \r\n<p>For authorization we will use our custom class <strong><code>CommonGroupPrincipal </code></strong>implementing the <code>java.security.Principal</code> interface.</p> \r\n<p>By some logic we assign roles to the user (as in the following very simple example) optimally in the commit method:</p> \r\n<p> </p> \r\n<pre class="brush: java">principals.add(new CommonGroupPrincipal("ROLE_USER"));\r\nif ("admin".equals(user)) {\r\n    principals.add(new CommonGroupPrincipal("ROLE_ADMIN"));\r\n}\r\nsubject.getPrincipals().addAll(principals);</pre> \r\n<p> Now we can use the modul in the CAS server. All we need to do is run an application server (Tomcat for instance) containing the CAS WAR file with a Java option defining the JAAS configuration file location.<br />Modify the run script of the application server as following (for Tomcat, Windows):</p> \r\n<pre class="brush: plain">set JAVA_OPTS=%JAVA_OPTS% -Djava.security.auth.login.config=%CATALINA_HOME%/conf/jaas.config</pre> \r\n<p>and create the configuration file: <br /></p> \r\n<pre class="brush: plain">CAS {\r\n    ttulka.test.auth.jaas.module.CasLoginModule required;\r\n};</pre> \r\n<p>Alternatively the Java default java.security.auth.login.config could be used, or the Java option could be set directly from the code of <code>CustomJaasAuthenticationManager </code>(see below):</p> \r\n<pre class="brush: java">System.setProperty("java.security.auth.login.config", "/path/to/jaas/config/file");</pre> \r\n<h2>Spring Security CAS plugin</h2> \r\n<p>We can setup the Spring Security CAS plugin in a usual way, but we will implement our custom <code>authenticationUserDetailsService </code>property from the CAS authentication provider bean:</p> \r\n<p> </p> \r\n<pre class="brush: xml">&lt;bean id="casAuthenticationProvider" class="org.springframework.security.cas.authentication.CasAuthenticationProvider"&gt;\r\n	&lt;property name="authenticationUserDetailsService"&gt;\r\n		&lt;bean class="ttulka.test.auth.spring.CustomAuthenticationUserDetailsService" /&gt;\r\n	&lt;/property&gt;\r\n	...</pre> The class <code>CustomAuthenticationUserDetailsService </code>implements the <code>org.springframework.security.core.userdetails.AuthenticationUserDetailsService</code> interface and its only one method deals with an object representing a CAS response token:&nbsp;\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n<pre class="brush: java">public class CustomAuthenticationUserDetailsService implements AuthenticationUserDetailsService&lt;CasAssertionAuthenticationToken&gt; {\r\n&nbsp;&nbsp; &nbsp;@Override\r\n&nbsp;&nbsp; &nbsp;public UserDetails loadUserDetails(CasAssertionAuthenticationToken token) throws UsernameNotFoundException {\r\n\r\n&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;final String groupList = (String)token.getAssertion().getPrincipal().getAttributes().get("CommonGroupPrincipal");\r\n&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;...\r\n</pre> \r\n<p>The variable <code>groupList</code> is holding a <strong>roles list transmitted from the CAS server</strong> got from the JAAS module. We will use to <strong>build a list of the granted authorities</strong> returned as a part of the <code>UserDetails</code> object.</p> \r\n<h2>CAS server extension</h2> \r\n<p> To push a CAS to consume and transmit additional attributes as roles we need to implement our custom alternative of an <strong>authentication handler</strong> and its standard implementation by the class <strong><code>JaasAuthenticationHandler</code></strong> class. Unfortunately the desired method <code>authenticateUsernamePasswordInternal</code> is in the <code>JaasAuthenticationHandler</code> class defined as final, so we cannot just simply extend the class.</p> \r\n<p>To work with our custom handler we need to extend the CAS <strong>authentication manager</strong>, too. As in the previous class, the standard implementation <strong><code>AuthenticationManagerImpl</code></strong> is set as a final class, so we have to create a new one.</p> \r\n<h3>JAAS Authentication Handler</h3> \r\n<p>Alike the <code>JaasAuthenticationHandler </code>we will extend the class <code>org.jasig.cas.authentication.handler.support.AbstractUsernamePasswordAuthenticationHandler</code> and implement just the method <code>authenticateUsernamePasswordInternal</code>.</p> \r\n<p>Using the standard JAAS process we log in via credentials and get principals from the JAAS subject represented by <code>CommonGroupPrincipal</code> objects (see above).<br />From the list we create a comma-separated string and put it into a principals map by a key as the class name (a public accessible property of the handler class):</p> \r\n<pre class="brush: java">public class CustomJaasAuthenticationHandler extends AbstractUsernamePasswordAuthenticationHandler {\r\n    ...\r\n    private Map&lt;String, Object&gt; principals = new HashMap&lt;&gt;();\r\n    ...\r\n    protected boolean authenticateUsernamePasswordInternal(final UsernamePasswordCredentials credentials)...\r\n        ...\r\n        loginContext = new LoginContext(realm, handler);\r\n        loginContext.login();\r\n	   \r\n        processPrincipals(loginContext.getSubject().getPrincipals());\r\n        ...\r\n    ...\r\n    private void processPrincipals(Set&lt;Principal&gt; principalsSet) {\r\n        ...\r\n        for (Principal p : principalsSet) {\r\n            if (p instanceof CommonGroupPrincipal) {\r\n                sb.append(p.getName());\r\n                ...\r\n            }\r\n        }\r\n        principals.put(CommonGroupPrincipal.class.getSimpleName(), sb.toString());\r\n        ...\r\n</pre> \r\n<p>The handler will be used directly by our new manager (see below) so needs no additional setting. <br />Alternatively we can define it in the CAS webapp configuration file (<code>WEB-INF/deployerConfigContext.xml</code>) as a new bean and then inject into the manager.</p> \r\n<p> </p> \r\n<h3>JAAS Authentication Manager</h3> \r\n<p>Alike the <code>AuthenticationManagerImpl</code> we will extend the class <code>org.jasig.cas.authentication.AbstractAuthenticationManager</code> and implement just the method <code>authenticateAndObtainPrincipal</code>.</p> \r\n<p>After the authentication succeeds we build the principal''s attributes from the handler''s principals and return:</p> \r\n<pre class="brush: java">handler = new CustomJaasAuthenticationHandler();\r\n...\r\nPrincipal principal = new SimplePrincipal(((UsernamePasswordCredentials)credentials).getUsername(), handler.getPrincipals());\r\n\r\nreturn new Pair&lt;AuthenticationHandler,Principal&gt;(handler, principal);</pre> \r\n<p>In the CAS webapp configuration file (<code>WEB-INF/deployerConfigContext.xml</code>) we need to set the manager:</p> \r\n<pre class="brush: xml">&lt;bean id="authenticationManager" class="ttulka.test.auth.cas.CustomJaasAuthenticationManager" /&gt;</pre> \r\n<p>To include the attributes with roles in the response to the Spring Security plugin we need to <strong>allow the attribute name <code>CommonGroupPrincipal</code> </strong>for a registered service in <code>WEB-INF/deployerConfigContext.xml</code>:</p> \r\n<p> </p> \r\n<pre class="brush: xml">&lt;bean id="serviceRegistryDao" class="org.jasig.cas.services.InMemoryServiceRegistryDaoImpl"&gt;\r\n&nbsp;&nbsp;&nbsp; &lt;property name="registeredServices"&gt;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;list&gt;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;bean class="org.jasig.cas.services.RegexRegisteredService"&gt;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ... \r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;property name="allowedAttributes"&gt;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;list&gt;\r\n &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;value&gt;CommonGroupPrincipal&lt;/value&gt;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;/list&gt;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;/property&gt;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;/bean&gt; \r\n            ...\r\n</pre> \r\n<p>The last step is to modify the response renderer JSP page <code>WEB-INF/view/jsp/protocol/2.0/casServiceValidatorSuccess.jsp</code> to contain the attributes: <br /></p> \r\n<pre class="brush: xml">&lt;cas:serviceResponse xmlns:cas=''http://www.yale.edu/tp/cas''&gt;\r\n&nbsp;&nbsp;&nbsp; &lt;cas:authenticationSuccess&gt;\r\n&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &lt;cas:user&gt;${fn:escapeXml(assertion.chainedAuthentications[fn:length(assertion.chainedAuthentications)-1].principal.id)}&lt;/cas:user&gt;&nbsp;&nbsp;&nbsp; \r\n&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &lt;cas:attributes&gt;\r\n&nbsp;&nbsp;&nbsp;     &lt;c:forEach var="attr" items="${assertion.chainedAuthentications[fn:length(assertion.chainedAuthentications)-1].principal.attributes}"&gt;\r\n&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp; &lt;cas:${fn:escapeXml(attr.key)}&gt;${fn:escapeXml(attr.value)}&lt;/cas:${fn:escapeXml(attr.key)}&gt;\r\n    &nbsp;&nbsp;&nbsp; &lt;/c:forEach&gt;\r\n&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &lt;/cas:attributes&gt; \r\n        ... \r\n</pre> \r\n<p> </p> \r\n<p> </p> \r\n<p> </p> \r\n<p>The response will then looks like: <br /></p> \r\n<pre class="brush: xml">&lt;cas:serviceResponse xmlns:cas=''http://www.yale.edu/tp/cas''&gt;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;cas:authenticationSuccess&gt;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;cas:user&gt;admin&lt;/cas:user&gt;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;cas:attributes&gt;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;cas:CommonGroupPrincipal&gt;ROLE_USER,ROLE_ADMIN&lt;/cas:CommonGroupPrincipal&gt;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;/cas:attributes&gt;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;/cas:authenticationSuccess&gt;\r\n&lt;/cas:serviceResponse&gt;\r\n</pre> \r\n<p>The responsed XML is then processed by the Spring''s <code>CustomAuthenticationUserDetailsService</code> (see above).</p> \r\n<p>All the CAS-related classes must be packed as a JAR library and copied to <code>/WEB-INF/lib</code> folder of the CAS WAR application.<br /></p> \r\n<p> </p> \r\n<p>And the integration is ready to use!</p> \r\n<h2>Appendix</h2> \r\n<p>I am working with Java 7, CAS 3.5.2, Spring 3.2.4. and Spring Security module 3.2.0.</p> \r\n<p>Please see the discussed code <a href="/storage/Principals_from_JAAS_through_CAS_to_Spring_Security.zip" title="The example code">in the attachment</a>. </p>', 1, 'admin', 1, 'false', 'true', 1434608275, 'false'),
(112, 'Multiple LDAP Servers Integration', 1528815360, '<p>When an administative solution (like <a href="https://technet.microsoft.com/pt-pt/library/how-global-catalog-servers-work.aspx" target="_blank">Global Catalog</a>) is not possible or wanted and we have to integrate more LDAP servers under one hood there is a simple way how to do it with <a href="https://github.com/TremoloSecurity/MyVirtualDirectory" taregt="_blank">MyVirtualDirectory</a>.</p>', 0, 0, '<p>MyVirtualDirectory (<strong>MyVD</strong>) offers much more than an integration of multiple LDAP servers, actually <em>anything</em> could be exposed as a LDAP service via MyVD. In this tutorial we focus only on LDAP.</p> \r\n<h2>Simple LDAP Integration</h2> \r\n<p>We begin with a simple example of two LDAP servers integration.</p> \r\n<p>We have one LDAP running in <code>server1.com</code> network on the port <code>398</code> and another running in <code>server2.com</code> on the same port.</p> \r\n<p>We integrate the server in out local network on the port <code>50983</code> as shows the following picture:</p> \r\n<p align="center"><img src="/storage/myvd-1.png" alt="Simple LDAP Integration" /></p> \r\n<p>First, let''s set up the MyVD server (HTTP in our case).</p> \r\n<pre>server.listener.port=50983\r\n</pre> \r\n<p>That''s it. Now the integration of the servers:</p> \r\n<pre>server.nameSpaces=server1,server2\r\n \r\nserver.server1.nameSpace=dc=server1,dc=com\r\nserver.server1.weight=100\r\nserver.server1.chain=ldap\r\nserver.server1.ldap.className=net.sourceforge.myvd.inserts.ldap.LDAPInterceptor\r\nserver.server1.ldap.config.host=server1.com\r\nserver.server1.ldap.config.port=389\r\nserver.server1.ldap.config.remoteBase=dc=server1,dc=com\r\nserver.server1.ldap.config.proxyDN=uid=testuser1,ou=people,dc=server1,dc=com\r\nserver.server1.ldap.config.proxyPass=123\r\n \r\nserver.server2.nameSpace=dc=server2,dc=com\r\nserver.server2.weight=100\r\nserver.server2.chain=ldap\r\nserver.server2.ldap.className=net.sourceforge.myvd.inserts.ldap.LDAPInterceptor\r\nserver.server2.ldap.config.host=server2.com\r\nserver.server2.ldap.config.port=389\r\nserver.server2.ldap.config.remoteBase=dc=server2,dc=com\r\nserver.server2.ldap.config.proxyDN=uid=testuser2,ou=people,dc=server2,dc=com\r\nserver.server2.ldap.config.proxyPass=123\r\n</pre> \r\n<h2>LDAP Client</h2> \r\n<p>As a non-trivial client example let''s consider the <a href="https://spring.io/guides/gs/authenticating-ldap" target="_blank">Spring Security LDAP</a>.</p> \r\n<p>Simple said, the Spring Security LDAP does two search queries to the LDAP server:</p> \r\n<ul> \r\n<li>Get a user DN by its username (<code>(uid=&lt;username&gt;)</code>),</li> \r\n<li>get groups by user''s DN (<code>(member=&lt;userDN&gt;)</code>).</li> \r\n</ul> \r\n<p>Spring allow the user to redefine the search bases and filters for different LDAP structures and uses placeholders (so the filter looks like <code>(uid={0})</code>). For the MyVD setting above let''s set our client as following:</p> \r\n<p>\r\n<table border="1" cellpadding="5" cellspacing="0"> \r\n<tbody>\r\n<tr>\r\n<td>user search base</td>\r\n<td><code>dc=com</code></td>\r\n</tr> \r\n<tr>\r\n<td>user search filter</td>\r\n<td><code>(uid={0})</code></td>\r\n</tr> \r\n<tr>\r\n<td>groups search base</td>\r\n<td><code>dc=com</code></td>\r\n</tr> \r\n<tr>\r\n<td>groups search filter</td>\r\n<td><code>(uid={0})</code></td>\r\n</tr> \r\n</tbody>\r\n</table>\r\n</p>\r\n \r\n<h2>Namespaces Integration</h2> \r\n<p>In our first example we had two server with one base in common <code>dc=com</code>. But what happend when we have to integrate multiple server with different bases? This is what the property <code>server.&lt;server&gt;.nameSpace</code> is meant for.</p> \r\n<p align="center"><img src="/storage/myvd-2.png" alt="Namespaces Integration" /></p> \r\n<pre>...\r\nserver.server1.nameSpace=dc=mycom,dc=com\r\n...\r\nserver.server1.ldap.config.host=server1.org\r\nserver.server1.ldap.config.remoteBase=dc=server1,dc=org\r\nserver.server1.ldap.config.proxyDN=uid=testuser1,ou=people,dc=server1,dc=org\r\n...\r\nserver.server2.nameSpace=dc=mycom,dc=com\r\n...\r\nserver.server2.ldap.config.host=server2.net\r\nserver.server2.ldap.config.remoteBase=dc=server2,dc=net\r\nserver.server2.ldap.config.proxyDN=uid=testuser2,ou=people,dc=server2,dc=net\r\n...\r\n</pre> \r\n<p>Now we can change our search base to <code>dc=mycom,dc=com</code>. Unfortunately this doesn''t work. The problem is the DN of the result user entity is mapped to the integration namespace. It means for the username <code>testuser1</code> we get instead of <code>uid=testuser1,ou=people,dc=server1,dc=com</code> a DN <code>uid=testuser1,ou=people,dc=mycom,dc=com</code> and that doesn''t match the value of the <code>member</code> attribute of group entities.</p> \r\n<p>MyVD brings a solution in <a href="https://github.com/TremoloSecurity/MyVirtualDirectory/blob/master/doc/myvd.asc#mapping-inserts" target="_blank">Mapping Inserts</a>:</p> \r\n<pre>...\r\nserver.server1.chain=dnMapper,ldap\r\n...\r\nserver.server1.dnMapper.className=net.sourceforge.myvd.inserts.mapping.DNAttributeMapper\r\nserver.server1.dnMapper.config.dnAttribs=member\r\nserver.server1.dnMapper.config.remoteBase=dc=server1,dc=org\r\nserver.server1.dnMapper.config.localBase=dc=mycom,dc=com\r\n...\r\nserver.server2.chain=dnMapper,ldap\r\n...\r\nserver.server2.dnMapper.className=net.sourceforge.myvd.inserts.mapping.DNAttributeMapper\r\nserver.server2.dnMapper.config.dnAttribs=member\r\nserver.server2.dnMapper.config.remoteBase=dc=server2,dc=net\r\nserver.server2.dnMapper.config.localBase=dc=mycom,dc=com\r\n...\r\n</pre> \r\n<p>The DN Attribute Mapper maps specified attributted back to the original namespace. Now the search works again.</p> \r\n<h2>Integration of Heterogeneous Services</h2> \r\n<p>As we mentioned in the beginning MyVD provides the possibility to integrate different services. So what happend when we integrate a standard LDAP server (e.g. <a href="https://www.openldap.org/" target="_blank">OpenLDAP</a>) and Active Directory (<strong>AD</strong>)? We are still on LDAP field but the details are different. For example AD''s user entity holds the username in an <code>sAMAccountName</code> attribute. This means we have to integrate those heterogeneous attributes to be searchable with one client search query. \r\n</p>\r\n<p align="center"><img src="/storage/myvd-3.png" alt="Integration of Heterogeneous Services" /></p> \r\n<p>Sure, we can compose the search filter like <code>(|(uid={0})(sAMAccountName={0}))</code>, which will work fine, but it <strong>exposes implementation details</strong> to the client and breaks so the encapsulation principle. The client shouldn''t know anything about the backend server, it should treat the service as a <strong>single LDAP server</strong>.</p> \r\n<p>Fortunately, there is MyVD''s Attribute Mapper:</p> \r\n<pre>...\r\nserver.server2.chain=uidMapper,dnMapper,ldap\r\n...\r\nserver.server2.uidMapper.className=net.sourceforge.myvd.inserts.mapping.AttributeMapper\r\nserver.server2.uidMapper.config.mapping=sAMAccountName=uid\r\n...\r\n</pre> \r\n<p>Now works everything fine. The whole MyVD configuration file:</p> \r\n<pre>server.listener.port=50983\r\n \r\nserver.nameSpaces=server1,server2\r\n \r\nserver.server1.nameSpace=dc=mycom,dc=com\r\nserver.server1.weight=100\r\nserver.server1.chain=dnMapper,ldap\r\nserver.server1.ldap.className=net.sourceforge.myvd.inserts.ldap.LDAPInterceptor\r\nserver.server1.ldap.config.host=server1.org\r\nserver.server1.ldap.config.port=389\r\nserver.server1.ldap.config.remoteBase=dc=server1,dc=org\r\nserver.server1.ldap.config.proxyDN=uid=testuser1,ou=people,dc=server1,dc=org\r\nserver.server1.ldap.config.proxyPass=123\r\n \r\nserver.server1.dnMapper.className=net.sourceforge.myvd.inserts.mapping.DNAttributeMapper\r\nserver.server1.dnMapper.config.dnAttribs=member\r\nserver.server1.dnMapper.config.remoteBase=dc=server1,dc=org\r\nserver.server1.dnMapper.config.localBase=dc=mycom,dc=com\r\n \r\nserver.server2.nameSpace=dc=mycom,dc=com\r\nserver.server2.weight=100\r\nserver.server2.chain=uidMapper,dnMapper,ldap\r\nserver.server2.ldap.className=net.sourceforge.myvd.inserts.ldap.LDAPInterceptor\r\nserver.server2.ldap.config.host=server2.net\r\nserver.server2.ldap.config.port=389\r\nserver.server2.ldap.config.remoteBase=dc=server2,dc=net\r\nserver.server2.ldap.config.proxyDN=uid=testuser2,ou=people,dc=server2,dc=net\r\nserver.server2.ldap.config.proxyPass=123\r\n \r\nserver.server2.dnMapper.className=net.sourceforge.myvd.inserts.mapping.DNAttributeMapper\r\nserver.server2.dnMapper.config.dnAttribs=member\r\nserver.server2.dnMapper.config.remoteBase=dc=server2,dc=net\r\nserver.server2.dnMapper.config.localBase=dc=mycom,dc=com\r\n \r\nserver.server2.uidMapper.className=net.sourceforge.myvd.inserts.mapping.AttributeMapper\r\nserver.server2.uidMapper.config.mapping=sAMAccountName=uid\r\n</pre> \r\n<p>Happy integrating!</p>', 1, 'admin', 1, 'false', 'false', 1528704595, 'false');
INSERT INTO `serendipity_entries` (`id`, `title`, `timestamp`, `body`, `comments`, `trackbacks`, `extended`, `exflag`, `author`, `authorid`, `isdraft`, `allow_comments`, `last_modified`, `moderate_comments`) VALUES
(6, 'RMI meets JMS', 1403112300, '<p>A simple lightweight library for <strong>calling remote services via JMS</strong>.</p> \r\n<p>Library is using only JMS 1.1 API and it''s Requestor and bytes messages.</p> \r\n<p>As simple as it can be, ready to use!<br /></p>', 0, 0, '<h2>How to use</h2> \r\n<p>Put the maven dependency into your POM file:</p> \r\n<p> </p> \r\n<pre class="brush: xml">&lt;dependency&gt;\r\n   &lt;groupId&gt;cz.net21.ttulka&lt;/groupId&gt;\r\n&nbsp;&nbsp; &lt;artifactId&gt;rmi-meets-jms&lt;/artifactId&gt;\r\n&nbsp;&nbsp; &lt;version&gt;1.0.1&lt;/version&gt;\r\n&lt;/dependency&gt;</pre> \r\n<p>Alternatively you can <a href="storage/rmi-meets-jms-1.0.1.jar">download the library in the JAR file</a> and put it directly into your project classpath.</p> \r\n<h3>Remote service</h3> \r\n<p>The remote service is just a simple interface implemented by a class:</p> \r\n<pre class="brush: java">public interface Service {\r\n \r\n&nbsp;&nbsp;&nbsp; Integer myMethod1(Integer i);\r\n&nbsp;&nbsp;&nbsp; void myMethod2(String str);\r\n}\r\n\r\npublic class ServiceImpl implements Service {\r\n\r\n&nbsp;&nbsp;&nbsp; public Integer myMethod1(Integer i) {\r\n&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; return i * 2;\r\n&nbsp;&nbsp;&nbsp; }\r\n\r\n&nbsp;&nbsp;&nbsp; public void myMethod2(String str) {\r\n&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; System.out.println("myMethod2 says: " + str);\r\n&nbsp;&nbsp;&nbsp; }\r\n}</pre> \r\n<p>Methods of the service can be overloaded. <br /></p> \r\n<h3>Java code</h3> \r\n<p>To use the library directly from a java code you need to create a JMS factory and a destination queue:</p> \r\n<p> </p> \r\n<pre class="brush: java">final QueueConnectionFactory connectionFactory = new ActiveMQConnectionFactory("tcp://localhost:61616");\r\nfinal Queue queue = new ActiveMQQueue("MyQueue1");</pre> \r\n<p>Then, on the <strong>server side</strong>, the remote service provider must be created with the service implementation as a parameter:</p> \r\n<pre class="brush: java">final Service serviceImpl = new ServiceImpl();\r\n\r\nfinal RemoteServiceProvider provider = new RemoteServiceProvider(connectionFactory, queue, serviceImpl);</pre> \r\n<p>On the <strong>client side</strong> the remote service consumer must be created and then the remote service can be obtained:</p> \r\n<pre class="brush: java">final RemoteServiceConsumer consumer = new RemoteServiceConsumer(connectionFactory, queue, Service.class);\r\n\r\nfinal Service service = (Service)consumer.getService();\r\n</pre> \r\n<p> </p> \r\n<p> </p> \r\n<p>and the service can be called:</p> \r\n<pre class="brush: java">Integer res1 = service.myMethod1(3);\r\nSystem.out.println(res1);               // will print "6"\r\n\r\nservice.myMethod2("Hello, server!");    // will print "Hello, server!" on the server''s console output</pre> \r\n<h3>Spring approach</h3> \r\n<p>The same can be achieved with the Spring framework very easily (as everything is easy with the Spring):</p> \r\n<pre class="brush: xml">&lt;!-- Server side --&gt;\r\n&lt;bean id="server" class="cz.net21.ttulka.rmimeetsjms.RemoteServiceProvider"&gt;\r\n	&lt;constructor-arg ref="jmsFactory" /&gt;\r\n	&lt;constructor-arg ref="queue" /&gt;\r\n	&lt;constructor-arg ref="serviceImpl" /&gt;\r\n&lt;/bean&gt;\r\n\r\n&lt;!-- Client side --&gt;\r\n&lt;bean id="client" class="cz.net21.ttulka.rmimeetsjms.RemoteServiceConsumer"&gt;\r\n	&lt;constructor-arg ref="jmsFactory" /&gt;\r\n	&lt;constructor-arg ref="queue" /&gt;\r\n	&lt;constructor-arg value="mypack.Service" /&gt;\r\n&lt;/bean&gt;\r\n&lt;bean id="serviceProxy" factory-bean="client" factory-method="getService" /&gt;\r\n\r\n&lt;!-- Service implementation --&gt;\r\n&lt;bean id="serviceImpl" class="mypack.ServiceImpl" /&gt;\r\n\r\n&lt;!-- JMS connection factory --&gt;\r\n&lt;bean id="jmsFactory" class="org.apache.activemq.ActiveMQConnectionFactory"&gt;\r\n	&lt;property name="brokerURL" value="tcp://localhost:61616" /&gt;\r\n&lt;/bean&gt;\r\n\r\n&lt;!-- JMS destination --&gt;\r\n&lt;bean id="queue" class="org.apache.activemq.command.ActiveMQQueue"&gt;\r\n	&lt;constructor-arg index="0" value="MyQueue1" /&gt;\r\n&lt;/bean&gt;</pre> \r\n<p>All you need to do is to initialize the Spring context:</p> \r\n<pre class="brush: java">final ApplicationContext context = new ClassPathXmlApplicationContext("spring-context.xml");</pre> \r\n<p>and get the service proxy on the client side:</p> \r\n<pre class="brush: java">final Service service = (Service)context.getBean("serviceProxy");</pre> \r\n<h2>Limitation <br /></h2> \r\n<p>There is only one limitation regarding the parameters of the remote service: all the <strong>parameters must be serializable</strong> (must implement <code>java.io.Serializable</code>).</p> \r\n<p><br /></p> \r\n<p>Have fun!</p> ', 1, 'admin', 1, 'false', 'true', 1434608253, 'false'),
(7, 'RMI meets JMS release 1.0.1', 1408898400, '<p>New version of RMI meets JMS released! <br /></p>', 0, 0, '<p>The last release has a version number 1.0.1.</p> \r\n<p>It improves the library in meaning of <strong>performance </strong>(optimized process of serialization) and adds additional <strong>logging </strong>of error statuses.</p> \r\n<p> </p> \r\n<p> <br /></p>\r\n<p>Use and gain!</p> \r\n<p> <br /></p>', 1, 'admin', 1, 'false', '', 1408949110, 'false'),
(8, 'Gradle build from an Ant script', 1415636520, '<p>Currently I am working on a redesign of a pretty complex project based on Ant builds. The task is to move whole concept into Gradle.</p> \r\n<p>I will continuously update this article how my work will be moving forward and put interesting issues and my solutions for them.</p> \r\n<p>If you have a better solution, please comment and discuss!<br /></p>', 0, 0, '<h2>Does a file exist?</h2> \r\n<p>In the Ant script I have found such a construct to check if a file exists:</p> \r\n<p> </p> \r\n<pre class="brush: xml">&lt;pathconvert property="MyFile.isPresent" setonempty="false"&gt;\r\n    &lt;path&gt;\r\n&nbsp;&nbsp;&nbsp;     &lt;fileset dir="src" includes="MyFile-*.dat" /&gt;\r\n&nbsp;&nbsp;&nbsp; &lt;/path&gt;\r\n&lt;/pathconvert&gt;\r\n</pre> \r\n<p>Obviously it checks the folder <em>src</em> for files with names of the filter <em>MyFile-*.dat</em>.</p> \r\n<p>We can do the same with Gradle''s <code>FileCollection</code>:</p> \r\n<p> </p> \r\n<pre class="brush: groovy">MyFile.isPresent = !fileTree("src").include(''MyFile-*.dat'').isEmpty();</pre> \r\n<p>\r\nThis will create a file filter on the folder and check if the match is empty, then set to a variable.</p> \r\n<h2>Substring </h2> \r\n<p>In the Ant script the macro was defined as a javascript:</p> \r\n<pre class="brush: xml">&lt;scriptdef name="substring" language="javascript"&gt;</pre> \r\n<p>With Gradle you can easily implement it in java:</p> \r\n<pre class="brush: groovy">def substring(String text, String regexp, int result) {\r\n&nbsp;&nbsp;&nbsp; java.util.regex.Pattern p = java.util.regex.Pattern.compile(regexp);\r\n&nbsp;&nbsp;&nbsp; java.util.regex.Matcher m = p.matcher(text);\r\n&nbsp;&nbsp;&nbsp; if (m.find( )) {\r\n&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; return m.group(result + 1);\r\n&nbsp;&nbsp;&nbsp; }\r\n&nbsp;&nbsp;&nbsp; return null;\r\n}</pre> \r\n<p>and use it:</p> \r\n<pre class="brush: groovy">def version = substring(files.getAsPath(), "executor-(.*)\\\\.msi", 0)</pre> \r\n<p> </p> \r\n<h2> Custom builds</h2> \r\n<p>Because the result from the new Gradle build must be the same as from the old Ant build <strong>without changes of the project structure</strong>, we need to customize standard <code>java </code>plugin builds a bit.</p> \r\n<h3>Source sets</h3> \r\n<p>Java plugin provides a pretty high-level configuration element called <code>sourceSets</code>. You can change the sources location by setting the <code>sourceSets</code> up:</p> \r\n<pre class="brush: groovy">sourceSets {\r\n&nbsp;&nbsp;&nbsp; main {\r\n&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; java {\r\n&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; srcDirs = ["mysource/mypkg"]\r\n&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; exclude "test/**"\r\n&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; }\r\n&nbsp;&nbsp;&nbsp; }\r\n}</pre> \r\n<h3>Destination of the result classes</h3> \r\n<p>Compilation of the java classes in the <a target="_blank" href="http://www.gradle.org/docs/current/userguide/java_plugin.html"><em>java plugin</em></a> is done by the target called <code>compileJava</code>. If you want to change the destination of the compilation, can do it easily by rewriting the variable <code>destinationDir</code>:</p> \r\n<pre class="brush: groovy">compileJava {\r\n&nbsp;&nbsp;&nbsp; destinationDir = file("myBuildDir")&nbsp;&nbsp;&nbsp; // change the default dir for classes\r\n}\r\n</pre> \r\n<h3>Additional clean</h3> \r\n<p> If you want to put some additional actions into the standard clean task, do it easily:</p> \r\n<pre class="brush: groovy">clean &lt;&lt; {\r\n&nbsp;&nbsp;&nbsp; // ... do some clean up\r\n}\r\n</pre> \r\n<p> </p> \r\n<h3>Compile task</h3> \r\n<p> In the old Ant script I have a compile task I need to keep. To make it work correctly together with the standard <code>java</code> plugin, make it dependent on the <code>classes</code> task, which is equivalent in the context:</p> \r\n<pre class="brush: groovy">task compile(dependsOn: classes) {&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; // depends on the standard java task "classes"\r\n}\r\n</pre> \r\n<h3>Another build</h3> \r\n<p> If you want to have a build of different sources in the same Gradle file (of course in a different task), you can do it like this:</p> \r\n<pre class="brush: groovy">sourceSets {\r\n&nbsp; main {\r\n&nbsp;&nbsp;&nbsp; ...\r\n&nbsp; }\r\n&nbsp; compileApp2 {\r\n&nbsp;&nbsp;&nbsp; java {\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; srcDirs = ["anothersource/mypkg2"]\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; include "app/**"\r\n&nbsp;&nbsp;&nbsp; }\r\n&nbsp; }\r\n}\r\n...\r\ntask compileApp2(type: JavaCompile, dependsOn: prepareApp2) {\r\n&nbsp;&nbsp;&nbsp; source = sourceSets.compileApp2.allSource.srcDirs\r\n&nbsp;&nbsp;&nbsp; destinationDir = file(''app2BuildDir'')&nbsp;&nbsp;&nbsp; \r\n&nbsp; &nbsp; classpath = configurations.compile&nbsp; \r\n}\r\n</pre> \r\n<br>', 1, 'admin', 1, 'false', 'true', 1434608226, 'false'),
(1, 'About me', 1392919980, '<p>Hi,<br>my name is Tomas Tulka and I am a software developer.</p>\r\n\r\n<p>I love reading Franz Kafka, listening to dark music and talking about my job.</p>\r\n<p>And because all my friends are already sick of it all, especially of the last one, I started to write this blog.</p>\r\n\r\n<p>I post ideas, thoughts and solutions I made up or heard of and didn''t find anywhere else.</p>\r\n<p>I hope it helps you a bit!</p>', 0, 0, '<p>Please feel free to comment and discuss!</p>', 0, 'admin', 1, 'false', 'true', 1484203737, 'false'),
(21, 'JSON Mock Data Generator', 1493140860, '<p>It''s easy to generate test mock JSON data for a small HTTP request or a similar use, because there is a planty of online tools providing this functionality for you.</p> \r\n<p>But what if you want to generate data for a database performance test for systems like MongoDB or Elasticsearch?</p> \r\n<p>Online tools can generate entities in tens, maybe in hunders, but in thousands or millions?&nbsp;</p> \r\n<p>In this case comes the&nbsp;<a href="https://github.com/ttulka/json-mock-data-generator" target="_blank" title="JSON Mock Data Generator">JSON Mock Data Generator</a> on the scene.</p>', 0, 0, '<p><br />&nbsp;</p>', 1, 'admin', 1, 'false', 'true', 1493184890, 'false'),
(9, 'Memory Examiner', 1420477560, '<p>When you need to learn something by hear, you must repeat it again and again... and it is hard.</p> \r\n<p>This little program could help you!</p> \r\n<p> It is a simple test application for pairs of term - explanation, it could be used for technical definitions as well as words of a foreign language.<br /></p>', 0, 0, '<h2>Fill up the lexicon</h2> \r\n<p>First we need to define the lexicon of pairs term-explanation from which the application shall test us.</p> \r\n<p> We can do it in two easy ways:</p> \r\n<ol> \r\n<li>by the form in the bottom part of the application frame,</li> \r\n<li>putting the pairs as <strong>two lines of a text file</strong> (first line the term, second the explanation and so on) and import them via the application menu.</li> \r\n</ol> \r\n<p>The lexicon can be as well exported into a text file via the application menu, this will create two lines of text for each term-explanation pair. The file can be then edited and imported into the application and vise versa.</p> \r\n<h2>Test your memory!</h2> \r\n<p>The application will show you first the term and let you think. You can let show the explanation. Then you can move forward by clicking the green or red button if you had known the term or not.</p> \r\n<p>The application will server the most difficult words with priority. </p> \r\n<h3>Structure your tests</h3> \r\n<p>The application uses the file named <strong><code>lexicon.dat</code></strong> in the working directory as the storage. You can backup your lexicons in files and just rename the file with the demanding lexicon to <code>lexicon.dat</code> to push it into the application (the application has to be restarted to load the new lexicon file).</p> \r\n<p>Or you can use export - import functions to achieve this. But be aware that doing this you will loose you success-fail results!</p> \r\n<h2>Get it</h2> \r\n<p>You can download the <a href="/storage/memory-examiner-1.0.jar">executable JAR archive</a> and run it by the command (if your OS is not configured to run JAR files on the JRE implicitly):</p> \r\n<p><code>java -jar memory-examiner-1.0.jar</code></p> \r\n<p> <br /></p> \r\n<p>And because this is a blog about programming, you can see the <a href="/storage/memory-examiner-1.0-sources.jar">source codes</a> as well.</p>', 1, 'admin', 1, 'false', 'true', 1434608214, 'false'),
(10, 'Managing non-java resources from Gradle', 1424198040, '<p>There are really complex projects which consist of a lot of heterogeneous parts, modules, batch scripts, binaries...</p> \r\n<p>Let''s consider a project containing a module written in C... How to proceed in this case when we want to manage everything by the same way, compile from Gradle and version in a Maven repository?</p> \r\n<p>This article describes an easy way how to achieve this tough DevOps goal.<br /> </p>', 0, 0, '<h2>Building non-java resources with Gradle <br /></h2> \r\n<p>For building non-java sources there is a package of plugins for dealing with native binaries, this package is currently under incubating but seems to be pretty usable so far.</p> \r\n<p>Details can be found in the <a target="_blank" href="https://gradle.org/docs/current/userguide/nativeBinaries.html" title="Building native binaries">Building native binaries</a> chapter of the official documentation. <a href="https://gradle.org/docs/current/userguide/nativeBinaries.html" title="Building native binaries"><br /></a></p> \r\n<p>There is a support for several languages like C, C++, Assembly, Windows resources, ...</p> \r\n<p>We will focus on C here, as the language differences are not the point of our issue.</p> \r\n<h3>C builds with Gradle</h3> \r\n<p>Applying the &quot;c&quot; Gradle plugin with a simple setting of source codes located in <code>src/main/c</code> and <code>src/main/c/headers</code> in the project folder:</p> \r\n<pre class="brush: groovy">apply plugin: ''c''\r\n\r\nexecutables {\r\n&nbsp; main { }\r\n}\r\n\r\nsources {\r\n&nbsp; main {\r\n&nbsp;&nbsp;&nbsp; c {\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; source { \r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; srcDir "src/main/c" \r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; include "**/*.c" \r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; exportedHeaders { \r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; srcDir "src/main/c/headers" \r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; include "**/*.h" \r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }\r\n&nbsp;&nbsp;&nbsp; }\r\n&nbsp; }\r\n}</pre> \r\n<p> This script will simply compile the sources in the source path and put the result (.exe file) into <code>build/binaries/mainExecutable</code> folder.</p> \r\n<p>More details can be found in the documentation (mentioned above).</p> \r\n<h2>Publish non-java resources into a Maven2 repository</h2> \r\n<p>For publishing we need to have an access to a Maven2 repository, for instance <a href="http://www.sonatype.org/nexus" target="_blank" title="Nexus server">the Nexus server from Sonatype</a>.</p> \r\n<p>The goal here is to <strong>version the binaries in the repository</strong>, and what''s more - we would like to make <strong>different variants of binaries</strong> (for instance each variant for a different platform).</p> \r\n<p>Using the Gradle <a title="Maven Publishing plugin" target="_blank" href="https://gradle.org/docs/current/userguide/publishing_maven.html">Maven Publishing plugin</a> is a pretty straightforward way to do this:</p> \r\n<pre class="brush: groovy">apply plugin: ''maven-publish''\r\n\r\ngroup = ''cz.net21.ttulka''\r\nversion = ''0.1''\r\n\r\ntask myZip(type: Zip) { \r\n&nbsp; destinationDir = file(''dist'') \r\n&nbsp; archiveName ''myC.zip'' \r\n&nbsp; from ''build/binaries/mainExecutable'' \r\n}\r\n\r\npublishing {\r\n&nbsp; publications {\r\n&nbsp;&nbsp;&nbsp; myPublicationName(MavenPublication) {\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; artifact (myZip) {\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; classifier = ''win32''\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }&nbsp;&nbsp;&nbsp; \r\n&nbsp;&nbsp;&nbsp; }\r\n&nbsp; }\r\n}\r\n\r\nrepositories {\r\n&nbsp; maven {\r\n&nbsp;&nbsp;&nbsp; credentials { \r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; username ''xxx'' \r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; password ''xyz'' \r\n&nbsp;&nbsp;&nbsp; }\r\n&nbsp;&nbsp;&nbsp; url ''http://localhost:8081/nexus/content/repositories/MyMavenRep1/''\r\n&nbsp; }\r\n}\r\n</pre> \r\n<p>Don''t forget to set the project name in the <code>settings.gradle</code> configuration file, for instance:</p> \r\n<pre class="brush: groovy">rootProject.name = ''my-project-with-native-binaries''</pre> \r\n<p>In the example snippet we have used the <code>Zip </code>Gradle task to archive the binaries into a zip file, then we have used the archive as the input for the Maven publication and finally added the classifier (<code>classifier = ''win32''</code>) to annotate this build variant as a Win32 platform-oriented. </p> \r\n<h2>Load the binaries as a dependency in an independent project</h2> \r\n<p>As far as we have compiled the sources and put the binaries into the repository, we want to deal with them from another project (or a different module).</p> \r\n<p> To distinguish the binary dependencies from the others, we can define a new Gradle configuration:</p> \r\n<pre class="brush: groovy">configurations {\r\n&nbsp; binaries {}\r\n}</pre> \r\n<p>Dependencies are then marked by this configuration flag, don''t forget that we used the zip archive and the classifier:</p> \r\n<pre class="brush: groovy">dependencies { \r\n&nbsp; binaries ''cz.net21.ttulka:my-project-with-native-binaries:0.1:win32@zip'' \r\n}</pre> \r\n<p>That''s it, now we can do whatever we want:</p> \r\n<pre class="brush: groovy">// copy the dependencies into a ''deps'' folder\r\ntask getDeps(type: Copy) { \r\n&nbsp; from configurations.binaries \r\n&nbsp; into ''deps/'' \r\n}</pre> \r\n<p> <br /></p> \r\n<p>Hopefully this article gave you a little insight how to deal with different types of resources in one unified way with Gradle, and help you optimize your DevOps processes!<br /></p> \r\n<p> <br /></p>', 1, 'admin', 1, 'false', 'true', 1434608205, 'false'),
(11, 'XSLT: Multiple XML Inputs', 1434550560, 'How to create one result document from more sources? It''s easy with XSLT!', 0, 0, '<p>Let''s imagine, that we have two (or more) XML documents as the data sources. In our example we will use a list of products as the first document and a list of attributes (colors, in this case) as the second document. Each product as a ID of a color as its attribute, the name of the color is in the list of colors. We would like to show all the products with their color names in a nice HTML table.</p> \r\n<h2>Data sources </h2> \r\n<p><em><strong>products.xml</strong></em></p> \r\n<pre class="brush: xml">&lt;?xml version="1.0" encoding="UTF-8"?&gt;\r\n&lt;products&gt;\r\n&nbsp; &lt;product id="1001" color="A1"&gt;\r\n&nbsp;&nbsp;&nbsp; &lt;name&gt;Strawberry&lt;/name&gt;\r\n&nbsp; &lt;/product&gt;\r\n&nbsp; &lt;product id="1002" color="A2"&gt;\r\n&nbsp;&nbsp;&nbsp; &lt;name&gt;Blueberry&lt;/name&gt;\r\n&nbsp; &lt;/product&gt;\r\n&nbsp; &lt;product id="1003" color="A2"&gt;\r\n&nbsp;&nbsp;&nbsp; &lt;name&gt;Plum&lt;/name&gt;\r\n&nbsp; &lt;/product&gt;\r\n&nbsp; &lt;product id="1004" color="A3"&gt;\r\n&nbsp;&nbsp;&nbsp; &lt;name&gt;Green Apple&lt;/name&gt;\r\n&nbsp; &lt;/product&gt;\r\n&lt;/products&gt;</pre> \r\n<p><em><strong>colors.xml</strong></em></p> \r\n<pre class="brush: xml">&lt;?xml version="1.0" encoding="UTF-8"?&gt;\r\n&lt;colors&gt;\r\n&nbsp; &lt;color id="A1"&gt;\r\n&nbsp;&nbsp;&nbsp; &lt;name&gt;Red&lt;/name&gt;\r\n&nbsp; &lt;/color&gt;\r\n&nbsp; &lt;color id="A2"&gt;\r\n&nbsp;&nbsp;&nbsp; &lt;name&gt;Blue&lt;/name&gt;\r\n&nbsp; &lt;/color&gt;\r\n&nbsp; &lt;color id="A3"&gt;\r\n&nbsp;&nbsp;&nbsp; &lt;name&gt;Green&lt;/name&gt;\r\n&nbsp; &lt;/color&gt;\r\n&lt;/colors&gt;</pre> \r\n<h2>XSLT Transformation</h2> \r\n<p><em><strong>transformation.xsl</strong></em></p> \r\n<pre class="brush: xml">&lt;?xml version="1.0" encoding="UTF-8"?&gt;\r\n&lt;xsl:stylesheet version="1.0" xmlns:xsl="http://www.w3.org/1999/XSL/Transform" exclude-result-prefixes="xsl"&gt;&nbsp; \r\n \r\n&nbsp; &lt;xsl:param name="colorsFile"/&gt;\r\n&nbsp; &lt;xsl:variable name="colorsDoc" select="document($colorsFile)"/&gt;\r\n \r\n&nbsp; &lt;xsl:template match="/"&gt;\r\n&nbsp;&nbsp;&nbsp; &lt;html&gt;\r\n&nbsp;&nbsp;&nbsp; &lt;body&gt;\r\n&nbsp;&nbsp;&nbsp; &lt;table border="1" cellpadding="10"&gt;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;tr bgcolor="#accfff"&gt;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;th&gt;Name&lt;/th&gt;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;th&gt;Color&lt;/th&gt;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;/tr&gt;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;xsl:for-each select="products"&gt;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;xsl:apply-templates select="product"/&gt;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;/xsl:for-each&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \r\n&nbsp;&nbsp;&nbsp; &lt;/table&gt;\r\n&nbsp;&nbsp;&nbsp; &lt;/body&gt;\r\n&nbsp;&nbsp;&nbsp; &lt;/html&gt;\r\n&nbsp; &lt;/xsl:template&gt;\r\n \r\n&nbsp; &lt;xsl:template match="product"&gt;\r\n&nbsp;&nbsp;&nbsp; &lt;tr&gt;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;td&gt;&lt;xsl:value-of select="name"/&gt;&lt;/td&gt;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;td&gt;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;xsl:variable name="colorId" select="@color"/&gt;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;xsl:value-of select="$colorsDoc/colors/color[@id=$colorId]/name"/&gt;\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;/td&gt;\r\n&nbsp;&nbsp;&nbsp; &lt;/tr&gt;\r\n&nbsp; &lt;/xsl:template&gt;\r\n \r\n&lt;/xsl:stylesheet&gt;</pre> \r\n<p>The parameter <code>colorsFile </code>takes its value from the processor (below), could be set to a file path like:</p> \r\n<pre class="brush: xml">&lt;xsl:param name="colorsFile" select="''../input/colors.xml''" /&gt;</pre> \r\n<h2>Java processor</h2> \r\n<p>In this article we''re using a Java processor, the solution can be but very easily converted to the pure XSLT solution and another processor (for instance an internet browser) can be used.</p> \r\n<p>All the classes are from the sub-packages of the package <code>javax.xml</code>. </p> \r\n<pre class="brush: java">final DocumentBuilderFactory factory = DocumentBuilderFactory.newInstance();\r\n\r\nfinal DocumentBuilder builder = factory.newDocumentBuilder();\r\nfinal Document document = builder.parse("products.xml");\r\n\r\nfinal TransformerFactory tFactory = TransformerFactory.newInstance();\r\nfinal Transformer transformer = tFactory.newTransformer(new StreamSource("transformation.xsl"));\r\n \r\ntransformer.setParameter("colorsFile", "colors.xml");\r\n\r\ntransformer.transform(new DOMSource(document), new StreamResult("output.html"));</pre> \r\n<p>And that''s exactly what we wanted!</p> \r\n<p><strong><em>output.html</em></strong></p> \r\n<p> \r\n<table cellpadding="3" border="1"> \r\n<tbody> \r\n<tr bgcolor="#accfff"> \r\n<th>Name</th> \r\n<th>Color</th> \r\n</tr> \r\n<tr> \r\n<td>Strawberry</td> \r\n<td>Red</td> \r\n</tr> \r\n<tr> \r\n<td>Blueberry</td> \r\n<td>Blue</td> \r\n</tr> \r\n<tr> \r\n<td>Plum</td> \r\n<td>Blue</td> \r\n</tr> \r\n<tr> \r\n<td>Green Apple</td> \r\n<td>Green</td> \r\n</tr> \r\n</tbody> \r\n</table> \r\n</p> ', 1, 'admin', 1, 'false', 'true', 1434541037, 'true'),
(12, 'JavaFX 2: Simple Graphs', 1452103140, '<p>It''s pretty easy to create a graphs in the JavaFX application, because there are a lot of neat libraries on the Internet.</p> \r\n<p>Trouble comes when you need to stick with JavaFX 2.</p> \r\n<p> This very very simple library will let you to create simple graphs like this one:</p> \r\n<p><img alt="Simple Graphs - preview" src="/storage/simple-graphs-preview.png" /><br /></p>', 0, 0, '<p>Let''s consider a simple JavaFX 2 application:</p> \r\n<pre class="brush: java">public class HelloWorld extends Application {\r\n\r\n&nbsp;&nbsp;&nbsp; private void init(Stage primaryStage) {\r\n&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; // TODO\r\n&nbsp;&nbsp;&nbsp; }\r\n\r\n&nbsp;&nbsp;&nbsp; @Override\r\n&nbsp;&nbsp;&nbsp; public void start(Stage primaryStage) throws Exception {\r\n&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; init(primaryStage);\r\n&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; primaryStage.show();\r\n&nbsp;&nbsp;&nbsp; }\r\n\r\n&nbsp;&nbsp;&nbsp; public static void main(String[] args) {\r\n&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; launch(args);\r\n&nbsp;&nbsp;&nbsp; }\r\n} </pre> \r\n<p>We will fill the init method to set up the scene showing the graph nodes from the picture above.</p> \r\n<p>First, we need the parent node:</p> \r\n<p> </p> \r\n<pre class="brush: java">final BoxNode parent = new BoxNode("Parent", 250, 0);</pre> \r\n<p> </p> \r\n<p>Then the children nodes:</p> \r\n<pre class="brush: java">final BoxNode myNode1 = new BoxNode("MyNode 1", 0, 200);\r\nfinal BoxNode myNode2 = new BoxNode("MyNode 2", 300, 400);</pre> \r\n<p>Second, we connect the nodes with each other (the parent to children, the first child to the second one and also with itself):</p> \r\n<pre class="brush: java">parent.addArrowTo(myNode1, "arrow 1");\r\nparent.addArrowTo(myNode2, "arrow 2");\r\nmyNode1.addArrowTo(myNode2, "arrow 3");\r\nmyNode1.addArrowTo(myNode1, "arrow round");<p></p></pre> \r\n<p>Finally, we all the nodes to a group (<code>javafx.scene.Group</code>) and the group to the scene:</p> \r\n<pre class="brush: java">final Group root = new Group();\r\nprimaryStage.setScene(new Scene(root));\r\nroot.getChildren().addAll(parent, myNode1, myNode2);</pre> \r\n<p>That''s all!</p> \r\n<p>The library is available as a <a href="/storage/simple-graphs-1.0.0.jar">JAR</a> or <a href="https://github.com/ttulka/javafx2-simple-graphs">source archive</a>.</p> ', 1, 'admin', 1, 'false', 'true', 1493110418, 'false'),
(13, 'SQL NULL: tricky equality', 1447268880, '<p>Especially when creating a SQL quary from the code, to make the life easier we are using constructions like this:</p> \r\n<pre class="brush: sql">SELECT &#42; FROM test WHERE 1=1</pre> \r\n<p>Then we can easily add a new condition just joined with AND (or OR):</p> \r\n<pre class="brush: sql">SELECT &#42; FROM test WHERE 1=1 AND ...</pre> \r\n<p>and it will be working perfectly fine.</p> \r\n<p>Working with constans can''t bring any problem, but it''s getting tricky when we''re working with variables (columns) like this:</p> \r\n<pre class="brush: sql">SELECT &#42; FROM test WHERE num=num</pre> \r\n<p>The problem is the special <em>value</em> NULL. <br /></p>', 0, 0, '<p>Why do we actually need <code>num = num</code> instead of <code>1 = 1</code>? Well it could be handy when we have a condition inside the query:</p> \r\n<pre class="brush: sql">SELECT &#42; FROM test WHERE val =&nbsp; IF(num &gt; 2, 3, val)</pre> \r\n<p>By this query we say: give me all the data in the <code>test</code> table where the value of the <code>val</code> column equals 3, in case that value of the <code>num</code> column is greater then 2, otherwise we don''t care of the value of the <code>val</code> at all.</p> \r\n<p><em>Comment: the control flow function <code>IF</code> is RDBMS-related (<code>IF</code> is available in MySQL).</em></p> \r\n<p>In case when the val column contains NULL values, we can get unexpected behaviour (unexpected for us, but logic as we will see next).</p> \r\n<h2>Working with the NULL values</h2> \r\n<p>Let''s consider a simple table:</p> \r\n<pre class="brush: sql">CREATE TABLE test (num INT, str VARCHAR(100), str2 VARCHAR(100));</pre> \r\n<p>with different values containg NULL values:</p> \r\n<pre class="brush: sql">INSERT INTO test VALUES (1, ''abc'', ''abc''), (2, NULL, NULL), (NULL, ''3'', NULL), (NULL, NULL, NULL);</pre> \r\n<p>The table looks like following:</p> \r\n<p> \r\n<table cellspacing="1" cellpadding="1" border="1" style="width: 300px;"> \r\n<tbody> \r\n<tr> \r\n<td valign="top"><strong>num<br /></strong></td> \r\n<td valign="top"><strong>str<br /></strong></td> \r\n<td valign="top"><strong>str2<br /></strong></td> \r\n</tr> \r\n<tr> \r\n<td style="width: 33%;">&nbsp;1</td> \r\n<td style="width: 33%;">&nbsp;abc</td> \r\n<td style="width: 33%;">&nbsp;abc</td> \r\n</tr> \r\n<tr> \r\n<td style="width: 33%;">&nbsp;2</td> \r\n<td style="width: 33%;">  NULL</td> \r\n<td style="width: 33%;">  NULL</td> \r\n</tr> \r\n<tr> \r\n<td style="width: 33%;">&nbsp;NULL</td> \r\n<td style="width: 33%;">&nbsp;3</td> \r\n<td style="width: 33%;">  NULL</td> \r\n</tr> \r\n<tr> \r\n<td style="width: 33%;">&nbsp;NULL <br /></td> \r\n<td style="width: 33%;">  NULL</td> \r\n<td style="width: 33%;">  NULL</td> \r\n</tr> \r\n</tbody> \r\n</table><br /> \r\n</p> \r\n<p>Executing this query:</p> \r\n<pre class="brush: sql">SELECT &#42; FROM test WHERE num = num;</pre> \r\n<p>will return</p> \r\n<p> \r\n<table cellspacing="1" cellpadding="1" border="1" style="width: 300px;"> \r\n<tbody> \r\n<tr> \r\n<td valign="top"><strong>num<br /></strong></td> \r\n<td valign="top"><strong>str<br /></strong></td> \r\n<td valign="top"><strong>str2<br /></strong></td> \r\n</tr> \r\n<tr> \r\n<td style="width: 33%;">&nbsp;1</td> \r\n<td style="width: 33%;">abc <br /></td> \r\n<td style="width: 33%;">&nbsp;abc</td> \r\n</tr> \r\n<tr> \r\n<td style="width: 33%;">&nbsp;2</td> \r\n<td style="width: 33%;">&nbsp;NULL</td> \r\n<td style="width: 33%;">&nbsp;NULL</td> \r\n</tr> \r\n</tbody> \r\n</table> \r\n</p> \r\n<p>But it''s very suspicious, because we have added four not two rows.</p> \r\n<p>NULL values can''t be compared by the <code>=</code> equality operator. The same behaviour we can see in this example:</p> \r\n<pre class="brush: sql">SELECT &#42; FROM test WHERE str = str2;</pre> \r\n<table cellspacing="1" cellpadding="1" border="1" style="width: 300px;"> \r\n<tbody> \r\n<tr> \r\n<td valign="top"><strong>num<br /></strong></td> \r\n<td valign="top"><strong>str<br /></strong></td> \r\n<td valign="top"><strong>str2<br /></strong></td> \r\n</tr> \r\n<tr> \r\n<td style="width: 33%;">&nbsp;1</td> \r\n<td style="width: 33%;">abc <br /></td> \r\n<td style="width: 33%;">&nbsp;abc</td> \r\n</tr> \r\n</tbody> \r\n</table> \r\n<p>Instead of <code>=</code> operator we need to use <code>IS</code> operator:</p> \r\n<pre class="brush: sql">SELECT &#42; FROM test WHERE num IS num;</pre> \r\n<p>will return the whole table.</p> \r\n<pre class="brush: sql">SELECT &#42; FROM test WHERE str IS str2;</pre> \r\n<table cellspacing="1" cellpadding="1" border="1" style="width: 300px;"> \r\n<tbody> \r\n<tr> \r\n<td valign="top"><strong>num<br /></strong></td> \r\n<td valign="top"><strong>str<br /></strong></td> \r\n<td valign="top"><strong>str2<br /></strong></td> \r\n</tr> \r\n<tr> \r\n<td style="width: 33%;">&nbsp;1</td> \r\n<td style="width: 33%;">&nbsp;abc</td> \r\n<td style="width: 33%;">&nbsp;abc</td> \r\n</tr> \r\n<tr> \r\n<td style="width: 33%;">&nbsp;2</td> \r\n<td style="width: 33%;">  NULL</td> \r\n<td style="width: 33%;">  NULL</td> \r\n</tr> \r\n<tr> \r\n<td style="width: 33%;">&nbsp;NULL <br /></td> \r\n<td style="width: 33%;">  NULL</td> \r\n<td style="width: 33%;">  NULL</td> \r\n</tr> \r\n</tbody> \r\n</table> \r\n<p>&nbsp;</p> \r\n<p>NULL is an unknown value. As <code>NULL != NULL</code>, we can''t do <code>num = NULL</code> nor <code>num != NULL</code> to get the expected results.</p> \r\n<p><strong>Always use <code>IS</code> (<code>IS NOT</code>) operators while working with NULL values.</strong><br /></p> ', 1, 'admin', 1, 'false', 'true', 1452251173, 'false'),
(14, 'JavaScript Menu Plugin for Mobile Web Applications', 1454521380, '<p>It''s not easy to put all the navigation information in the small space of a website for mobile apps, especially when you have a lot of categories, departments etc...</p> \r\n<p>This JavaScript (<a href="https://jquery.com/download" target="_blank">jQuery</a>) based dynamic menu could help you with the challenge.</p> \r\n<p> It''s small, compact, customizable, easy to deploy and free to use! <br /></p>', 0, 0, '<h2>Live Example</h2> \r\n<p>Example page optimized for the mobile devices with the menu is <a target="_blank" href="http://www.net21.cz/mobile-menu">here</a>.</p> \r\n<p> \r\n<table cellspacing="0" cellpadding="0" border="0" style="width: 100%;"> \r\n<tbody> \r\n<tr> \r\n<td style="width: 33%;"> <img border="1" alt="Menu for Mobile Web Apps #1" src="/storage/mobilMenu_screenshot_1.png" /></td> \r\n<td style="width: 33%;"> <img border="1" alt="Menu for Mobile Web Apps #2" src="/storage/mobilMenu_screenshot_2.png" /></td> \r\n</tr> \r\n<tr> \r\n<td valign="top"><br /></td> \r\n<td valign="top"><br /></td> \r\n</tr> \r\n</tbody> \r\n</table><img border="1" src="/storage/mobilMenu_screenshot_3.png" alt="Menu for Mobile Web Apps #3" /><br /> \r\n</p> \r\n<h2>Get started</h2> \r\n<p>Dowload the <a href="http://www.net21.cz/mobile-menu/mobileMenu.js" target="_blank">Menu jQuery Plugin</a> (<a href="http://www.net21.cz/mobile-menu/mobileMenu.min.js" target="_blank">compressed</a>) or the <a href="http://www.net21.cz/mobile-menu/mobileMenu.zip">this whole example</a>.</p> \r\n<p>To deploy the menu on your website you need to include jQuery and the plugin scripts:</p> \r\n<pre class="brush: javascript">&lt;script type="text/javascript" src="http://code.jquery.com/jquery-1.12.0.min.js"&gt;&lt;/script&gt;\r\n&lt;script type="text/javascript" src="mobileMenu.min.js"&gt;&lt;/script&gt;</pre> \r\n<p>Then to connect a start point on the page (typically a button or a text block) with the plugin:</p> \r\n<pre class="brush: javascript">&lt;script type="text/javascript"&gt;\r\n$(document).ready(function() {\r\n&nbsp; $("#mobileMenuStartButton").mobileMenu("url/to/data.json");\r\n});\r\n&lt;/script&gt;</pre> \r\n<h3>Data structure <br /></h3> \r\n<p>As the first parameter of the <code>mobileMenu</code> plugin you have to set an URL to a JSON file containing the menu data in the structure like following:</p> \r\n<pre>{\r\n&nbsp; "menu" : [\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; {"name" : "Text 1", "menu" : [\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; {"name" : "Text 1.1", "link" : "link1.1"},\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; {"name" : "Text 1.2", "menu" : [\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; {"name" : "Text 1.2.1", "link" : "link1.2.1"},\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; {"name" : "Text 1.2.2", "link" : "link1.2.2"}\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ]},\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; {"name" : "Text 1.3", "link" : "link1.3"}\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ]},\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; {"name" : "Text 2", "link" : "link2"},\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; {"name" : "Text 3", "menu" : [\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; {"name" : "Text 3.1", "link" : "link3.1"},\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; {"name" : "Text 3.2", "link" : "link3.2"}\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ]} \r\n&nbsp; ]\r\n}</pre> \r\n<p>As showed in the example data above, the structure starts with the <code>menu</code> record with a value of a list of menu items. Every menu item has a name and a link or a sub-menu of the same structure recursively.</p> \r\n<h3>Custom styling</h3> \r\n<p>The menu component contains several CSS classes which can be styled by the user.</p> \r\n<p> The easiest way is to download the <a href="view-source:http://www.net21.cz/mobile-menu/mobileMenu.css" target="_blank">example CSS style sheet</a> and adjust it.</p> \r\n<p>The important CSS are following:</p> \r\n<ul> \r\n<li><strong><code>mobileMenuButton </code></strong><br />The starter element will get this class additionaly. Together with the class <code>expanded</code> indicates the opened menu.<br /> <br /></li> \r\n<li><strong><code>mobileMenuMain</code></strong><br />The wrapper for the whole menu context. It''s important to set atributte <code>position:absolute</code> for this to make the menu overflowing the context of the page below.<br /> <br /></li> \r\n<li><strong><code>mobileMenuBlock</code></strong><br />The container for the menu items context.<br /> <br /></li> \r\n<li><strong><code>mobileMenuItem</code></strong><br />The class for the menu items, has following additional classes:<br /> <br /></li> \r\n<ul> \r\n<li><code>title</code><br />The menu item showing the name of the currently expanded class.<br /> <br /></li> \r\n<li><code>first</code><br />The first item in the first menu list (without title item).<br /> <br /></li> \r\n<li><code>link</code><br />Indicates that the menu item has no sub-menu but it''s only a simple link.<br /></li> \r\n</ul> \r\n</ul> \r\n<p> <br /></p>', 1, 'admin', 1, 'false', 'true', 1454590208, 'false'),
(15, 'Upgrade Java SE 7 to Java SE 8 OCP Programmer - Summary', 1468343940, '<p>Maybe you are updating your Oracle Professional Certification from Java 7 to Java 8 as I just did a few days ago.</p> \r\n<p>This summary contains everything important to learn to achive this goal.</p> \r\n<p>You can <a href="/storage/Upgrade_Java_SE_7_to_Java_SE_8_OCP_Programmer_-_Summary.pdf">download this summary</a> as a PDF document.</p> \r\n<p>I wish you good luck!</p>', 0, 0, '<p> </p> \r\n<p> <br /></p> \r\n<p>Of course that this summary it''s not enought, if you are beginning to learn all the new stuff in the Java 8.</p> \r\n<p>For deeper study I can recoment you a few things:</p> \r\n<ul> \r\n<li> OCP: Oracle Certified Professional Java SE 8 Programmer II Study Guide: Exam 1Z0-809<br /><a target="_blank" href="https://www.amazon.de/OCP-Certified-Professional-Programmer-1Z0-809/dp/1119067901">https://www.amazon.de/OCP-Certified-Professional-Programmer-1Z0-809/dp/1119067901<br /></a> <br /></li> \r\n<li>Mock Exams from Enthuware<br /><a target="_blank" href="http://enthuware.com/index.php/mock-exams/oracle-certified-professional/ocpjp-8-1z0-810-questions">http://enthuware.com/index.php/mock-exams/oracle-certified-professional/ocpjp-8-1z0-810-questions<br /></a><br /></li> \r\n<li>Pu-erh Dark Tea - good for the memory and whole body fitness<br /><a href="https://en.wikipedia.org/wiki/Pu-erh_tea">https://en.wikipedia.org/wiki/Pu-erh_tea</a> <br /></li> \r\n</ul> \r\n<p> </p> \r\n<p><br />If you find some mistakes or have some comments to the summary, please feel free to discuss!</p> \r\n<p><br /></p>', 1, 'admin', 1, 'false', '', 1484154684, 'false'),
(16, 'Pre-processing Spring Beans of Prototype Scope', 1470585900, '<p>Sometimes you have a type of bean in the <strong>Spring framework</strong> which you want to create by every asking for it - in the <strong>scope prototype</strong>.</p> \r\n<p>Pre-processing of those <strong>prototypes</strong> only one and in the beginning &nbsp;could be tricky.</p> \r\n<p>Let''s consider an annotation which tell you someting about the setting of the beans. For example which alternative names is your GUI box connected to. You want to create a proper bean based on its alternative name of course without featching all the beans every time and looking for the right one (of course you can do it by lazy caching, but that''s still not the best solution). Or what if you want to get a list of all the alternative names of course <u>withou the need to create the beans</u> first?</p> \r\n<p>This short article will tell you how to do it.&nbsp;</p>', 0, 0, '<p>Consider the following annotations:</p> \r\n<pre class="brush: java">@Target(ElementType.TYPE)\r\n@Retention(RetentionPolicy.RUNTIME)\r\n@Documented\r\n@Component\r\n@Scope(value = SCOPE_PROTOTYPE)\r\npublic @interface Box {\r\n}</pre> \r\n<pre class="brush: java">@Target(ElementType.TYPE)\r\n@Retention(RetentionPolicy.RUNTIME)\r\n@Documented\r\n@Component\r\n@Scope(value = SCOPE_PROTOTYPE)\r\npublic @interface AlternativeNames {\r\n&nbsp; &nbsp; AlternativeName[] value();\r\n}</pre> \r\n<pre class="brush: java">@Target(ElementType.TYPE)\r\n@Retention(RetentionPolicy.RUNTIME)\r\n@Repeatable(AlternativeNames.class)\r\n@Documented\r\npublic @interface AlternativeName {\r\n&nbsp; &nbsp; String value();\r\n}</pre> \r\n<p>Then you have defined the base annotation <code>@Box </code>which tell the Spring framework that this class is a bean, <code>@AlternativeNames</code> which allows you to put the <code>@AlternativeName</code> annotation more times (<em>Repeating Annotations</em>).</p> \r\n<p>Based on the definitions you can create a class like this:</p> \r\n<pre class="brush: java">@Box\r\n@AlternativeName("my-box")\r\n@AlternativeName("box-of-mine")\r\npublic class MyBox {\r\n&nbsp; &nbsp; // ... some code goes here\r\n}</pre> \r\n<p>Now it''s time for the pre-processor:</p> \r\n<pre class="brush: java">@Component\r\npublic class BoxContextListener implements ApplicationListener&lt;ContextRefreshedEvent&gt; {\r\n\r\n&nbsp; &nbsp; private final ConfigurableListableBeanFactory factory;\r\n\r\n&nbsp; &nbsp; @Autowired\r\n&nbsp; &nbsp; public BoxContextListener(ConfigurableListableBeanFactory factory) {\r\n&nbsp; &nbsp; &nbsp; &nbsp; this.factory = factory;\r\n&nbsp; &nbsp; }\r\n\r\n&nbsp; &nbsp; @Override\r\n&nbsp; &nbsp; public void onApplicationEvent(ContextRefreshedEvent event) {\r\n&nbsp; &nbsp; &nbsp; &nbsp; String[] beanDefinitionNames = event.getApplicationContext().getBeanDefinitionNames();\r\n&nbsp; &nbsp; &nbsp; &nbsp; for (String beanDefinitionName : beanDefinitionNames) {\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; try {\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; BeanDefinition beanDefinition = factory.getBeanDefinition(beanDefinitionName);\r\n\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; String originalClassName = beanDefinition.getBeanClassName();\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if (originalClassName != null &amp;&amp; !originalClassName.isEmpty()) {\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; try {\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; final Class&lt;?&gt; originalClass = Class.forName(originalClassName);\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if (originalClass.isAnnotationPresent(Box.class)) {\r\n\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if (originalClass.isAnnotationPresent(AlternativeNames.class) \r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; || originalClass.isAnnotationPresent(AlternativeName.class)) { \r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; AlternativeName[] mappings = originalClass.getAnnotationsByType(AlternativeName.class);\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; for (AlternativeName alternativeMapping : mappings) {\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; String alternativeName = alternativeMapping.value();\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; // do someting with the alternative name ...\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; } catch (ClassNotFoundException e) {\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; // ...\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; } catch (BeansException e) {\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; // ...\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\r\n&nbsp; &nbsp; &nbsp; &nbsp; }\r\n&nbsp; &nbsp; }\r\n}</pre> \r\n<p>That''s the way how to get values from the annotation of the Spring prototype beans in the pre-processing.</p> \r\n<p>I hope it helped!</p>', 1, 'admin', 1, 'false', 'true', 1473231115, 'true'),
(17, 'Resolving a Generic Type with the Spring Framework', 1472312460, '<div>In the case of generic beans sometimes you need to get the <strong>generic type value</strong> for some specific reasons. A typical example could be parsing some data into the type.</div> \r\n<div><br /></div> \r\n<div>Following code shows you how to parse a JSON data into the specific structure defined by a generic class.</div>', 0, 0, '<pre class="brush: java">import com.fasterxml.jackson.databind.ObjectMapper;\r\nimport org.springframework.core.GenericTypeResolver;\r\n// ...\r\n\r\n@Component \r\npublic class MyDataBean&lt;T extends MySuperData&gt; {\r\n\r\n    private final Class&lt;T&gt; genericType;\r\n\r\n    private final ObjectMapper objectMapper = new ObjectMapper();\r\n\r\n    public MyDataBean() {\r\n        this.genericType = (Class&lt;T&gt;) GenericTypeResolver.resolveTypeArgument(getClass(), MyDataBean.class);\r\n    }\r\n\r\n    public T parseData(String jsonData) {\r\n    	return objectMapper.readValue(jsonData, this.genericType);\r\n    }\r\n}\r\n</pre> \r\n<div> \r\n<p>Spring tool <code>GenericTypeResolver</code> will set the <code>genericType</code> class value which is later used as the parameter for the JSON parsing.</span></p> \r\n<p>It''s easy!</p> \r\n<p> </p> \r\n</div>', 1, 'admin', 1, 'false', 'true', 1473245548, 'false');
INSERT INTO `serendipity_entries` (`id`, `title`, `timestamp`, `body`, `comments`, `trackbacks`, `extended`, `exflag`, `author`, `authorid`, `isdraft`, `allow_comments`, `last_modified`, `moderate_comments`) VALUES
(18, 'Ant script to copy a snippet of a XML to another XML', 1475854620, '<p>I know, Ant is not the most modern technology, but there are still Ant-based systems we have to maintenance.</p> \r\n<p>Sometimes we need to cut or copy a piece of a XML document and save it to another.</p> \r\n<p>We will use <a href="http://www.oopsconsultancy.com/software/xmltask/" target="_blank">XmlTask</a> library by OOPS Consultancy to achive this goal.&nbsp;</p>', 0, 0, '<p>First of all, we have to define an Ant task:</p> \r\n<p>&lt;taskdef name=&quot;xmltask&quot; classname=&quot;com.oopsconsultancy.xmltask.ant.XmlTask&quot; /&gt;</p> \r\n<p>Don''t forget to put the downloaded library into the Ant libs folder or onto the classpath:</p> \r\n<p><code>ant ... -lib xmltask.jar</code></p> \r\n<p>Let''s consider two XML configuration files:</p> \r\n<p><code><strong>conf.xml</strong></code></p> \r\n<pre class="brush: xml">&lt;configuration&gt;\r\n&nbsp; &lt;applications&gt;\r\n&nbsp; &nbsp; &lt;app id="MyCoolApp" /&gt;\r\n&nbsp; &nbsp; &lt;app id="AnotherApp" /&gt;\r\n&nbsp; &lt;/applications&gt;\r\n&lt;/configuration&gt;&nbsp;</pre> \r\n<p><code><strong>settings.xml</strong></code></p> \r\n<pre class="brush: xml">&lt;settings&gt;\r\n...\r\n&nbsp; &lt;apps&gt;\r\n&nbsp; &nbsp; &lt;app id="thisAppWasAlreadyHere" /&gt;\r\n&nbsp; &lt;/apps&gt;\r\n&lt;/settings&gt;</pre> \r\n<p>And we want to merge those documents in the way we get this content of the <code>settings.xml</code>:</p> \r\n<pre class="brush: xml">&lt;settings&gt;\r\n&nbsp; ...\r\n&nbsp; &lt;apps&gt;\r\n&nbsp; &nbsp; &lt;app id="thisAppWasAlreadyHere" /&gt;\r\n&nbsp; &nbsp; &lt;app id="MyCoolApp" /&gt;\r\n&nbsp; &nbsp; &lt;app id="AnotherApp" /&gt;\r\n&nbsp; &lt;/apps&gt;\r\n&lt;/settings&gt;</pre> \r\n<p>We can use the xmltask''s command call to get a path-defined snippet into the buffer and append it with the command insert.</p> \r\n<p>Here is the whole code:&nbsp;</p> \r\n<pre class="brush: xml">&lt;xmltask source="conf.xml"&gt;\r\n&nbsp; &lt;call path="configuration/applications/app" buffer="apps_storedXml"&gt;\r\n&nbsp; &nbsp; &lt;param name="id" path="@id" /&gt;\r\n&nbsp; &nbsp; &lt;actions&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &lt;echo&gt;Merge the app id="@{id}"&lt;/echo&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &lt;xmltask source="settings.xml" dest="settings.xml"&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;insert path="settings/apps" buffer="apps_storedXml" /&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &lt;/xmltask&gt;\r\n&nbsp; &nbsp; &lt;/actions&gt;&nbsp;\r\n&nbsp; &lt;/call&gt;\r\n&lt;/xmltask&gt;</pre> \r\n<p>That''s it!</p> \r\n<p> </p>', 1, 'admin', 1, 'false', 'true', 1478502881, 'false'),
(19, 'Ant Sequential Tasks', 1479228600, '<p>This article will show you how to implement an Ant task which consume a sequence of sub-task and call them with a parameter of the result from the execution.</p> \r\n<p>As an example we can consider a task <strong>taking a path to a directory</strong> as a parameter, <strong>fetching files</strong> in the directory and <strong>running a sequence of sub-task for each file</strong>.&nbsp;</p> \r\n<p>The task will be implemented as a <strong>Java library</strong>.&nbsp;</p>', 0, 0, '<p>Considering the example, we will have in our Ant script something like:</p> \r\n<pre>&lt;fetch-files path="/Windows" suffix=".exe"&gt;\r\n    &lt;sequential&gt;\r\n        &lt;echo&gt;My file print: @{file}&lt;/echo&gt;\r\n\r\n        &lt;antcall target="process-file"&gt;\r\n            &lt;param name="filename" value="@{file}" /&gt;\r\n        &lt;/antcall&gt;\r\n    &lt;/sequential&gt;\r\n&lt;/fetch-files&gt;\r\n</pre> \r\n<p>This should process all the <code>.exe</code> files in the <code>/Windows</code> directory and print the name of the file before processing.&nbsp;</p> \r\n<h2>Implementation in Java&nbsp;</h2> \r\n<p>Let''s create a new Maven project, all we need is a dependency to the Ant API:</p> \r\n<pre class="brush: xml">&lt;dependency&gt;\r\n    &lt;groupId&gt;org.apache.ant&lt;/groupId&gt;\r\n    &lt;artifactId&gt;ant&lt;/artifactId&gt;\r\n    &lt;version&gt;1.9.7&lt;/version&gt;\r\n&lt;/dependency&gt;\r\n</pre> \r\n<h3>Sequential Task&nbsp;</h3> \r\n<p>First of all we will create an abstract class which allows us to put the <code>&lt;sequential&gt;</code> part into the task:</p> \r\n<pre class="brush: java">abstract class SequentialTask extends Task {\r\n\r\n    private MacroDef macroDef;\r\n    private Target owningTarget;\r\n\r\n    abstract String getAttributeName();\r\n\r\n    @Override\r\n    public void setOwningTarget(Target owningTarget) {\r\n        this.owningTarget = owningTarget;\r\n    }\r\n\r\n    public Object createSequential() {\r\n        macroDef = new MacroDef();\r\n        macroDef.setProject(getProject());\r\n\r\n        MacroDef.Attribute attribute = new MacroDef.Attribute();\r\n        attribute.setName(getAttributeName());\r\n        macroDef.addConfiguredAttribute(attribute);\r\n\r\n        return macroDef.createSequential();\r\n    }\r\n\r\n    void executeSequential(String attrValue) {\r\n        MacroInstance instance = new MacroInstance();\r\n        instance.setProject(getProject());\r\n        instance.setOwningTarget(owningTarget);\r\n        instance.setMacroDef(macroDef);\r\n        instance.setDynamicAttribute(getAttributeName(), attrValue);\r\n        instance.execute();\r\n    }\r\n}</pre> \r\n<p>All the task exending the class must define the declared <code>getAttributeName()</code> method which returns the name of the attribute (<code>&quot;file&quot;</code> in our example).</p> \r\n<p>Then we cann call the method <code>executeSequential(String attrValue)</code> for each item in the task result.</p> \r\n<h3>Fetching Files Task&nbsp;</h3> \r\n<p>Our concrete task implementation could look like:</p> \r\n<pre class="brush: java">public class FetchFilesTask extends SequentialTask {\r\n\r\n    private static final String ATTR_NAME = "file";\r\n\r\n    private String path;\r\n    private String suffix;\r\n\r\n    public void setPath(String path) {\r\n        this.path = path;\r\n    }\r\n\r\n    public void setSuffix(String suffix) {\r\n        this.suffix = suffix;\r\n    }\r\n\r\n    @Override\r\n    String getAttributeName() {\r\n        return ATTR_NAME;\r\n    }\r\n\r\n    @Override\r\n    public void execute() { \r\n        if (path == null || path.trim().isEmpty()) {\r\n            throw new BuildException("Parameter ''path'' must be specified.");\r\n        }\r\n\r\n        List&lt;String&gt; filesList = getFilesList(Paths.get(path), suffix);\r\n\r\n        for (String file : filesList) {\r\n            executeSequential(file.toString());\r\n        }\r\n    }\r\n\r\n    List&lt;String&gt; getFilesList(Path sourcePath, String suffix) {\r\n        final List&lt;String&gt; toReturn = new ArrayList&lt;&gt;();\r\n\r\n        try (DirectoryStream&lt;Path&gt; stream = Files.newDirectoryStream(sourcePath)) {\r\n            for (Path file: stream) {\r\n                if (Files.isRegularFile(file)) {\r\n                    if (suffix == null || file.toString().endsWith(suffix)) {\r\n                        toReturn.add(file.toString());\r\n                    }\r\n                }\r\n            }\r\n        }\r\n        catch (IOException | DirectoryIteratorException e) {\r\n            throw new BuildException("Error by reading ''" + sourcePath + "''.", e);\r\n        }\r\n        return toReturn;\r\n    }\r\n}</pre> \r\n<p>The class extends the <code>SequentialTask</code>, defines its abstract method and use the <code>executeSequential</code> method. </p> \r\n<p>Additionaly defines the class two task parameter&nbsp;<code>path</code> and&nbsp;<code>suffix</code> by the defining the <em>getters </em>for them.&nbsp;</p> \r\n<h2>Using the task in an Ant script</h2> \r\n<p>To call the task in an Ant script as showned in the example we have to provide the JAR library and define the task by its class:</p> \r\n<pre class="brush: xml">&lt;taskdef name="fetch-files" classname="cz.net21.ttulka.ant.FetchFilesTask" classpath="AntTasks-1.0.jar" /&gt;</pre> \r\n<p> </p> \r\n<p>You can download the <a href="/storage/AntTasks-1.0.jar">compiled JAR library</a> or whole <a href="https://github.com/ttulka/ant-sequential-tasks">project sources</a>.</p> \r\n<p>Have fun!</p>', 1, 'admin', 1, 'false', 'true', 1493110367, 'false'),
(20, 'Application Package Manager with Ant and Java', 1484073960, '<p>\r\nEveryone knows the operation systems package manager like&nbsp;<em>dpkg </em>(from Debian) or&nbsp;<em>RPM Package Manager</em> (from RedHat).</p> \r\n<p>Sometimes there is a need of such a management system in our own use.</p> \r\n<p>The environment doesn''t have to be an operation system, but for instance a<strong>&nbsp;web server</strong> or just a <strong>container application</strong>.</p> \r\n<p>The manager must be able to manage package <strong>dependencies</strong>, <strong>versions </strong>and <strong>installation </strong>to the environment system.</p>', 0, 0, '<p>All the information must be contained only inside the application itself, the system nor the manage <strong>must not</strong> have any additional data about a concrete package.</p> \r\n<p>To distinguish between a package and a package manager we will use in our context terms <em>Application Package</em> (<strong>AP</strong>) and <em>Application Package Manager</em> (<strong>APM</strong>).</p> \r\n<h2><em>Scenario One</em>: Container Application</h2> \r\n<p>We want to develop a container application which on the starup checks the application folder and install included application if not installed yet.</p> \r\n<p>Consider an application which simulates an operation system. It has a core, folder for configuration, run and so one. In the simplest case:</p> \r\n<pre>/applications/\r\n/system/\r\n       /conf/\r\n            /applications.conf\r\n       /core/\r\n            /lib/\r\n                /apm.jar\r\n                /system.jar\r\n            /apm.xml\r\n       /data/\r\n       /start.bat</pre> \r\n<p>The file <code>conf/applications.conf</code> contains pairs of <code>application-name=files-in-bin-directory-comma-separated</code>. It''s empty with a brand new system installation or contains some initial system-provided application and files.</p> \r\n<p>The system calls the APM (<code>core/apm.xml</code>) after the <code>start.bat</code> script is executed. The APM takes care of the applications installation. Then a system program (from the library <code>core/lib/system.jar</code>) goes thru the <code>conf/application.conf</code> and run each application logic (in our case only prints the content of a file defined by the application).</p> \r\n<p>The <code>applications</code> directory stands outside the <code>system</code> directory, it means even when the system is completely updated remains the <code>applications</code> directory untouched and the included application are always ready for a new installation by the next startup.</p> \r\n<h3>AP Implementation</h3> \r\n<p>An AP is nothing more than a folder with a strict defined structure containing all the needed system-related information about itselft. We will put all the AP-related files into the <code>META-INF</code> sub-folder.</p> \r\n<p>Every AP must have a meta information file. We will create a ordinary property file and call it <code>meta.info</code>. The meta information file contains the <em>name</em>, <em>version </em>and <em>dependencies </em>(optionally) of the AP.</p> \r\n<p>For our example we need data to be executed (their content will be printed after the system start). We will put them into <code>data</code> folder.&nbsp;</p> \r\n<pre>META-INF/\r\n        /data/\r\n        /meta.info\r\n</pre> \r\n<p>For an application to be deployed must be the application folder named in the pattern name-version (e.g. code>MySuperAppA-1.0</code>) and placed in the <code>applications</code> folder. This is the default place for the APM to look for the new APs.</p> \r\n<h4>Demo APs&nbsp;</h4> \r\n<p>For the test purposes let''s create three APs: <code>A</code>, <code>B</code>, <code>C</code> with the following dependencies:</p> \r\n<pre>A --&gt; B, C\r\nB --&gt; C\r\nC --&gt; (no dependency)</pre> \r\n<p>Each AP has two text files called be the pattern ap-name-1.txt and ap-name-2.txt with the content of the name of the AP and number of the data file.</p> \r\n<p>For example the AP named <code>B</code> contains in the folder <code>META-INF/data</code> a file <code>B-1.txt</code> with the content &quot;<code>B1</code>&quot; and a file <code>B-2.txt</code> with the content &quot;<code>B2</code>&quot;.</span></p> \r\n<p>After start of the demo system, we should see the following output:</p> \r\n<pre>C1\r\nC2\r\nB1\r\nB2\r\nA1\r\nA2&nbsp;</pre> \r\n<p>The order of the startups follows the dependencies definitions of the APs.</p> \r\n<h3>APM Implementation</h3> \r\n<p>First of all we need two Ant task for our APM script. The implementation of both is in the <code>core/lib/apm.jar</code> Java library and could be found in the source codes under the <code>ant-lib</code> project.</p> \r\n<h4>Dependencies order</h4> \r\n<p>This task takes a path as a parameter, goes thru this directory and gets all the folders inside it as an input.</p> \r\n<p>Then goes thru all of them and checks the dependencies from the <code>META-INF/meta.info</code>. So it creates a list of dependencies in the order of the need. For each application in the list a sequence inside the task will be executed. The sequence defines the installation procedure.</p> \r\n<pre class="brush: xml">&lt;taskdef name="dependencies-order" classname="cz.net21.ttulka.apm.ant.demo.DependenciesOrderTask"\r\n         classpath="core/lib/apm.jar" /&gt;\r\n...\r\n&lt;dependencies-order path="../applications" relpathmetainfofile="META-INF/meta.info"&gt;\r\n    &lt;sequential&gt;\r\n        &lt;antcall target="install-app"&gt;\r\n            &lt;param name="appPath" value="@{application}" /&gt;\r\n        &lt;/antcall&gt;\r\n    &lt;/sequential&gt;\r\n&lt;/dependencies-order&gt;\r\n</pre> \r\n<h4>Configuration record&nbsp;</h4> \r\n<p>For every application we need to scan the <code>data</code> folder and create a list of the files inside. This list in comma-separated form will be appended into the applications configuration file.</p> \r\n<pre class="brush: xml">&lt;taskdef name="create-conf-record" classname="cz.net21.ttulka.apm.ant.demo.CreateConfRecordTask"\r\n         classpath="core/lib/apm.jar" /&gt;\r\n...\r\n&lt;create-conf-record path="${appPath}/META-INF/data"&gt;\r\n    &lt;sequential&gt;\r\n        &lt;antcall target="write-conf-record"&gt;\r\n            &lt;param name="record" value="@{record}" /&gt;\r\n        &lt;/antcall&gt;\r\n    &lt;/sequential&gt;\r\n&lt;/create-conf-record&gt;\r\n...\r\n&lt;target name="write-conf-record"&gt;\r\n    &lt;echo file="conf/applications.conf" append="true"&gt;${line.separator}${appName}=${record}&lt;/echo&gt;\r\n&lt;/target&gt;&nbsp;</pre> \r\n<p> </p> \r\n<h2><em>Scenario Two</em>: Application (Web) Server&nbsp;</h2> \r\n<p>Such a APM could be used in the same way in the case of installing <strong>web applications into a server</strong>.&nbsp;</p> \r\n<p>Consider that the applications provide some functional services and their installation is <strong>dependent on one or more other</strong>.</p> \r\n<p>We can also install <strong>more versions of an application</strong> and enable only the latest version.</p> \r\n<p>For a proper run of an application the <strong>server needs to be configurated</strong> in a way known only to the application self.</p> \r\n<p>Application must be corretly <strong>re-installed after an update of the server</strong>, even when the old server data was completely removed.</p> \r\n<p>Even here helps the APM in all the above mentioned cases.&nbsp;</p> \r\n<h2>Downloads</h2> \r\n<p>You can download <a href="/storage/APM-demo.jar">whole demo project</a>. After unpacking you can start the demo with <code>system/start.bat</code>.</p> \r\n<p>Alternatively you can download the <a href="https://github.com/ttulka/application-package-manager-demo">source project</a>&nbsp;and addapt it to your needs and desires.</p> \r\n<p><br /></p>', 1, 'admin', 1, 'false', 'true', 1493110320, 'false'),
(116, 'Testing Serverless Systems', 1536920836, '<p>Designing a system architecture is always about making tradeoffs. Microservices resp. serverless architecture has a lot of benefits, but some drawbacks as well. One of them is testing. <strong>Testing serverless systems is hard</strong>. In this article I will discuss some practices which work for my project.</p>', 0, 0, '<h2>Serverless Systems</h2> \r\n<p>Because the view to serverless microservices can differ, let''s start with a bit theory to define the terms we will use.</p> \r\n<p>A <em>serverless architecture</em> is built upon <strong>managed elastic simple components</strong>. AWS offers for example components like Lambda functions, DynamoDB NoSQL database, SNS message service etc.</p> \r\n<p><img src="https://raw.githubusercontent.com/ttulka/testing-serverless/master/assets/ServelessMicroservices-BigPicture.png" width="70%" /></p> \r\n<p>A <em>microservice</em> is my understanding a <strong>logical unit owning all the components</strong> to carry out its whole functionality. Microservices are built around a boundary context (domain-specific) and contains all the functions and resources to be able to run as an autonomous service. All the components are private for the microservice and the functionality is accessible only via an API. If you are adapting Infrastructure as code (and you should) you build a microservice as one stack (1:1). Typically you have an integration build pipeline per microservice. Microservices can communicate via domain events (preferred way) or API call.</p> \r\n<p>A fictitious on-line store can have for example these microservices:</p> \r\n<p><img src="https://raw.githubusercontent.com/ttulka/testing-serverless/master/assets/ServelessMicroservices-StoreExample.png" width="40%" /></p> \r\n<p>Very important role in a serverless architecture have <em>functions</em>. Functions (like AWS Lambda or Google Cloud Functions) are the simplest core units of processing, typically built around an aggregate (what has to be processed within a transaction).</p> \r\n<p>Applications are clients outside the system (general untrusted) using system via API calls.</p> \r\n\r\n<h2>What and How to Test</h2> \r\n<p>The most problematic term in testing theories is a <em>Unit Test</em>, resp. the <em>Unit</em>. Some articles say it''s the smallest functional block. Some add that a unit test must run in isolation.</p> \r\n<p>In this article we define a <em>unit</em> as a <strong>component with well-defined boundaries (via API)</strong>. Depending on the level of abstraction the unit can be a function, a microservice, even the entire system.</p> \r\n<p>The term isolation is very tricky here. Because in real system there are almost no truly isolated components - components work together as a system to provide a feature - so it makes no sense to try to isolate the components by stubbing or mocking them. Such tests have no big value. Consider following pseudo code:</p> \r\n<pre class="brush: java">public class GetProductFunction {\r\n    private static final DbClient db = DbClient.build();\r\n\r\n    public Response handle(Request request, Context context) {\r\n        DbResult result = db.query("ProductTable", "name, description", "id = ?", request.getProductId());\r\n        return result.found()\r\n               ? new Response(200, result.getSingleItem())\r\n               : new Response(400);\r\n    } }\r\n</pre> \r\n<p>Building a database client is an expensive operation so we keep the instance as a static variable while the function container is warm.</p> \r\n<p>Now we want to test this simple function in isolation. The problem is the variable <code>db</code> is private and final so if we want to stub it we propably end up with a code change like following:</p> \r\n<pre class="brush: java">public class GetProductFunction {\r\n    static DbClient db; \r\n         \r\n    private static DbClient getDbClient() { return db == null ? db = DbClient.build() : db; }\r\n    \r\n    public Response handle(Request request, Context context) {\r\n        DbResult result = getDbClient().query("ProductTable", "name, description", "id = ?", request.getProductId());\r\n        return result.found()\r\n               ? new Response(200, result.getSingleItem())\r\n               : new Response(404);\r\n    } }\r\n</pre> \r\n<p>Changing the code for sake of a test sucks. There is a lot of problems with this code, but at least we can mock our resource now:</p> \r\n<pre class="brush: java">public class GetProductFunctionTest { \r\n    @Mock\r\n    private DbClient dbClient;\r\n    @Mock\r\n    private Request request;\r\n    @Mock\r\n    private Context context;\r\n\r\n    @Before\r\n    public void setup() { GetProductFunction.db = dbClient;  /* mock the expensive resource */ }\r\n    \r\n    @Test\r\n    public void testSuccess() {\r\n        when(request.getProductId()).thenReturn("test-id");\r\n\r\n        when(dbClient.found()).thenReturn(true);\r\n        when(dbClient.getSingleItem()).thenReturn(\r\n                Result.builder()\r\n                        .put("name", "test-name")\r\n                        .put("description", "test-description")\r\n                        .build());\r\n\r\n        Response response = new GetProductFunction().handle(request, context);\r\n\r\n        assertEquals("test-name", response.get("name"));\r\n        assertEquals("test-description", response.get("description")); \r\n    }\r\n        \r\n    @Test\r\n    public void testNotFound() {\r\n        when(request.getProductId()).thenReturn("test-id");\r\n\r\n        when(dbClient.found()).thenReturn(false);\r\n        when(dbClient.getSingleItem()).thenThrow(RuntimeException.class);\r\n\r\n        Response response = new GetProductFunction().handle(request, context);\r\n\r\n        assertEquals(404, response.getStatusCode());\r\n    } }\r\n</pre> \r\n<p>When we execute this test it''s green - cool, great job! Wait, really? What do we actually test here? Apart from the trivial logic (found ⇒ 200, not found ⇒ 404) we test only the behavior we stubbed with the mocks. What''s the value of testing mocks? - not a big one I guess...</p> \r\n<p>As we saw in the previous example, besides a few exceptions it makes only sense to test components in the system. <b>The unit of isolation is the test</b> - the tests should run isolated from each other (possibly in paralel).</p> \r\n<p>We <strong>always test only the API, never the implementation!</strong> There can be cases where implementation testing makes sense, or when we have to mock expensive resources, but event in such situations coupling tests with the implementation should be used as little as possible.</p> \r\n\r\n<h2>Test Categories</h2> \r\n<p>Bases on the levels of abstraction of components under test we can distinguish several test categories and which APIs should be visible for the test:</p> \r\n<p> \r\n<table cellspacing="0" cellpadding="5" border="1"> \r\n  <tr> \r\n    <th>Test category</th> \r\n    <th>Component under test</th> \r\n    <th>API</th>\r\n  </tr> \r\n  <tr> \r\n    <td>Unit Testing</td>\r\n    <td>Function</td> \r\n    <td>Public methods / exported functions</td> \r\n  </tr> \r\n  <tr> \r\n    <td>Integration Testing</td> \r\n    <td>Microservice</td> \r\n    <td>Events (REST requests / messages)</td>\r\n  </tr> \r\n  <tr> \r\n    <td>End-to-End Testing</td> \r\n    <td>System</td> \r\n    <td>API Gateway</td>\r\n  </tr> \r\n</table> \r\n</p> \r\n<p>What about testing of the (client) applications? Well, an application is actually an individual system so we can apply the entire testing model on it (we can see an application as a system in the table above).</p> \r\n<p>The test category determines how and where in the build pipeline the test is executed in:</p> \r\n<p><img src="https://raw.githubusercontent.com/ttulka/testing-serverless/master/assets/ServelessMicroservices-Pipeline2.png" width="100%" /></p> \r\n<p>A software delivery strategy cloud look like following scenario (an example):</p> \r\n<ul> \r\n  <li>a commit triggers the pipeline</li>\r\n  <li>the code source is fetched</li> \r\n  <li>the code is being built individually for each function (A, B, ... X)</li> \r\n  <li>the service is staged into a development environment, all resources are created</li>\r\n  <li>unit tests are being executed for each function (A, B, ... X)</li>\r\n  <li>integration tests are being executed for the entire service</li> \r\n  <li>the component is deployed into a QA environment</li> \r\n  <li>end-to-end testing pipeline is triggered or scheduled to run tests with a new version of the system</li> \r\n  <li>application pipeline is triggered to be tested with a new version of the system</li> \r\n  <li>the system is ready to be released into production</li> \r\n</ul> \r\n\r\n<h2>Unit Testing</h2> \r\n<p><em>Unit testing</em> distinguishes the smallest pieces of software in a serverless system - <strong>functions</strong>. They should be written by developers in the same programming language as the function and be a part of the function code base.</p> \r\n<p>As an example we have our <code>get-product</code>* function as a component (this time in Node.js):</p> \r\n<pre class="brush: javascript">const AWS = require(''aws-sdk'')\r\nconst dynamoDb = new AWS.DynamoDB.DocumentClient({apiVersion: ''2012-08-10''})\r\n\r\nexports.handler = async (event) =&gt; {\r\n    const product = await findProduct(event.productId)\r\n    return product \r\n        ? { statusCode: 200,\r\n            body: JSON.stringify(product) } \r\n        : { statusCode: 404 }\r\n}\r\n\r\nasync function findProduct(productId) {\r\n    const params = {\r\n        TableName: ''ProductTable'',\r\n        KeyConditionExpression: "productId = :productId",\r\n        ExpressionAttributeValues: { '':productId'': productId }\r\n    }\r\n    const result = await dynamoDb.query(params).promise()\r\n    \r\n    return result.Items &amp;&amp; result.Items.length\r\n        ? result.Items.map(item =&gt; ({\r\n            name: item.name, \r\n            description: item.description,\r\n        }))[0] : undefined\r\n}\r\n</pre>\r\n<p>And a test for it:</p> \r\n<pre class="brush: javascript">describe("Test get-product", function () {\r\n    const testProduct = {\r\n        productId: ''123'',\r\n        name: ''Product 123'',\r\n        description: ''Product Desc 123'',\r\n    }                                              \r\n\r\n    const handler = require(__dirname + ''/../src/get-product.js'').handler\r\n  \r\n    beforeAll(done =&gt; {\r\n        saveTestProduct(testProduct)\r\n            .then(res =&gt; done())\r\n            .catch(err =&gt; done.fail(err))\r\n    })\r\n    \r\n    it("Product should be found.", function() {\r\n        const response = handler({ productId: testProduct.productId })\r\n    \r\n        expect(response).toBeDefined()\r\n        expect(response.statusCode).toBe(200)\r\n        \r\n        expect(response.body).toBeDefined()\r\n        expect(JSON.parse(response.body).name).toBe(testProduct.name)\r\n        expect(JSON.parse(response.body).description).toBe(testProduct.description)\r\n    }) \r\n    \r\n    it("Product shouldn''t be found.", function() {\r\n        const response = handler({ productId: testProduct.productId + ''junk'' })\r\n    \r\n        expect(response).toBeDefined()\r\n        expect(response.statusCode).toBe(404)\r\n        \r\n        expect(response.body).toBeUndefined()\r\n    })\r\n    \r\n    afterAll(done =&gt; {\r\n        deleteTestProduct(testProduct)\r\n            .then(res =&gt; done())\r\n            .catch(err =&gt; done.fail(err))\r\n    })\r\n    \r\n    function saveTestProduct(testProduct) { /* ... */ }\r\n    function deleteTestProduct(testProduct) { /* ... */ }\r\n})\r\n</pre> \r\n<p>What about <code>saveTestProduct</code> and <code>deleteTestProduct</code> functions? If we implement them as direct database calls we couple our test with implementation details. We said a unit test checked the behavior of a component in the system; it means the test <strong>can use another resources via their APIs</strong>.</p> \r\n<p>Let''s assume that the bounding microservice have functions saving and deleting a product record in the database:</p> \r\n<pre class="brush: javascript">    const AWS = require(''aws-sdk'')\r\n    const lambda = new AWS.Lambda({apiVersion: ''2015-03-31''})\r\n    \r\n    function saveTestProduct(testProduct) {\r\n        const params = {\r\n            FunctionName: ''save-product'',\r\n            Payload: JSON.stringify({\r\n                name: testProduct.name, \r\n                description: testProduct.description,\r\n            })\r\n        }\r\n        return lambda.invoke(params).promise()\r\n    }\r\n    \r\n    function deleteTestProduct(testProduct) {\r\n        const params = {\r\n            FunctionName: ''delete-product'',\r\n            Payload: JSON.stringify({\r\n                productId: testProduct.productId,\r\n            })\r\n        }\r\n        return lambda.invoke(params).promise()\r\n    }\r\n</pre> \r\n\r\n<h2>Integration Testing</h2> \r\n<p><em>Integration testing</em> in serverless systems operates on level of <strong>microservices</strong>. Not only one function is under test, we test the whole feature the service provides by verifying communication and interactions between functions and other resources.</p> \r\n<p>As an example let''s consider a Catalog microservice - after saving a new product via <code>save-product</code> function a domain event like <code>NEW_PRODUCT_CREATED</code> should be fired. The <strong>event is a part of the internal API</strong> of the service and can be consumed by any other service registered to it. Typically an indexing service reacts to the event by extracting meta-data from the product and provides a full-search upon them. There should be an integration test validating this behavior.</p> \r\n<p>Because <strong>integration tests are testing already deployed services</strong> there is no more the requirement to use the same programming language as the service is written in (consider polyglot microservices). But as well as unit tests the integration tests should be created and maintained by developers.</p> \r\n<pre class="brush: javascript">const AWS = require(''aws-sdk'')\r\nconst lambda = new AWS.Lambda({apiVersion: ''2015-03-31''})\r\n\r\ndescribe("Integration test to save a new product", function () {\r\n	  const testProduct = {\r\n        productId: ''123'',\r\n        name: ''Product 123'',\r\n        description: ''Product Desc 123'',\r\n    }       \r\n\r\n    it("Metadata should be indexed after a new product was saved.", async function() {\r\n    	// save a new product\r\n        const saveParams = {\r\n            FunctionName: ''save-product'',\r\n            Payload: JSON.stringify({\r\n                name: testProduct.name, \r\n                description: testProduct.description,\r\n            })\r\n        }\r\n        const saveResponse = await lambda.invoke(saveParams).promise()\r\n    \r\n        expect(saveResponse).toBeDefined()\r\n        expect(saveResponse.statusCode).toBe(201)\r\n\r\n        await sleep(1000) // waiting necessary due to eventual consistency\r\n\r\n        // the product must be indexed and available for searching\r\n        const searchParams = {\r\n            FunctionName: ''search-catalog'',\r\n            Payload: JSON.stringify({\r\n                name: testProduct.name, \r\n                description: testProduct.description,\r\n            })\r\n        }\r\n        const searchResponse = await lambda.invoke(searchParams).promise()\r\n\r\n		expect(searchResponse).toBeDefined()\r\n        expect(searchResponse.statusCode).toBe(200)\r\n    })\r\n    \r\n    afterAll(done =&gt; {\r\n        deleteTestProduct(testProduct)\r\n            .then(res =&gt; done())\r\n            .catch(err =&gt; done.fail(err))\r\n    })\r\n    \r\n    function deleteTestProduct(testProduct) { /* ... */ }\r\n\r\n    function sleep(ms) { /* ... */ }\r\n})\r\n</pre> \r\n\r\n<h2>End-to-End Testing</h2> \r\n<p>The <em>end-to-end tests</em> validate behavior of the <strong>entire system or its sub-systems</strong> and run apart from a feature (microservice''s) build pipeline.</p> \r\n<p>They can have a form of <em>acceptance tests</em> where whole paths are tested (1. search a product, 2. order the product, 3. create an invoice, 4. delivery etc.) or <em>automated GUI tests</em> which are testing the system from the client''s point of view.</p>\r\n<p>End-to-end tests could be generally written by someone else than by the developer. Especially GUI tests can be fully in hands of testers.</p> \r\n<p>Of course, the <em>manual testing</em> belongs to this category as well.</p> \r\n<p>In the previous integration-testing example both functions for saving and searching products were a part of one microservice - it means they lie in one build pipeline. If these functions were parts of different microservices the test would belong to the end-to-end testing category.</p>\r\n<pre class="brush: java">public class SaveProductServiceTestE2E {\r\n\r\n    private final String SERVICE_API = System.getenv("SERVICE_API");\r\n    private final String PRODUCT_SAVE_ENDPOINT = SERVICE_API + "/catalog/product";\r\n    private final String SEARCH_ENDPOINT = SERVICE_API + "/search";\r\n\r\n    private HttpClient httpClient;\r\n\r\n    @Before\r\n    public void setup() { this.httpClient = createHttpClient(); }\r\n\r\n    @Test\r\n    public void testMetadataShouldIndexed() throws Exception {\r\n        Product product = Product.build("Product 123", "Product Desc 123");\r\n\r\n        // save a new product\r\n        HttpPost saveRequest = httpClient.post(PRODUCT_SAVE_ENDPOINT);\r\n        saveRequest.setHeader("Content-type", "application/json");\r\n        saveRequest.setBody("{\\"name\\":\\"" + product.getName() + "\\",\\"description\\":\\"" + product.getDescription() + "\\"}");\r\n\r\n        HttpResponse saveResponse = httpClient.execute(saveRequest);\r\n\r\n        assertEquals(201, saveResponse.getStatusCode());\r\n\r\n        Thread.sleep(1000); // waiting necessary due to eventual consistency\r\n\r\n        // the product must be indexed and available for searching\r\n        HttpPost searchRequest = httpClient.post(SEARCH_ENDPOINT);\r\n        searchRequest.setHeader("Content-type", "application/json");\r\n        searchRequest.setBody("{\\"keyword\\":\\"" + product.getName() + "\\"}");\r\n\r\n        HttpResponse searchResponse = httpClient.execute(searchRequest);\r\n\r\n        assertEquals(200, searchResponse.getStatusCode());\r\n    }\r\n\r\n    @After\r\n    public void cleanup() {\r\n        // ...\r\n    } }\r\n</pre>\r\n\r\n<h2>Summary</h2> \r\n<p>In this article I wanted to recap my experience with functional testing of serverless systems and simplify the levels of tests. I reviewed terms unit-, integration- and end-to-end-testing to show what is under test and where such tests lie in the development process.</p> \r\n<p>Despite the fact that I focused only on functional testing doesn''t mean that testing non-functional requirements like performance, security, scalability etc. are not important...:-)</p> \r\n\r\n<p>Happy testing!</p> <hr /> \r\n\r\n<p><em>* I use verbs to name functions because it sounds natural to me. A function is in fact an action.</em></p>', 1, 'admin', 1, 'false', 'true', 1537180299, 'false'),
(22, 'How to Effectively Protect Critical Section', 1496338500, '<div>Not everywhere could be <em>immutable objects</em> used to ensure thread-safe code. Sometimes we need to wait for some events (especially coming as user input) to initialize a variable. In the case this input can come from a concurrent environment we need to protect the initialization as critical section.</div> \r\n<div><br /></div> \r\n<div>Native Java approach is to use the keyword <code>synchronized</code> of the critical code and this will work... but is it <strong>effective </strong>as well?</div> \r\n<div> </div> \r\n<div>Let''s discuss some more methods how to protect a critical section in the Java code.&nbsp;</div>', 0, 0, '<div>As usual we start as simple as possible, this is our code:</div> \r\n<pre class="brush: java">class MyCriticalSection {\r\n\r\n    static Object toBeInitialized = null;   // mutable static object\r\n\r\n    public void callFromClient(Object... globalParams) {\r\n        if (toBeInitialized == null) {\r\n            toBeInitialized = initialize(globalParams);\r\n        }\r\n\r\n        // so something with the toBeInitialized object\r\n        System.out.println(toBeInitialized.toString());\r\n    }\r\n\r\n    private Object initialize(Object... params) {\r\n        // do some better stuff here...\r\n        return new Object();\r\n    }\r\n}\r\n</pre> \r\n<div>Completely unsafe. So let''s synchronize it:</div> \r\n<pre class="brush: java">public synchronized void callFromClient(Object... globalParams) {\r\n    // ...\r\n}\r\n</pre> \r\n<div>Very ineffective. Actually we want to synchronize only the initialization part:</div> \r\n<pre class="brush: java">public void callFromClient(Object... globalParams) {\r\n    synchronized (MyCriticalSection.class) {\r\n        if (toBeInitialized == null) {\r\n            toBeInitialized = initialize(globalParams);\r\n        }\r\n    }\r\n    // ...\r\n}\r\n</pre> \r\n<div>Synchronizing on the class means a caller trying to access the section will be block even when another caller is inside another section synchronized on the class as well:</div> \r\n<pre class="brush: java">void anotherCall() {\r\n    synchronized (MyCriticalSection.class) {\r\n        // ...\r\n    }\r\n}\r\n</pre> \r\n<div>The same for static methods:</div> \r\n<pre class="brush: java">void static doSomething() {\r\n    synchronized (MyCriticalSection.class) {\r\n        // ...\r\n    }\r\n}\r\n</pre> \r\n<div>This could be okay when the initialization is distributed or static, but even for these cases we have a better option:</div> \r\n<pre class="brush: java">private final Object initializationLock = new Object();     // could be static for static methods\r\n\r\npublic void callFromClient(Object... globalParams) {\r\n    synchronized (initializationLock) {\r\n        if (toBeInitialized == null) {\r\n            toBeInitialized = initialize(globalParams);\r\n        }\r\n    }\r\n    // ...\r\n}\r\n</pre> \r\n<div>Looks nice, we''re done...? Actually not, using the synchronized keyword is far not the most effectively way how to protect a critical section.</div> \r\n<div>Java 5 came with a package of atomic classes <code>java.util.concurrent.atomic</code> among then <code>AtomicBoolen</code>.</div> \r\n<div><code>AtomicBoolen</code> could be used to check atomically if a condition was already fulfilled or not:</div> \r\n<pre class="brush: java">private final AtomicBoolean alreadyInitialized = new AtomicBoolean();\r\n\r\npublic void callFromClient(Object... globalParams) {\r\n    if (alreadyInitialized.compareAndSet(false, true)) {\r\n        toBeInitialized = initialize(globalParams);\r\n    }\r\n    // ...\r\n}\r\n</pre> \r\n<div>This works the same way as the synchronized section above and is much more effective... but well, there is another little devil hidden in the code.</div> \r\n<div>Take a look at the code above including the synchronized variants. What happens when another caller calls the method in the same time as the first method entered the critical section to initialize the object?</div> \r\n<div>The second caller doesn''t get the access to the critical section and continues in the code execution. But this means he works with a potentially uninitialized object and the last line of code will throw a <code>NullPointerException</code> trying to call <code>toString()</code> method on the <code>null</code> value.</div> \r\n<div> \r\n<p>Our job is not done here yet...</p> \r\n<p>In the package <code>java.util.concurrent</code> we can find a class<code>CountDownLatch</code> designed to synchronize concurrency of thread processing:</p> \r\n<pre class="brush: java">private final AtomicBoolean initializationStarted = new AtomicBoolean();\r\nprivate final CountDownLatch initializationFinished = new CountDownLatch(1);\r\n\r\npublic void callFromClient(Object... globalParams) throws InterruptedException {\r\n    if (initializationStarted.compareAndSet(false, true)) {\r\n        toBeInitialized = initialize(globalParams);\r\n        initializationFinished.countDown();\r\n    } else {\r\n        initializationFinished.await();\r\n    }\r\n    // ...\r\n}\r\n</pre> \r\n<div>So, what happens here? We use the atomic boolean to check if the object was already initialized or not. If not we access the critical section. Because the set and set of the atomic boolean is done atomically only one thread can access the initialization.</div> \r\n<div>The initialization is first ready when the first caller counts down the latch. Before the latch was count-downed all the concurrent callers wait on its <code>await()</code> method.</div> \r\n<div>All this doesn''t look as nice and easy as with the <code>synchronized</code> keyword. So, is it really so effective?</div> \r\n<div> \r\n<p>I did performance tests using all the above mentioned techniques. I tried to access the critical section one million times for each of them:</p> \r\n<p> \r\n<table border="1" cellspacing="1" cellpadding="3"> \r\n<tbody> \r\n<tr> \r\n<td><strong>technique</strong></td> \r\n<td><strong>execution time</strong></td> \r\n</tr> \r\n<tr> \r\n<td>not thread-safe </td> \r\n<td style="text-align: right;">2 ms</td> \r\n</tr> \r\n<tr> \r\n<td>synchronized class</td> \r\n<td style="text-align: right;">32 ms</td> \r\n</tr> \r\n<tr> \r\n<td>synchronized object</td> \r\n<td style="text-align: right;">26 ms</td> \r\n</tr> \r\n<tr> \r\n<td>atomic-latch</td> \r\n<td style="text-align: right;">16 ms</td> \r\n</tr> \r\n</tbody> \r\n</table> \r\n</p> \r\n</div> \r\n<p> </p> \r\n<div> \r\n<p>Of course there a great penalty of synchronization but this shouldn''t be a big surprise, I guess.</p> \r\n</div> \r\n<div> \r\n<p>The more important thing is the <em>AtomicBoolean-CountDownLatch</em> synchronization is over 40 % more effective. In environments like servers where the calls come for every request hundred thousand times in second this is a pretty nice optimization.</p> \r\n<p> </p> \r\n<p> </p> \r\n</div> \r\n</div>', 1, 'admin', 1, 'false', 'true', 1496397452, 'false'),
(23, 'Managing Asynchronous Tests', 1500480360, '<p>It''s recommended to avoid any asynchrony within the scope of test, but this is unfortunaly not possible everywhere. In some systems the caller must wait for another thread or transaction to be completed.</p> \r\n<p>Testing asynchrony could be pretty tricky, not always is clear how long must a test wait for a result to be delivered - if it''s too little the test fails event when the tested functionality works, if it''s too long the test is just wasting time (so expensive especially in the commit stage).</p> \r\n<p>So, how to deal with this problem?&nbsp;</p>', 0, 0, '<p>Consider a simple test in JUnit:</p> \r\n<pre class="brush: java">@Test\r\npublic void shouldDeliverResult() {\r\n&nbsp; &nbsp; calculateResult();\r\n&nbsp; &nbsp; confirmResultWasDelivered(); &nbsp; &nbsp; &nbsp; &nbsp;\r\n}\r\n\r\nprivate void confirmResultWasDelivered() {\r\n&nbsp; &nbsp; if (!resultWasDelivered()) {\r\n&nbsp; &nbsp; &nbsp; &nbsp; fail("No result was delivered!");\r\n&nbsp; &nbsp; }\r\n}</pre> \r\n<p>In this unit test we test a state of an object after calling the method <code>calculateResult()</code> with the method <code>resultWasDelivered()</code>. If the method <code>calculateResult()</code> is designed in the asynchronous manner, the test will fail almost in 100 % cases. </p> \r\n<p>A naive solution is to <strong>add a timeout</strong>:</p> \r\n<pre class="brush: java">private void confirmResultWasDelivered() {\r\n&nbsp; &nbsp; sleep(TIMEOUT);\r\n&nbsp; &nbsp; \r\n&nbsp; &nbsp; if (!resultWasDelivered()) {\r\n&nbsp; &nbsp; &nbsp; &nbsp; fail("No result was delivered!");\r\n&nbsp; &nbsp; }\r\n}\r\nprivate void sleep(long milliseconds) {\r\n&nbsp; &nbsp; try {\r\n&nbsp; &nbsp; &nbsp; &nbsp; Thread.sleep(milliseconds);\r\n&nbsp; &nbsp; } catch (InterruptedException ignore) {\r\n&nbsp; &nbsp; }\r\n}</pre> \r\n<p>But again, what is the <em>right </em>value of the timeout here?</p> \r\n<p>We want to be sure that our test passes always when a correct result is delivered, so we set the timeout to a maximal waiting period. On the other hand in some cases the result could be delivered quickly in a small amout of time: </p> \r\n<pre class="brush: java">private void confirmResultWasDelivered() {\r\n&nbsp; &nbsp; long testStarted = System.currentTimeMillis();\r\n&nbsp; &nbsp; do {\r\n&nbsp; &nbsp; &nbsp; &nbsp; if (resultWasDelivered()) {\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; return;\r\n&nbsp; &nbsp; &nbsp; &nbsp; }\r\n&nbsp; &nbsp; &nbsp; &nbsp; sleep(SMALL_AMOUT_OF_TIME);\r\n&nbsp; &nbsp; \r\n&nbsp; &nbsp; } while (TIMEOUT &gt; System.currentTimeMillis() - testStarted);\r\n&nbsp; &nbsp; \r\n&nbsp; &nbsp; fail("No result was delivered!");\r\n}</pre> \r\n<p>The last approach is still based on the pull princip and active waiting, but it''s much more efficient as the previous one.&nbsp;</p> \r\n<p>We try to check if a result was delivered, if not we try it again after a small amout of time till the timeout exceeds.</p> \r\n<p> </p>', 1, 'admin', 1, 'false', 'true', 1500532569, 'false'),
(24, 'Synchronized Methods versus Semaphore', 1501684800, '<div> \r\n<p>When one-thread-access is too restrictive and we want to allow more threads to our resource then come semaphores on the stage.</p> \r\n<p>But there is one important difference in these approaches.</p> \r\n</div>', 0, 0, '<div>Let''s consider a code:</div> \r\n<pre class="brush: java">private Object synch = new Object();\r\n\r\npublic void synchronizedMethod1() {\r\n    synchronized (synch) {\r\n        synchronizedMethod2();\r\n    }\r\n}\r\n\r\npublic void synchronizedMethod2() {\r\n    synchronized (synch) {\r\n        System.out.println("Access to the resource acquired.");\r\n    }\r\n}</pre> \r\n<div>What happened by calling the <code>synchronizedMethod1()</code>?</div> \r\n<div>Of course the access to the resource will be acquired because the synchronized block is in Java shared in within the thread. In other words, if the thread is already in the synchronized block will get all the others as well (protected by the same object).</div> \r\n<div><br /></div> \r\n<div>Applying a semaphore (with the counter set to one) on the same code:</div> \r\n<pre class="brush: java">private Semaphore semaphore = new Semaphore(1);\r\n\r\npublic void synchronizedMethod1() throws InterruptedException {\r\n    semaphore.acquire();\r\n    synchronizedMethod2();\r\n    semaphore.release();\r\n}\r\n\r\npublic void synchronizedMethod2() throws InterruptedException {\r\n    semaphore.acquire();\r\n    System.out.println("Access to the resource acquired.");\r\n    semaphore.release();\r\n} </pre> \r\n<div>And calling <code>synchronizedMethod1()</code> will freeze forever.</div> \r\n<div><br /></div> \r\n<div>In this case acquire the <code>synchronizedMethod1</code> the semaphore but <code>synchronizedMethod2</code>&nbsp;fails on trying to acquire it again.</div> \r\n<div><br /></div> \r\n<div>In general, this problem is caused by a weak design and can be solved by a simple refactoring:</div> \r\n<pre class="brush: java">public void synchronizedMethod1() throws InterruptedException {\r\n    semaphore.acquire();\r\n    resourceMethod();\r\n    semaphore.release();\r\n}\r\n\r\npublic void synchronizedMethod2() throws InterruptedException {\r\n    semaphore.acquire();\r\n    resourceMethod();\r\n    semaphore.release();\r\n}\r\n\r\nprivate void resourceMethod() {\r\n    System.out.println("Access to the resource acquired.");\r\n}</pre>', 1, 'admin', 1, 'false', 'true', 1506965500, 'false');
INSERT INTO `serendipity_entries` (`id`, `title`, `timestamp`, `body`, `comments`, `trackbacks`, `extended`, `exflag`, `author`, `authorid`, `isdraft`, `allow_comments`, `last_modified`, `moderate_comments`) VALUES
(25, 'Pitfalls of Processing a Stream from an External Program', 1506962040, '<div>Let''s image an external standalone program producing a big amount of binary data. Good example is a files converter (images, mp3s, documents, etc).</div> \r\n<div>How to design such a program and what are the pitfalls of the approach?</div>', 0, 0, '<h2>Standalone Producer Application</h2> \r\n<div>There is many ways how to create a standalone application and one of the easiest and the most straight-forward approaches is Spring-Boot (<code>pom.xml</code>):</div> \r\n<pre class="brush: xml">&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd"&gt;\r\n&nbsp; &nbsp; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;\r\n&nbsp; &nbsp; &lt;parent&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &lt;!-- Your own application should inherit from spring-boot-starter-parent --&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &lt;version&gt;1.5.7.RELEASE&lt;/version&gt;\r\n&nbsp; &nbsp; &lt;/parent&gt;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\r\n&nbsp; &nbsp; &lt;groupId&gt;cz.net21.ttulka.eval&lt;/groupId&gt;\r\n&nbsp; &nbsp; &lt;artifactId&gt;StandaloneBytesProducer&lt;/artifactId&gt;\r\n&nbsp; &nbsp; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt;\r\n&nbsp; &nbsp; &lt;properties&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &lt;java.version&gt;1.8&lt;/java.version&gt;\r\n&nbsp; &nbsp; &lt;/properties&gt;\r\n&nbsp; &nbsp; &lt;dependencies&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &lt;dependency&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &lt;/dependency&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &lt;dependency&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;groupId&gt;commons-logging&lt;/groupId&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;artifactId&gt;commons-logging&lt;/artifactId&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;version&gt;1.2&lt;/version&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &lt;/dependency&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &lt;dependency&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;artifactId&gt;lombok&lt;/artifactId&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;version&gt;1.16.18&lt;/version&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;scope&gt;provided&lt;/scope&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &lt;/dependency&gt;\r\n&nbsp; &nbsp; &lt;/dependencies&gt;\r\n&nbsp; &nbsp; &lt;build&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &lt;plugins&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;plugin&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;version&gt;3.7.0&lt;/version&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;configuration&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;source&gt;1.8&lt;/source&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;target&gt;1.8&lt;/target&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;/configuration&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;/plugin&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;plugin&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;/plugin&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &lt;/plugins&gt;\r\n&nbsp; &nbsp; &lt;/build&gt;\r\n&lt;/project&gt;</pre> \r\n<div> </div> \r\n<div> </div> \r\n<div> </div> \r\n<p><code>StandaloneBytesProducerApplication.java</code>:</p> \r\n<pre class="brush: java">package cz.net21.ttulka.eval.bytesproducer;\r\n\r\nimport org.springframework.boot.ApplicationArguments;\r\nimport org.springframework.boot.ApplicationRunner;\r\nimport org.springframework.boot.SpringApplication;\r\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\r\nimport lombok.extern.apachecommons.CommonsLog;\r\n\r\n@SpringBootApplication\r\n@CommonsLog\r\npublic class StandaloneBytesProducerApplication implements ApplicationRunner {\r\n&nbsp; &nbsp; @Override\r\n&nbsp; &nbsp; public void run(ApplicationArguments args) {\r\n&nbsp; &nbsp; &nbsp; &nbsp; log.info("StandaloneBytesProducerApplication started.");\r\n&nbsp; &nbsp; &nbsp; &nbsp; try {\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; int bytesAmount = 1000;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if (args.containsOption("bytes")) {\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bytesAmount = Integer.parseInt(args.getOptionValues("bytes").get(0));&nbsp; &nbsp;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; for (int i = 0; i &lt; bytesAmount; i++) {&nbsp; &nbsp;&nbsp;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; System.out.write(i % Byte.MAX_VALUE);&nbsp; &nbsp;// we''re writing on the standard output stream\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\r\n&nbsp; &nbsp; &nbsp; &nbsp; } catch (Exception e) {\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; log.error("Unexpected error.", e);\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; System.exit(1);\r\n&nbsp; &nbsp; &nbsp; &nbsp; }\r\n&nbsp; &nbsp; &nbsp; &nbsp; System.exit(0);\r\n&nbsp; &nbsp; }\r\n&nbsp; &nbsp; public static void main(String[] args) throws Exception {\r\n&nbsp; &nbsp; &nbsp; &nbsp; SpringApplication.run(StandaloneBytesProducerApplication.class, args);\r\n&nbsp; &nbsp; }\r\n}</pre> \r\n<div> </div> \r\n<div> </div> \r\n<div> </div> \r\n<p> </p> \r\n<div> \r\n<p>Compile it and run:</p> \r\n</div> \r\n<pre>mvn clean package\r\nmvn spring-boot:run</pre> \r\n<div>It looks good. Of course a consumer will run it direct from a JAR:</div> \r\n<pre>java -jar target\\StandaloneBytesProducer-1.0.0-SNAPSHOT.jar</pre> \r\n<div>The result is what we expected, Spring Boot ASCII logo, some log messages and our bytes stream.</div> \r\n<div>And this is exactly one pitfall because all this junk destroys our result, actually all and only we need is the bytes stream.</div> \r\n<div><br /></div> \r\n<div>Spring Boot uses it own logging (based on <code><a href="https://commons.apache.org/proper/commons-logging/" target="_blank">commons-logging</a></code>) hidden in the artifact <code>spring-boot-starter-logging</code>. To get rid of it we can exclude this artifact from the build:</div> \r\n<pre class="brush: xml">&lt;dependency&gt;\r\n&nbsp; &nbsp; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\r\n&nbsp; &nbsp; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;\r\n&nbsp; &nbsp; &lt;exclusions&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &lt;exclusion&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &lt;/exclusion&gt;\r\n&nbsp; &nbsp; &lt;/exclusions&gt;\r\n&lt;/dependency&gt;</pre> \r\n<div>When we now run the program, the log messages look different. After excluding the Spring Boot logging the <code>commons-logging</code> uses its default fall-back implementation <code>SimpleLog</code>.</div> \r\n<div><code>SimpleLog</code> then sends all messages, for all defined loggers, to <code>stderr</code>. We can prove it by forwarding the standard output into a file:</div> \r\n<pre>java -jar target\\StandaloneBytesProducer-1.0.0-SNAPSHOT.jar &gt; out.dat</pre> \r\n<div>Indeed, the log messages are still written in the console and the file includes only the Spring Boot logo and our bytes.</div> \r\n<div><br /></div> \r\n<div>To get rid of the logo is easy, just put the <code>application.yml</code> into the <em>resources </em>directory:</div> \r\n<pre>spring:\r\n&nbsp; main:\r\n&nbsp; &nbsp; banner-mode: "off"</pre> \r\n<div> \r\n<p>Now the standard output contains only the result bytes. It''s time to implement a consumer...</p> \r\n</div> \r\n<h2>Standalone Consumer Application</h2> \r\n<div>Consumer could be done in the same manner, this time we don''t case about logging much (<code>pom.xml</code>):</div> \r\n<pre class="brush: xml">&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd"&gt;\r\n&nbsp; &nbsp; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;\r\n&nbsp; &nbsp; &lt;parent&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &lt;!-- Your own application should inherit from spring-boot-starter-parent --&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &lt;version&gt;1.5.7.RELEASE&lt;/version&gt;\r\n&nbsp; &nbsp; &lt;/parent&gt;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\r\n&nbsp; &nbsp; &lt;groupId&gt;cz.net21.ttulka.eval&lt;/groupId&gt;\r\n&nbsp; &nbsp; &lt;artifactId&gt;StandaloneBytesConsumer&lt;/artifactId&gt;\r\n&nbsp; &nbsp; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt;\r\n&nbsp; &nbsp; &lt;properties&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &lt;java.version&gt;1.8&lt;/java.version&gt;\r\n&nbsp; &nbsp; &lt;/properties&gt;\r\n&nbsp; &nbsp; &lt;dependencies&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &lt;dependency&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &lt;/dependency&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &lt;dependency&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;groupId&gt;commons-logging&lt;/groupId&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;artifactId&gt;commons-logging&lt;/artifactId&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;version&gt;1.2&lt;/version&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &lt;/dependency&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &lt;dependency&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;artifactId&gt;lombok&lt;/artifactId&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;version&gt;1.16.18&lt;/version&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;scope&gt;provided&lt;/scope&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &lt;/dependency&gt;\r\n&nbsp; &nbsp; &lt;/dependencies&gt;\r\n&nbsp; &nbsp; &lt;build&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &lt;plugins&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;plugin&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;version&gt;3.7.0&lt;/version&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;configuration&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;source&gt;1.8&lt;/source&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;target&gt;1.8&lt;/target&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;/configuration&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;/plugin&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;plugin&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;/plugin&gt;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &lt;/plugins&gt;\r\n&nbsp; &nbsp; &lt;/build&gt;\r\n&lt;/project&gt;&nbsp;</pre> \r\n<div> </div> \r\n<div> </div> \r\n<div> </div> \r\n<div>Important pitfall here to be aware about: <strong>all (stdout, stderr) the streams must be consumed</strong>. If you forget to consume the <code>stderr</code> stream the program will freeze forever.</div> \r\n<div><br /></div> \r\n<div>The error log can be either consumed and forgotten or consumed and print into the log:</div> \r\n<pre class="brush: java">package cz.net21.ttulka.eval.bytesconsumer;\r\n\r\nimport java.io.IOException;\r\nimport java.io.InputStream;\r\nimport java.util.Scanner;\r\nimport org.springframework.boot.ApplicationArguments;\r\nimport org.springframework.boot.ApplicationRunner;\r\nimport org.springframework.boot.SpringApplication;\r\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\r\nimport lombok.extern.apachecommons.CommonsLog;\r\n\r\n@SpringBootApplication\r\n@CommonsLog\r\npublic class StandaloneBytesConsumerApplication implements ApplicationRunner {\r\n&nbsp; &nbsp; @Override\r\n&nbsp; &nbsp; public void run(ApplicationArguments args) {&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\r\n&nbsp; &nbsp; &nbsp; &nbsp; String pathToJar = System.getProperty("PATH_TO_JAR");\r\n&nbsp; &nbsp; &nbsp; &nbsp; log.info("StandaloneBytesConsumerApplication started: " + pathToJar);\r\n&nbsp; &nbsp; &nbsp; &nbsp; ProcessBuilder builder = new ProcessBuilder("java", "-jar", pathToJar);&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\r\n&nbsp; &nbsp; &nbsp; &nbsp; try {\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Process process = builder.start();\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; processErrors(process.getErrorStream());&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; processStream(process.getInputStream());&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\r\n&nbsp; &nbsp; &nbsp; &nbsp; } catch (Exception e) {\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; log.error("Unexpected error.", e);\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; System.exit(1);\r\n&nbsp; &nbsp; &nbsp; &nbsp; }\r\n&nbsp; &nbsp; &nbsp; &nbsp; System.exit(0);\r\n&nbsp; &nbsp; }\r\n&nbsp; &nbsp; private void processStream(InputStream stream) throws IOException {\r\n&nbsp; &nbsp; &nbsp; &nbsp; int b;\r\n&nbsp; &nbsp; &nbsp; &nbsp; while ((b = stream.read()) != -1) {\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; // TODO do something with the stream\r\n&nbsp; &nbsp; &nbsp; &nbsp; }\r\n&nbsp; &nbsp; &nbsp; &nbsp; stream.close();\r\n&nbsp; &nbsp; }\r\n&nbsp; &nbsp; private void processErrors(final InputStream in) {\r\n&nbsp; &nbsp; &nbsp; &nbsp; new Thread(new Runnable() {\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; @Override\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; public void run() {\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; int logLevel = 3;&nbsp; &nbsp;// 0 - ERROR, 1 - WARN, 2 - INFO, 3 - DEBUG\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Scanner scanner = new Scanner(in);\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; while (scanner.hasNextLine()) {\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; String line = scanner.nextLine();\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if (line.startsWith("ERROR") || line.startsWith("FATAL")) {\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; logLevel = 0;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if (line.startsWith("WARN")) {\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; logLevel = 1;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if (line.startsWith("INFO")) {\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; logLevel = 2;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if (line.startsWith("DEBUG") || line.startsWith("TRACE")) {\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; logLevel = 3;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; switch (logLevel) {\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; case 0:\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; log.error(line);\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; break;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; case 1:\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; log.warn(line);\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; break;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; case 2:\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; log.info(line);\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; break;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; default:\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; log.debug(line);\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; break;\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\r\n&nbsp; &nbsp; &nbsp; &nbsp; }).start();\r\n&nbsp; &nbsp; }\r\n&nbsp; &nbsp; public static void main(String[] args) throws Exception {\r\n&nbsp; &nbsp; &nbsp; &nbsp; SpringApplication.run(StandaloneBytesConsumerApplication.class, args);\r\n&nbsp; &nbsp; }\r\n}&nbsp;</pre> \r\n<div> </div> \r\n<div> </div> \r\n<div> </div> \r\n<div> </div> \r\n<div> </div> \r\n<div> </div> \r\n<div>Compile and run it:</div> \r\n<pre>mvn clean package\r\nmvn spring-boot:run -DPATH_TO_JAR=..\\StandaloneBytesProducer\\target\\StandaloneBytesProducer-1.0.0-SNAPSHOT.jar</pre> \r\n<div> \r\n<p>Source codes: <a href="https://github.com/ttulka/eval/tree/master/StandaloneBytesProducer" target="_blank" title="StandaloneBytesProducer">StandaloneBytesProducer</a> and <a href="https://github.com/ttulka/eval/tree/master/StandaloneBytesConsumer" target="_blank" title="StandaloneBytesConsumer">StandaloneBytesConsumer</a>.&nbsp;</p> \r\n<p>Happy byting!</p>\r\n</div>', 1, 'admin', 1, 'false', 'true', 1506966919, 'false'),
(26, 'ThistleDB - Simple JSON Database - Released!', 1505935380, '<p>Simple JSON database based on the <strong>file-access</strong> and <strong>server-client</strong> approach with the non-blocking server and the reactive (asynchronous non-blocking) client.</p>', 0, 0, '<p>All about:&nbsp;<a href="http://thistledb.net21.cz"><strong>http://thistledb.net21.cz</strong></a></p> \r\n<p>Have fun!</p>', 1, 'admin', 1, 'false', 'true', 1525788558, 'false'),
(115, 'How AWS Lambda Executes Node.js Functions', 1531317443, '<p>Based on <a href="https://stackoverflow.com/questions/51037262/aws-lambda-javascript-sdk-async-handler" target="_blank">my question</a> on StackOverflow I did a bit investigation about how (likely) are Node.js functions called in AWS Lambda containers.</p>', 0, 0, '<p>First, I have to mention I don''t have the actual implementation of the Node.js AWS Lambda container executors, so all following is only a simple thought experiment. But it seems to be very likely and can definitely help with understanding <em>how are Node.js handler functions executed in AWS Lambda</em>.</p>\r\n\r\n<p>The problem as described in the question is following:</p>\r\n<p>A simple function with an asynchrony inside is not correctly executed when the handler function is declared as <code>async</code>.</p>\r\n<pre class="brush: javascript">\r\nexports.handler = async (event, context, callback) => {\r\n  setTimeout(() => callback(null, "resolved"), 100)\r\n}\r\n</pre>\r\n<p>The result of the execution of this Lambda is <code>null</code>.</p>\r\n<p>When the keyword <code>async</code> is removed from the handler everything works fine and the result is <code>resolved</code> as expected.</p>\r\n\r\n<p>So, what is the difference?</p>\r\n\r\n<p>According <a href="https://docs.aws.amazon.com/lambda" target="_blank">the documentation</a>, the asynchronous handlers are executed without using the callback function and the result of the <code>return</code> is used instead.</p>\r\n\r\n<p>I tried to simulate the executor code and came up with this:</p>\r\n\r\n<pre class="brush: javascript">\r\nvar handler1 = async (event, context, callback) => {\r\n  setTimeout(() => callback(null, "resolved"), 100)\r\n}\r\n\r\nvar handler2 = async (event, context, callback) => {\r\n  return "resolved"\r\n}\r\n\r\nvar handler3 = (event, context, callback) => {\r\n    setTimeout(() => callback(null, "resolved"), 100)\r\n}\r\n\r\n// main thread function\r\n(async function main() {\r\n  var handler = handler1 || handler2 || handler3 // set the handler \r\n\r\n  var call = () => new Promise(async (resolve, reject) => {\r\n    var event = undefined\r\n    var context = undefined\r\n    \r\n    if (isAsync(handler)) {\r\n      try {\r\n        // await the result\r\n        var res = await handler(event, context, (err, succ) => {})\r\n        resolve(res)        \r\n      } catch (err) {\r\n        reject(err)\r\n      }      \r\n    } else {\r\n      // use the callback to get the result\r\n      handler(event, context, function(err, succ) {\r\n        if (err) reject(err)\r\n        else resolve(succ)\r\n      })\r\n    }\r\n  })\r\n\r\n  var res = await call()\r\n  console.log(''RESULT'', res || null)\r\n\r\n})()\r\n\r\nfunction isAsync(fn) {\r\n   return fn.constructor.name === ''AsyncFunction''\r\n}\r\n</pre>\r\n\r\n<p>When the handler is set to <code>handler1</code> the result <code>null</code> is returned, when <code>handler2</code> is used the result value is <code>resolved</code> as well as with <code>handler3</code> - exactly the same as observed.</p>\r\n\r\n<h2>Final Thoughts</h2>\r\n<p>Well, the simulation above doesn''t behave 100%, for example when there is no promising (like <code>setTimeout(...)</code>) in an <code>async</code> handler, the AWS Lambda executor will still take account of the callback function.</p>\r\n<p>And this is exactly what I find so confusing - it''s easy to overlook that and be suprised of the very new (and very wrong) results...</p>\r\n<p>I wrote the simulation code to understand its behaviour as a rule of thumb - keep in mind:</p>\r\n<ul>\r\n  <li><code>async</code> &rArr; <code>return</code></li>\r\n  <li>no <code>async</code> &rArr; <code>callback</code></li>\r\n</ul>\r\n\r\n<p>Happy serverlessing!</p>  ', 0, 'admin', 1, 'false', 'false', 1531318596, 'false'),
(27, 'Process Watch Dog Released!', 1507387373, 'It''s a good idea to work with external processes to prevent the system from failure especially when the process is very resources-demanding. \r\n<br/>But what if something goes wrong?\r\n<br/>Let the <em>watch dog</em> out!', 0, 0, '<pre class="brush: xml">&lt;dependency&gt;\r\n&nbsp; &nbsp; &lt;groupId&gt;cz.net21.ttulka.exec&lt;/groupId&gt;\r\n&nbsp; &nbsp; &lt;artifactId&gt;process-watch-dog&lt;/artifactId&gt;\r\n&nbsp; &nbsp; &lt;version&gt;1.0.0&lt;/version&gt;\r\n&lt;/dependency&gt;</pre> \r\n<p>Consider a very simple tooling class for executing new processes. Put the watch dog to kill processes after 2 minutes:</p> \r\n<pre class="brush: java">import cz.net21.ttulka.exec.ProcessWatchDog;\r\n\r\npublic class ProcessExecutorTool {\r\n\r\n&nbsp; &nbsp; private static int TIMEOUT = 2 ✱ 60 ✱ 1000; // 2 minutes\r\n\r\n&nbsp; &nbsp; private static ProcessWatchDog watchDog = new ProcessWatchDog();\r\n\r\n&nbsp; &nbsp; public static int executeExternalProcess(String... cmd) {\r\n&nbsp; &nbsp; &nbsp; &nbsp; try {\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ProcessBuilder builder = new ProcessBuilder(cmd);\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Process process = builder.start();\r\n\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; watchDog.watch(process, TIMEOUT);   // release the dog!</pre> \r\n<pre class="brush: java">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; process.waitFor();\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; return process.exitValue();</pre> \r\n<pre class="brush: java">&nbsp; &nbsp; &nbsp; &nbsp; } catch (Exception e) {\r\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; throw new RuntimeException("Exception by executing ''" + cmd + "''.", e);\r\n&nbsp; &nbsp; &nbsp; &nbsp; }\r\n&nbsp; &nbsp; }\r\n}</pre> \r\n<p>All about:&nbsp;<a href="https://github.com/ttulka/process-watch-dog"><strong>https://github.com/ttulka/process-watch-dog</strong></a> </p> \r\n<p>Happy watching!</p>', 1, 'admin', 1, 'false', 'true', 1509560262, 'false'),
(28, 'Boundary I/O Streams Released!', 1509557686, 'New Java library for working with <strong>boundary I/O streams</strong> was released.\r\n<br/> \r\nThis library provides classes for processing multiple streams withing a single stream bounded by a specific boundary content.\r\n<br/> \r\nLet''s take a deeper look at its functionality...', 0, 0, '<p>First of all, put the Maven dependency into your <code>pom.xml</code>:</p> \r\n<pre class="brush: xml">&lt;dependency&gt;\r\n    &lt;groupId&gt;cz.net21.ttulka.io&lt;/groupId&gt;\r\n    &lt;artifactId&gt;boundary-io-streams&lt;/artifactId&gt;\r\n    &lt;version&gt;1.0.0&lt;/version&gt;\r\n&lt;/dependency&gt;&nbsp;</pre> \r\n<p> </p> \r\n<p> </p> \r\n<p>Consider a simple use-case: a files streaming service into the <code>stdout</code>.</p> \r\n<pre class="brush: java">public class FileStreamService {\r\n\r\n    public static void main(String[] args) throws IOException {\r\n        try (BoundaryOutputStream bos = new BoundaryOutputStream(System.out)) {\r\n\r\n            for (String filename : args) {\r\n                try (InputStream is = new FileInputStream(filename)) {\r\n\r\n                    org.apache.commons.io.IOUtils.copy(is, bos);  // see https://commons.apache.org/io\r\n                    bos.boundary();                               // separate the stream with the boundary\r\n                }\r\n            }\r\n        }\r\n    }\r\n}&nbsp;</pre> \r\n<p>When you run the service from the command line</p> \r\n<pre>java FileStreamService /data/text1.txt /data/text2.txt&nbsp;</pre> \r\n<p>You get something similar like:</p> \r\n<pre>Content of the text1.txt-----StreamBoundary-----Content of the text2.txt-----StreamBoundary-----&nbsp;</pre> \r\n<p>Notice that the class&nbsp;<code>BoundaryOutputStream</code> is nothing more than a convenient class, you don''t need this class to create such a stream with standard Java I/O classes.</p> \r\n<h2>Reading a Multiple Stream&nbsp;</h2> \r\n<p>For reading a multiple stream you can use the class&nbsp;<code>BoundaryInputStream</code> direct or wrap it into a convenient iterable class <code>IterableBoundaryInputStream</code>. We show the second approach:</p> \r\n<pre class="brush: java">InputStream in = callFileStreamingService();\r\n\r\ntry (BoundaryInputStream bis = new BoundaryInputStream(in)) {\r\n    IterableBoundaryInputStream ibis = new IterableBoundaryInputStream(bis);\r\n\r\n    for (InputStream is : ibis) {                \r\n        // do something with the stream\r\n    }\r\n}</pre> \r\n<p>The method&nbsp;<code>callFileStreamingService</code> calls the service above and returns its stream as the input for the <code>BoundaryInputStream</code>.</p> \r\n<p>More details at&nbsp;<a href="https://github.com/ttulka/boundary-io-streams" target="_blank" title="ttulka/boundary-io-streams">https://github.com/ttulka/boundary-io-streams</a>.</p> \r\n<p>Happy streaming!</p> \r\n<p> </p> \r\n<p> </p>', 1, 'admin', 1, 'false', 'true', 1509561040, 'false'),
(29, 'Process Watch Dog with Heartbeat Released!', 1510335660, 'It''s nice to watch a process execution and kill frozen processes after timeout, but when a process is supplying data is not frozen even when it takes a long time.\r\n<br/> \r\nRelease 1.1.0 introduces a new process wrapper to send a <strong>heartbeat to reset the timeout</strong> explicitly or automatically with every read byte.', 0, 0, '<pre class="brush: xml">&lt;dependency&gt;\r\n    &lt;groupId&gt;cz.net21.ttulka.exec&lt;/groupId&gt;\r\n    &lt;artifactId&gt;process-watch-dog&lt;/artifactId&gt;\r\n    &lt;version&gt;1.1.0&lt;/version&gt;\r\n&lt;/dependency&gt;</pre> \r\n<p>Putting a process into watching returns a process wrapper:</p> \r\n<pre class="brush: java">Process process = ...\r\n\r\nProcessWatchDog watchDog = new ProcessWatchDog();\r\n\r\nWatchedProcess watchedProcess = watchDog.watch(process, 1000);</pre> \r\n<p>Because the class <code>WatchedProcess</code> extends stadard Java class Process, we can do simply:</p> \r\n<pre class="brush: java">process = watchDog.watch(process, 1000);</pre> \r\n<p>Now, a heartbeat will be sent every time we read from the process input stream:</p> \r\n<pre class="brush: java">InputStream is = process.getInputStream();\r\nint b;\r\nwhile ((b = is.read()) != -1) {\r\n    // heartbeat is sent implicitly with every successful call of `read()` \r\n}</pre> \r\n<p>To send a heartbeat explicitly, we can do it via the WatchedProcess object:</p> \r\n<pre class="brush: java">wp.heartBeat();</pre> \r\n<p>Or simply tell the Watch Dog to do it:</p> \r\n<pre class="brush: java">watchDog.heartBeat(process);   // we don''t need the `WatchedProcess` object here</pre> \r\n<p>Previous post about the Watch Dog: <a href="/index.php?/archives/27-Process-Watch-Dog-Released!.html">Process Watch Dog Released!</a></p> \r\n<p>All about:&nbsp;<a href="https://github.com/ttulka/process-watch-dog"><strong>https://github.com/ttulka/process-watch-dog</strong></a></p> \r\n<p>Happy heartbeating!</p> \r\n<p> </p>', 1, 'admin', 1, 'false', 'true', 1510335755, 'false'),
(30, 'Stop Boundary I/O Streams Released!', 1512587038, 'The <a href="https://github.com/ttulka/boundary-io-streams" title="boundary-io-streams">library for boundary I/O streams</a> brought the possibility to work with multiple stream written in a single stream.\r\n<br/> \r\nBut what if the stream continues further without containing any more sub-stream? In this case we can use the new released <strong>Stop Boundary Stream</strong> feature from the same library to ignore the rest of the stream after a boundary was reached.', 0, 0, '<pre class="brush: xml">&lt;dependency&gt;\r\n    &lt;groupId&gt;cz.net21.ttulka.io&lt;/groupId&gt;\r\n    &lt;artifactId&gt;boundary-io-streams&lt;/artifactId&gt;\r\n    &lt;version&gt;1.2.0&lt;/version&gt;\r\n&lt;/dependency&gt;</pre> \r\n<p>To stop consuming a stream after a boundary was reached it is possible to use the <code>StopBoundaryInputStream</code> class and the convenience class <code>StopBoundaryOutputStream</code> to generate such a stream. The stop boundary streaming is still using a boundary to separate sub-streams, but when a stop boundary occurs the rest of the input stream is ignored.</p> \r\n<p>Let''s take a look at a simple example:&nbsp;</p> \r\n<pre class="brush: java">String[] values = {\r\n    "abcde", "ABCDE", "12345"\r\n};\r\n\r\nbyte[] boundary = "|".getBytes();\r\nbyte[] stopBoundary = "#".getBytes();\r\n\r\nByteArrayOutputStream bytes = new ByteArrayOutputStream();\r\n\r\nStopBoundaryOutputStream out = new StopBoundaryOutputStream(bytes, boundary, stopBoundary);\r\n\r\nfor (String s : values) {\r\n    out.write(s.getBytes());\r\n    out.boundary();\r\n}\r\nout.stopBoundary();\r\nout.write("xyz".getBytes());    // some junk at the end\r\n\r\n//System.out.println(bytes);    // prints `abcde|ABCDE|12345|#xyz`\r\n\r\nStopBoundaryInputStream in = new StopBoundaryInputStream(\r\n        new ByteArrayInputStream(bytes.toByteArray()), boundary, stopBoundary);\r\n\r\nfor (InputStream is : in) {\r\n    int b;\r\n    while ((b = is.read()) != -1) {\r\n        System.out.print((char) b);\r\n    }\r\n    System.out.println();\r\n}\r\n\r\n// close streams...\r\n</pre> \r\n<p>The code above prints:</p> \r\n<pre>abcde\r\nABCDE\r\n12345\r\n</pre> \r\n<p>Previous post about the library: <a href="/index.php?/archives/28-Boundary-IO-Streams-Released%21.html">Boundary I/O Streams Released!</a></p> \r\n<p>All about: <a href="https://github.com/ttulka/boundary-io-streams"><strong>https://github.com/ttulka/boundary-io-streams</strong></a></p> \r\n<p> </p> \r\n<p>Happy streaming!</p>', 1, 'admin', 1, 'false', 'true', 1512587038, 'false'),
(31, 'Debugging jasmine-ts in IntelliJ IDE', 1522241674, 'TypeScript application wants tests to be written in TypeScript as well, right?<br/> \r\nThere is a great library to achive this: <a href="https://www.npmjs.com/package/jasmine-ts" target="_blank">jasmine-ts</a> <br/> \r\nBut how to debug such tests within your&nbsp;IntelliJ IDE?', 267, 0, '<p>You need to use the Node.js plugin and configure it to run/debug the <code>jasmine-ts</code> like following:</p> \r\n<p><img src="/storage/jasmine-ts-debug.png" alt="jasmine-ts debug from IntelliJ" width="100%" /></p> \r\n<p>I''m developing under Windows, but for Mac or Linux would be the situation almost the same.</p> \r\n<p>The meaning of the settings is following:</p> \r\n<p> </p> \r\n<ul> \r\n<li><em>Working directory</em> is the location of my TypeScript project, generally it the directory where your Jasmine configuration is located.</li> \r\n<li><em>JavaScript file</em> is the <code>jasmine-ts</code> bootstrap file. My local <code>npm</code>&nbsp;repository is located in my home ordner under&nbsp;<code>AppData\\Roaming\\npm\\node_modules</code>, this is the folder where <code>jasmine-ts</code> is installed into.</li> \r\n<li><em>Application parameters</em> are used to debug a concrete test suite. If you want to debug all the Jasmine tests, leave this field empty. In my case, all my Jasmine test files are located under the <code>test</code> sub-folder in my project directory.</li> \r\n</ul> \r\n<p>Then just set up some breakpoints and click the Run/Debug button.</p> \r\n<p>Here we go...&nbsp;</p> \r\n<p>Happy debugging!</p> \r\n<p> </p>', 1, 'admin', 1, 'false', 'true', 1522800799, 'false'),
(32, 'Meaning of Queues and Topics in AWS', 1523467800, '<em>Queues</em> and <em>topics</em> are standard communication channels in messaging systems.\r\n<br/> \r\nHow to use then in <strong>AWS</strong>, for example to implement the&nbsp;<a href="http://www.enterpriseintegrationpatterns.com/patterns/messaging/CompetingConsumers.html" target="_blank" title="Competing Consumers">Competing Consumers</a> pattern?', 871, 0, '<p>Let''s consider a following scenario:</p> \r\n<p>A REST endpoint (Amazon API Gateway‎) initiates a time expensive processing served by a serverless function (AWS Lambda). Not only because of the max timeout 30 seconds on the gateway it is not a good idea to process the request synchronously (see <a href="https://www.reactivemanifesto.org" title="The Reactive Manifesto">The Reactive Manifesto</a>).&nbsp;</p> \r\n<p>Let''s build a queue of working tasks into the middle between the gateway and the worker function:</p> \r\n<pre>Request --&gt; Queue --&gt; Worker&nbsp;</pre> \r\n<p>Immediately after a request comes it is put into the queue and taken by a worker function to the processing.</p> \r\n<p>To implement this in AWS the tasks queue is not a queue (SQS) at all, but a topic (SNS). Let''s&nbsp;explain why.</p> \r\n<p>In a standard non-serverless implementation will be workers listening on the queue and distributing the tasks among each other. It means the queue is a <em>pull</em> mechanism.</p> \r\n<p>Serverless service creates as many worker instances as needed. So there is no need to keep tasks in a queue while they are processed immediately as put into the queue. Initialization of the worker function must be event-driven (a lambda function must never&nbsp;idle!) - implementing a <em>push</em> mechanism.</p> \r\n<p>There is no change to register a lambda function to a queue, for such a usage there is another concept - topics:</p> \r\n<pre>Request --&gt; Topic --&gt; Worker</pre> \r\n<p>As the request comes a task is put into the topic and processed by the lambda function, elastically created on demand.</p> \r\n<p>So, that''s the meaning of queues and topics in AWS.</p> \r\n<p>Happy clouding!</p>', 1, 'admin', 1, 'false', 'true', 1524763348, 'false');
INSERT INTO `serendipity_entries` (`id`, `title`, `timestamp`, `body`, `comments`, `trackbacks`, `extended`, `exflag`, `author`, `authorid`, `isdraft`, `allow_comments`, `last_modified`, `moderate_comments`) VALUES
(33, 'PHP Restful API Microservices', 1525189403, 'How difficult is to properly implement the <strong>microservices design pattern in PHP</strong>? It will definitely need some thinking and maybe to leave some convince behind. At the end of the day we should have an autonomous loosely coupled service with all the benefits (and drawbacks) of microservices.<br/>In this article we do a little walk-through of a development process of a small RESTful microservice in PHP and we take a look at some Domain-Driven Design (DDD) theory as well.', 0, 0, '<div>Consider a simple <a href="https://en.wikipedia.org/wiki/Create,&#95;read,&#95;update&#95;and&#95;delete" target="_blank" title="CRUD">CRUD</a> service for a blog articles management. Via this <a href="https://martinfowler.com/articles/richardsonMaturityModel.html" target="_blank" title="REST">REST</a> API you can list, create, update and delete articles in the database (or whatever the persistence is).</div> \r\n<div> \r\n<p>We will implement this service following the <a href="https://martinfowler.com/articles/microservices.html" target="_blank" title="Microservices">microservices design pattern</a> so we create a single REST endpoint (<code>/articles</code>) serving all the request.&nbsp;<br />Similarly we would create endpoint for the categories and authors management.</p> \r\n<p>First of all, let''s prepare the infrastructure.</p> \r\n<h2>Database Schema and Test-Data</h2> \r\n<p>Traditionally, we use a <strong>MySQL database</strong> with a following schema:&nbsp;</p> \r\n<pre class="brush: sql">CREATE SCHEMA `blog` DEFAULT CHARACTER SET utf8;\r\n\r\nCREATE TABLE `blog`.`categories` (\r\n&nbsp; `id` INT NOT NULL AUTO&#95;INCREMENT,\r\n&nbsp; `name` VARCHAR(50) NOT NULL,\r\n&nbsp; PRIMARY KEY (`id`));\r\n&nbsp;&nbsp;\r\nCREATE TABLE `blog`.`authors` (\r\n&nbsp; `id` INT NOT NULL AUTO&#95;INCREMENT,\r\n&nbsp; `name` VARCHAR(50) NOT NULL,\r\n&nbsp; `email` VARCHAR(50) NOT NULL,\r\n&nbsp; PRIMARY KEY (`id`));\r\n\r\nCREATE TABLE `blog`.`articles` (\r\n&nbsp; `id` INT NOT NULL AUTO&#95;INCREMENT,\r\n&nbsp; `title` VARCHAR(100) NOT NULL,\r\n&nbsp; `summary` TEXT(1000) NOT NULL,\r\n&nbsp; `body` TEXT NOT NULL,\r\n&nbsp; `createdAt` DATE&nbsp; NOT NULL,\r\n&nbsp; `categoryId` INT NOT NULL,\r\n&nbsp; `authorId` INT NOT NULL,\r\n&nbsp; PRIMARY KEY (`id`),\r\n&nbsp; INDEX `categoryId&#95;idx` (`categoryId` ASC),\r\n&nbsp; INDEX `authorId&#95;idx` (`authorId` ASC),\r\n&nbsp; CONSTRAINT `category&#95;fk`\r\n&nbsp; &nbsp; FOREIGN KEY (`categoryId`)\r\n&nbsp; &nbsp; REFERENCES `blog`.`categories` (`id`),\r\n&nbsp; CONSTRAINT `author&#95;fk`\r\n&nbsp; &nbsp; FOREIGN KEY (`authorId`)\r\n&nbsp; &nbsp; REFERENCES `blog`.`authors` (`id`));&nbsp;</pre> \r\n<p>Then, let''s put one author, two categories and three articles into the database.</p> \r\n<pre class="brush: sql">INSERT INTO `blog`.`authors` (`id`, `name`, `email`)\r\n&nbsp; VALUES (0, ''Tomas Tulka'', ''tomas.tulka@gmail.com'');\r\n\r\nINSERT INTO `blog`.`categories` (`id`, `name`)\r\n&nbsp; VALUES (0, ''PHP''), (0, ''Java'');\r\n\r\nINSERT INTO `blog`.`articles` (`id`, `title`, `summary`, `body`, `createdAt`, `categoryId`, `authorId`)\r\n&nbsp; VALUES \r\n&nbsp; &nbsp; (0, ''Sample PHP blog post'',&nbsp;\r\n&nbsp; &nbsp; ''Lorem ipsum dolor sit amet.'',\r\n&nbsp; &nbsp; ''Sed vitae tincidunt magna. Sed pretium neque commodo mauris lobortis, quis finibus dolor malesuada.'',\r\n&nbsp; &nbsp; ''2018-05-01'', 1, 1),&nbsp;\r\n&nbsp; &nbsp; (0,&nbsp; ''Another PHP blog post'',&nbsp;\r\n&nbsp; &nbsp; ''Donec id pellentesque elit, sit amet accumsan mi.'',\r\n&nbsp; &nbsp; ''Duis molestie tellus quis orci venenatis, ac pretium quam malesuada. Vivamus congue justo nulla, sit amet pharetra purus condimentum at.'',\r\n&nbsp; &nbsp; ''2018-05-02'', 1, 1),&nbsp;\r\n&nbsp; &nbsp; (0,&nbsp; ''Java blog post'',&nbsp;\r\n&nbsp; &nbsp; ''Praesent porta sagittis diam non interdum.'',\r\n&nbsp; &nbsp; ''Semper a nunc nec dapibus. Sed tristique vel ipsum vitae euismod. Aenean vel nibh ac diam ullamcorper porta id at purus.'',\r\n&nbsp; &nbsp; ''2018-05-02'', 2, 1);</pre> \r\n<p>After creating the database schema and putting some test data, we can discuss the service architecture design.&nbsp;</p> \r\n<h2>REST API&nbsp;</h2> \r\n<p>We will use the <a href="https://martinfowler.com/articles/richardsonMaturityModel.html#level2" title="REST Verbs">Richardson Maturity Model</a> approach of <strong>HTTP verbs</strong>, simply:&nbsp;</p> \r\n<p> </p> \r\n<ul> \r\n<li><code>GET endpoint</code> - listing items</li> \r\n<li><code>GET endpoint/{id}</code> - item detail</li> \r\n<li><code>POST endpoint</code> - creating a new item</li> \r\n<li><code>PUT endpoint/{id}</code> -&nbsp;updating an existing item</li> \r\n<li><code>DELETE&nbsp;endpoint/{id}</code> - deleting an existing item</li> \r\n</ul> \r\n<p> </p> \r\n<h2>Microservices and Domain-Driven Design</h2> \r\n<p>We will model our microservice around a <a href="https://martinfowler.com/bliki/DDD&#95;Aggregate.html" target="_blank" title="DDD Aggregate">DDD Aggregate</a>, in this case around the&nbsp;<em>Article</em>.</p> \r\n<p>For sake of simplicity we model our Article aggregate as an <a href="https://martinfowler.com/bliki/AnemicDomainModel.html" target="_blank" title="Anemic Domain Model">Anemic Domain Entity</a>. With a maturer domain model the entity should be modeled as immutable object, created only via a constructor or a Factory, containing only getters and behavior methods. Such a domain object shouldn''t be definitely exposed to the client''s view (like we are doing), but should be transformed into a <a href="https://en.wikipedia.org/wiki/Data&#95;transfer&#95;object" target="_blank" title="DTO">DTO</a>.</p> \r\n<p><code><strong>domain/Article.php</strong></code> </p> \r\n<pre class="brush: php">class Article { \r\n    public $id;\r\n    public $title;\r\n    public $summary;\r\n    public $body;\r\n    public $createdAt;\r\n    \r\n    public $categoryId;\r\n    \r\n    public $author;         \r\n}\r\n\r\nclass ArticleAuthor {  \r\n    public $id;\r\n    public $name;\r\n    public $email;\r\n}&nbsp;</pre> \r\n<p>Why is there the class <code>ArticleAuthor</code>, why don''t we create a separate class <em>Author</em> for that purpose? Well, we just don''t need all the data of the author, an article needs only few of them. If, in the future, more attributes will be added to the <em>Author</em> entity, the Article structure should stay untouched. The object of the class <code>ArticleAuthor</code> is an <a href="https://martinfowler.com/bliki/ValueObject.html" target="_blank" title="Value Object">Value Object</a> and is accessible only thru the aggregate''s root. So remains the Article consistent event when the Author entity changes its structure. Instead of ArticleAuthor we can use the name Author within different namespaces (<code>articles</code>&nbsp;and&nbsp;<code>authors</code>).</span></p> \r\n<h2>Persistence</h2> \r\n<p>According the DDD theory, <strong>each aggregate has a matching repository</strong>.&nbsp;The repository is the mechanism you should use to retrieve and persist aggregates. Obviously, we will persist the data into a database, but the <strong>persistence is a point of decision</strong> which could be (and should be) made at the latest possible point. And this is exactly what a repository makes possible.</p> \r\n<p><code><strong>domain/ArticleRepo.php</strong></code></p> \r\n<pre class="brush: php">require&#95;once &#95;&#95;DIR&#95;&#95; . ''/Article.php'';\r\n\r\ninterface ArticleRepo { \r\n    public function fetchAll($categoryId, $authorId, $start, $limit);    \r\n    public function fetchOne($id);    \r\n    public function create(Article $article);    \r\n    public function update($id, Article $article);    \r\n    public function delete($id);\r\n}</pre> \r\n<p>This <strong>interface decouples the client code</strong> (the service) from the persistence decision. It can be for example implemented as an in-memory storage in the early phases of the development.</p> \r\n<p>We create a <a href="http://php.net/manual/book.pdo.php" title="PDO">PDO</a>-based implementation:</p> \r\n<p><code><strong>infrastructure/ArticleRepoPDO.php</strong></code></p> \r\n<pre class="brush: php">require&#95;once &#95;&#95;DIR&#95;&#95; . ''/../domain/Article.php'';\r\nrequire&#95;once &#95;&#95;DIR&#95;&#95; . ''/../domain/ArticleRepo.php'';\r\n\r\nclass ArticleRepoPDO implements ArticleRepo {\r\n \r\n    private $conn;\r\n    \r\n    private $articles&#95;table = ''articles'';\r\n    private $articles&#95;categories&#95;table = ''categories'';\r\n    private $authors&#95;table = ''authors'';\r\n  \r\n    public function &#95;&#95;construct(PDO $conn){                                           \r\n        $this-&gt;conn = $conn;\r\n    }\r\n    \r\n    function fetchAll($categoryId = null, $authorId = null, $start = 0, $limit = 10) {   \r\n        $q = "SELECT a.id, a.title, a.summary, a.createdAt, a.categoryId, a.authorId, au.name authorName, au.email authorEmail\r\n                FROM {$this-&gt;articles&#95;table} a\r\n                    LEFT JOIN {$this-&gt;authors&#95;table} au ON a.authorId = au.id\r\n                WHERE 1=1 ";\r\n                \r\n        $params = array(''start'' =&gt; (int)$start, ''limit'' =&gt; (int)$limit);\r\n\r\n        if ($categoryId) {\r\n            $q .= " AND a.categoryid = :categoryId";\r\n            $params[''categoryId''] = (int)$categoryId;\r\n        }\r\n        if ($authorId) {\r\n            $q .= " AND a.authorId = :authorId";\r\n            $params[''authorId''] = (int)$authorId;\r\n        }                    \r\n                    \r\n        $q .="  ORDER BY a.createdAt DESC, a.id DESC\r\n                LIMIT :start,:limit";\r\n        \r\n        $stmt = $this-&gt;conn-&gt;prepare($q);\r\n        \r\n        foreach ($params as $param =&gt; $value) {\r\n            $stmt-&gt;bindValue($param, $value, PDO::PARAM&#95;INT);\r\n        }\r\n        \r\n        $stmt-&gt;execute();\r\n        \r\n        $articles = array();  \r\n               \r\n        while ($row = $stmt-&gt;fetch(PDO::FETCH&#95;ASSOC)){\r\n          $article = new Article();\r\n          \r\n          $article-&gt;id = (int)$row[''id''];\r\n          $article-&gt;title = $row[''title''];\r\n          $article-&gt;summary = $row[''summary''];\r\n          $article-&gt;createdAt = $row[''createdAt''];\r\n          $article-&gt;categoryId = (int)$row[''categoryId''];\r\n          \r\n          $article-&gt;author = new ArticleAuthor();\r\n          $article-&gt;author-&gt;id = (int)$row[''authorId''];\r\n          $article-&gt;author-&gt;name = $row[''authorName''];\r\n          $article-&gt;author-&gt;email = $row[''authorEmail''];\r\n          \r\n          array&#95;push($articles, $article);\r\n        }\r\n             \r\n        return $articles;\r\n    }\r\n    \r\n    public function fetchOne($id) {\r\n        $q = "SELECT a.id, a.title, a.summary, a.body, a.createdAt, a.categoryId, a.authorId, au.name authorName, au.email authorEmail\r\n                FROM {$this-&gt;articles&#95;table} a\r\n                    LEFT JOIN {$this-&gt;authors&#95;table} au ON a.authorId = au.id\r\n                WHERE a.id = :id ";\r\n                        \r\n        $stmt = $this-&gt;conn-&gt;prepare($q);        \r\n        $stmt-&gt;bindValue(''id'', (int)$id, PDO::PARAM&#95;INT);        \r\n        $stmt-&gt;execute();\r\n        \r\n        $article = null;  \r\n               \r\n        if ($row = $stmt-&gt;fetch(PDO::FETCH&#95;ASSOC)){\r\n          $article = new Article();\r\n          \r\n          $article-&gt;id = (int)$row[''id''];\r\n          $article-&gt;title = $row[''title''];\r\n          $article-&gt;summary = $row[''summary''];\r\n          $article-&gt;body = $row[''body''];\r\n          $article-&gt;createdAt = $row[''createdAt''];\r\n          $article-&gt;categoryId = (int)$row[''categoryId''];\r\n          \r\n          $article-&gt;author = new ArticleAuthor();\r\n          $article-&gt;author-&gt;id = (int)$row[''authorId''];\r\n          $article-&gt;author-&gt;name = $row[''authorName''];\r\n          $article-&gt;author-&gt;email = $row[''authorEmail''];\r\n        }\r\n             \r\n        return $article;\r\n    }\r\n    \r\n    public function create($article) {\r\n        $q = "INSERT INTO {$this-&gt;articles&#95;table} (id, title, summary, body, createdAt, categoryId, authorId)\r\n                VALUES (0, \r\n                  ''{$article-&gt;title}'', \r\n                  ''{$article-&gt;summary}'', \r\n                  ''{$article-&gt;body}'', \r\n                  ''{$article-&gt;createdAt}'', \r\n                  {$article-&gt;categoryId}, \r\n                  {$article-&gt;authorId}\r\n                )";\r\n                        \r\n        $stmt = $this-&gt;conn-&gt;prepare($q);        \r\n        $stmt-&gt;execute(); \r\n        \r\n        $article-&gt;id = $this-&gt;conn-&gt;lastInsertId();\r\n        \r\n        return $article;   \r\n    }\r\n    \r\n    public function update($id, $article) {\r\n        $q = "UPDATE {$this-&gt;articles&#95;table}\r\n                SET title = ''{$article-&gt;title}'', \r\n                    summary = ''{$article-&gt;summary}'', \r\n                    body = ''{$article-&gt;body}'', \r\n                    createdAt = ''{$article-&gt;createdAt}'', \r\n                    categoryId = {$article-&gt;categoryId}, \r\n                    authorId = {$article-&gt;authorId}\r\n                WHERE id = :id";\r\n                        \r\n        $stmt = $this-&gt;conn-&gt;prepare($q);        \r\n        $stmt-&gt;bindValue(''id'', (int)$id, PDO::PARAM&#95;INT);        \r\n        $stmt-&gt;execute();\r\n                \r\n        $count = $stmt-&gt;rowCount();        \r\n        return $count &gt; 0;   \r\n    }\r\n    \r\n    public function delete($id) {\r\n        $article = $this-&gt;fetchOne($id);\r\n        if ($article === null) {\r\n            return false;\r\n        }\r\n        \r\n        $q = "DELETE FROM {$this-&gt;articles&#95;table} WHERE id = :id ";\r\n        \r\n        $stmt = $this-&gt;conn-&gt;prepare($q);                                  \r\n        $stmt-&gt;bindValue(''id'', (int)$id, PDO::PARAM&#95;INT);        \r\n        $stmt-&gt;execute();\r\n        \r\n        $count = $stmt-&gt;rowCount();        \r\n        return $count &gt; 0;\r\n    }\r\n}&nbsp;</pre> \r\n<p>Constructor of the repository class needs a PDO database connection. We deal with that with a help of the <em>Factory</em> pattern.</p> \r\n<p>We create a <code>Database</code> interface which must be implemented by all the persistence providers, MySQL in our case:</p> \r\n<p><code><strong>infrastructure/db/Database.php</strong></code></p> \r\n<pre class="brush: php">interface Database { \r\n    public function getConnection();  // returns a PDO connection object\r\n}&nbsp;</pre> \r\n<p><code><strong>infrastructure/db/DatabaseMySql.php</strong></code></p> \r\n<pre class="brush: php">require&#95;once &#95;&#95;DIR&#95;&#95; . ''/Database.php'';\r\n\r\nclass DatabaseMySql implements Database {    \r\n    private $conn;\r\n    \r\n    function &#95;&#95;construct($host, $db, $username, $password) {\r\n        try {\r\n            $this-&gt;conn = new PDO("mysql:host={$host};dbname={$db}", $username, $password);\r\n            $this-&gt;conn-&gt;setAttribute(PDO::ATTR&#95;ERRMODE, PDO::ERRMODE&#95;EXCEPTION);\r\n            $this-&gt;conn-&gt;setAttribute(PDO::MYSQL&#95;ATTR&#95;FOUND&#95;ROWS, true);\r\n            $this-&gt;conn-&gt;exec("set names utf8");\r\n            \r\n        } catch(PDOException $e){\r\n            throw new Exception(''Connection error: '' . $e-&gt;getMessage(), 0, $e);\r\n        }\r\n    }\r\n \r\n    public function getConnection() {\r\n        return $this-&gt;conn;\r\n    }\r\n}&nbsp;</pre> \r\n<p>Our factory has a static method for getting the right PDO connection:</p> \r\n<p><code><strong>infrastructure/db/DatabaseFactory.php</strong></code></p> \r\n<pre class="brush: php">require&#95;once &#95;&#95;DIR&#95;&#95; . ''/DatabaseMySql.php'';\r\n\r\nclass DatabaseFactory {  \r\n  public static function getDatabase($type, $host, $db, $username, $password) {\r\n    switch ($type) {         \r\n      case ''mysql'':\r\n        return new DatabaseMySql($host, $db, $username, $password);        \r\n      default:\r\n        throw new Exception(''Unknown database type: '' . $type);\r\n    } \r\n  }\r\n}</pre> \r\n<p>The factory can be used as following:</p> \r\n<pre class="brush: php">$db = DatabaseFactory::getDatabase(''mysql'', ''localhost'', ''blog'', ''root'', ''1234'');</pre> \r\n<h2>Controller</h2> \r\n<p>The term comes from <a href="https://en.wikipedia.org/wiki/Model%E2%80%93view%E2%80%93controller" target="_blank" title="MVC">MVC</a> design pattern. The responsibility of the controller in the application is to<strong> process the user input into output</strong>. This is the right place where the parameters should be validated (data types, range etc., the business validation is not meant here - that belongs to the domain services), proceeded and transformed back to the client.</p> \r\n<p>The important point here is the controller shouldn''t know anything about the fact, that we''re developing a web application. The web-specifics must be present only in the application itself, as we show in a moment.&nbsp;</p> \r\n<p><code><strong>application/ArticleController.php</strong></code> </p> \r\n<pre class="brush: php">require&#95;once &#95;&#95;DIR&#95;&#95; . ''/../domain/ArticleRepo.php'';\r\n\r\nclass ArticleController {\r\n\r\n  private $repo;\r\n\r\n  public function &#95;&#95;construct(ArticleRepo $repo){                                           \r\n    $this-&gt;repo = $repo;\r\n  }\r\n\r\n  public function detailRequest($id) {\r\n    $article = $this-&gt;repo-&gt;fetchOne((int)$id);\r\n    \r\n    return $article;\r\n  }\r\n  \r\n  public function listRequest($params) {\r\n    $limit = 10;\r\n    \r\n    $categoryId = $this-&gt;getIfSet($params, ''categoryId'');   \r\n    $authorId = $this-&gt;getIfSet($params, ''authorId'');   \r\n    $page = $this-&gt;getIfSet($params, ''page'', 0);\r\n    \r\n    $articles = $this-&gt;repo-&gt;fetchAll((int)$categoryId, (int)$authorId, $page &#42; $limit, $limit);\r\n    \r\n    return $articles;\r\n  }\r\n  \r\n  public function createRequest($params) {\r\n    $article = new Article();\r\n    $article-&gt;title = $params[''title''];\r\n    $article-&gt;summary = $params[''summary''];\r\n    $article-&gt;body = $params[''body''];\r\n    $article-&gt;createdAt = $params[''createdAt''];\r\n    $article-&gt;categoryId = (int)$params[''categoryId''];\r\n    $article-&gt;authorId = (int)$params[''authorId''];\r\n    \r\n    if (!$article-&gt;title || !$article-&gt;summary || !$article-&gt;body || !$article-&gt;createdAt || !$article-&gt;categoryId || !$article-&gt;authorId) {\r\n      return array(''error'' =&gt; ''Incorrect payload.'');\r\n    }\r\n    \r\n    $article = $this-&gt;repo-&gt;create($article);\r\n    \r\n    return (int)$article-&gt;id;\r\n  }\r\n  \r\n  public function updateRequest($id, $params) {\r\n    $article = new Article();\r\n    $article-&gt;title = $params[''title''];\r\n    $article-&gt;summary = $params[''summary''];\r\n    $article-&gt;body = $params[''body''];\r\n    $article-&gt;createdAt = $params[''createdAt''];\r\n    $article-&gt;categoryId = (int)$params[''categoryId''];\r\n    $article-&gt;authorId = (int)$params[''categoryId''];\r\n    \r\n    return $this-&gt;repo-&gt;update($id, $article);\r\n  }\r\n  \r\n  public function deleteRequest($id) {  \r\n    return $this-&gt;repo-&gt;delete($id);\r\n  }\r\n  \r\n  // ///////// HELPER FUNCTIONS /////////////////////////////////////\r\n  \r\n  private function getIfSet($params, $var, $def = null) {\r\n    return isset($params[$var]) ? $params[$var] : $def;\r\n  }\r\n}</pre> \r\n<h2>Putting It All Together&nbsp;</h2> \r\n<p><img src="https://raw.githubusercontent.com/ttulka/blog-assets/master/BlogArticlesDesign.png" alt="Blog Articles Architecture" width="100%"/></p> \r\n<p>The picture above shows the service components, double-lines represent layers boundaries. As you can see, <strong>all the inter-boundary communication is through interfaces</strong>, which define an API of every layer.</p> \r\n<p>Finally we have all the blocks we need to build our service.</p> \r\n<p>To keep things clean, we create a database configuration in a separate file:</p> \r\n<p><code><strong>config/db.config.php</strong></code></p> \r\n<pre>define(''DB&#95;TYPE'', ''mysql''); \r\ndefine(''DB&#95;HOST'', ''localhost''); \r\ndefine(''DB&#95;NAME'', ''blog''); \r\ndefine(''DB&#95;USER'', ''root''); \r\ndefine(''DB&#95;PASS'', ''1234'');&nbsp;</pre> \r\n<p>This configuration will be loaded withing the application code.</p> \r\n<p>The application&nbsp;code is here to <strong>serve the request</strong> and&nbsp;<strong>assembly the components</strong>, this the only &quot;dirty&quot; code doing all the injections; a dependency-injection framework could be used here as well:</p> \r\n<p><code><strong>articles.php</strong></code></p> \r\n<pre class="brush: php">header("Access-Control-Allow-Origin: &#42;");\r\nheader("Content-Type: application/json; charset=UTF-8");\r\n  \r\nrequire&#95;once &#95;&#95;DIR&#95;&#95; . ''/config/db.config.php'';\r\nrequire&#95;once &#95;&#95;DIR&#95;&#95; . ''/application/ArticleController.php'';\r\nrequire&#95;once &#95;&#95;DIR&#95;&#95; . ''/infrastructure/ArticleRepoPDO.php'';\r\nrequire&#95;once &#95;&#95;DIR&#95;&#95; . ''/infrastructure/db/DatabaseFactory.php'';\r\n\r\n$db = DatabaseFactory::getDatabase(DB&#95;TYPE, DB&#95;HOST, DB&#95;NAME, DB&#95;USER, DB&#95;PASS);\r\n\r\n$repo = new ArticleRepoPDO($db-&gt;getConnection());\r\n\r\n$controller = new ArticleController($repo);\r\n\r\n$response = null;\r\n\r\nswitch ($&#95;SERVER[''REQUEST&#95;METHOD'']) {  \r\n  case ''GET'':\r\n    if (isset($&#95;GET[''id''])) {\r\n      $response = $controller-&gt;detailRequest($&#95;GET[''id'']);\r\n      \r\n    } else {\r\n      $response = $controller-&gt;listRequest($&#95;GET);\r\n    }\r\n    if ($response === null) {\r\n      http&#95;response&#95;code(404);\r\n      \r\n    } else {\r\n      echo json&#95;encode($response);\r\n    }\r\n    break;\r\n    \r\n  case ''POST'':\r\n    $&#95;DATA = parseRequestData();\r\n    $response = $controller-&gt;createRequest($&#95;DATA);\r\n    \r\n    if ($response === null) {\r\n      http&#95;response&#95;code(400);       \r\n    \r\n    } else {\r\n      http&#95;response&#95;code(201);\r\n      echo json&#95;encode($response);\r\n    }\r\n    break;                           \r\n  \r\n  case ''PUT'':\r\n    if (!isset($&#95;GET[''id''])) {\r\n      http&#95;response&#95;code(400);\r\n      echo json&#95;encode(array(''error'' =&gt; ''Missing "id" parameter.''));\r\n    }\r\n  \r\n    $&#95;DATA = parseRequestData();\r\n    $response = $controller-&gt;updateRequest($&#95;GET[''id''], $&#95;DATA);\r\n    \r\n    if ($response === false) {\r\n      http&#95;response&#95;code(404);\r\n      echo json&#95;encode(array(''error'' =&gt; ''Article not found.''));\r\n    } else {\r\n      http&#95;response&#95;code(204);\r\n    }\r\n    break;\r\n    \r\n  case ''DELETE'':\r\n    if (!isset($&#95;GET[''id''])) {\r\n      http&#95;response&#95;code(400);\r\n      header("Location: {$&#95;SERVER[''REQUEST&#95;URI'']}/{$response}");\r\n    }\r\n    \r\n    $response = $controller-&gt;deleteRequest($&#95;GET[''id'']);\r\n    \r\n    if ($response === false) {\r\n      http&#95;response&#95;code(404);\r\n      echo json&#95;encode(array(''error'' =&gt; ''Article not found.''));\r\n    } else {\r\n      http&#95;response&#95;code(204);\r\n    } \r\n    break;\r\n    \r\n  case ''OPTIONS'':\r\n    header(''Allow: GET POST PUT DELETE OPTIONS'');\r\n    break;\r\n        \r\n  default:\r\n    http&#95;response&#95;code(405);\r\n    header(''Allow: GET POST PUT DELETE OPTIONS'');\r\n}\r\n\r\n// ///////// HELPER FUNCTIONS /////////////////////////////////////\r\n\r\nfunction parseRequestData() {\r\n  $contentType = explode('';'', $&#95;SERVER[''CONTENT&#95;TYPE'']);\r\n  $rawBody = file&#95;get&#95;contents(''php://input'');\r\n  $data = array();\r\n  \r\n  if (in&#95;array(''application/json'', $contentType)) {\r\n    $data = json&#95;decode($rawBody, true);\r\n    \r\n  } else {\r\n    parse&#95;str($data, $data);\r\n  }\r\n  \r\n  return $data;\r\n}</pre> \r\n<h2>Production</h2> \r\n<p>In production we want our API to be agnostic of the underlying technology. We can achieve that via setting rules of the HTTP server:</p> \r\n<p><code><strong>.htaccess</strong></code></p> \r\n<pre class="brush: plain">RewriteEngine On\r\nRewriteRule ^articles$ articles.php [NC,L]\r\nRewriteRule ^articles/([0-9]+)$ articles.php?id=$1 [NC,L]&nbsp;</pre> \r\n<p>And now we can call the endpoint without the <code>.php</code> suffix.</p> \r\n<h2>Usage&nbsp;</h2> \r\n<p>The usage is pretty straight-forward:</p> \r\n<pre>curl http://localhost/articles\r\ncurl http://localhost/articles?categoryId=1\r\ncurl http://localhost/articles?authorId=1\r\ncurl http://localhost/articles?categoryId=1&amp;authorId=1\r\n\r\ncurl http://localhost/articles/1\r\n\r\ncurl http://localhost/articles -X POST -H "Content-Type: application/json" -d @data.json\r\n\r\ncurl http://localhost/articles/4 -X PUT -H "Content-Type: application/json" -d @data.json\r\n\r\ncurl http://localhost/articles/4 -X DELETE&nbsp;</pre> \r\n<p><code><strong>data.json</strong></code></p> \r\n<pre class="brush: plain">{ "title": "New article", \r\n  "summary": "Lorem ipsum", \r\n  "body": "Lorem ipsum dolor sit amet", \r\n  "createdAt": "2018-05-03", \r\n  "categoryId": 1, \r\n  "authorId": 1 \r\n}&nbsp;</pre> \r\n<h2>Source Code&nbsp;</h2> \r\n<p>You can find the whole project source code on <a href="https://github.com/ttulka/blog-code-samples/tree/master/php-rest-articles" title="Source code">GitHub</a>.</p> \r\n<p>Enjoy!&nbsp;</p> \r\n</div>', 1, 'admin', 1, 'false', 'true', 1525336147, 'true'),
(113, 'Secure Communication between Services in Multitenant Systems', 1530465300, '<p>Implementing a SaaS as a multitenant system brings a lot of benefits. As usual, there are some tradeoffs, too. For example security becomes more complex. Let''s take a look at possible approaches when implementing security in a multitenant architectrure.</p>', 0, 0, '<p>Let''s consider a trivial example of a communication between two independent services.</p> \r\n<p><img src="/storage/multitenant-security.png" alt="communication between two independent services" /></p> \r\n<p>Service A and Service B are in different realms untrusted to each other.</p> \r\n<h2>Security Levels</h2> \r\n<p>There are several levels of security when talking about a communication between systems:</p> \r\n<h3>1. Security Level: Don''t trust anyone</h3> \r\n<p><img src="/storage/multitenant-security-level-1.png" alt="1. Security level" /></p> \r\n<p>This is the most secure model. It can be achive only by an active client establishing the communication.</p> \r\n<p>In this case, services don''t know anything about each other - the client must know all the communication details and control the whole flow.</p> \r\n<p>If you don''t trust anyone, you have to do everything by yourself...</p> \r\n<h3>2. Security Level:  In your name</h3> \r\n<p><img src="/storage/multitenant-security-level-2.png" alt="2. Security level" /></p> \r\n<p>In this model, a part of the communication is moved to the service code and the calling service acts partially on behalf of the client.</p> \r\n<p>Everytime the client sends its credentials to the Service A he manifests his trust to the service. The Service A uses client''s identity to build trust between Service B. The identity can be implemented for example via a security token.</p> \r\n<p>The Service A can''t communicate with the Service B without client''s identity so it''s unable to access any data but the client''s one.</p> \r\n<h3>3. Security Level:  We''re all friends</h3> \r\n<p><img src="/storage/multitenant-security-level-3.png" alt="3. Security level" /></p> \r\n<p>On this level you practically loose the multitenant-specific secuirity whatsoever. That could be okay in some cases like logging, collecting anonymous statistics etc., but we have to choose out friends carefully.</p> \r\n<p>If such a kind of trust is supported, the Service A can access any data of any client in the Service B. It can even make an identity up which doesn''t exist (if the Service B is just blindly accepting the input).</p> \r\n<p>This model can be implemented using <em>API keys</em> or application certificates.</p> \r\n<h3>4. Security Level:  Whatever makes you happy</h3> \r\n<p>Pretty obvious one - the Service B has a public API accesible without any needed trust.</p> \r\n<p>There are definitely valid use-cases, but don''t make your service public as long as you''re not 100% sure!</p> \r\n<h2>Real-World Example</h2> \r\n<p>We will show a simple model of a multitenant system based on the <b>second security level</b> as described above.</p> \r\n<p>Let''s consider a Service A consuming client''s data and processing them somehow (e.g. saving into a database).</p> \r\n<p>The data can be later used for a post-procesing in the Service B.\r\n</p> \r\n<p>Because the Service A plays only the role of a data source and its business logic is completely independent on the post-processing and the Service B is a general service knowing nothing about its data sources we want to decouple both services as much as possible. Using <em>event-driven architecture</em> makes perfectly sense in this use-case.</p> \r\n<p>We build a plugin Adapter in the Service A to consume the data and forward them to the Service B. The Adapter is conceptually a part of the Service A, but it''s loosly coupled to it and can be plugged-in/out completely independently on the life-cycle of the service.\r\n\r\n</p> \r\n<p><img src="/storage/multitenant-security-example-1.png" alt="Real-World Example 1" /></p> \r\n<p>When the Client sends data to the Service A (1) he uses a token to authorize himself. The Service A accepts the request, processes it and fires an event including the data (or some reference to them) and authorization token (2). The Adapter reacts on the event and uses the client''s token to forward the data to the Service B (3).</p> \r\n<p>Gray lines separate three different realms of trust: Client''s, Service A''s and B''s realms. Inside a realm everything trusted, outside the realm nothing is trusted.</p> \r\n<h3>Another example</h3> \r\n<p>If you are developing for the cloud, the following scenario should sound familier to you: You want to process data with a large file attachment. First, you make a request to the service with a security token, a data record is created and a signed upload URL is returned in the response. Second, the client puts the file data to the upload URL.</p> \r\n<p>The Adapter them must save the session information to be able to react to the event when the upload is finished.</p> \r\n<p>To save the token internally in the service is not enough in this situation because the upload can take longer than the token expiration time is. The Adapter have to get a temporary but long enough access to the Service B. This can be implemented using API keys.</p> \r\n<p><img src="/storage/multitenant-security-example-2.png" alt="Real-World Example 2" width="100%" /></p> \r\n<p>When the Client sends metadata (like a file-name) to the Service A (1) he uses a token to authorize himself. The Service A accepts the request, processes it, fires an event including the metadata and security token (2), and returns a signed upload URL in the response. The Adapter reacts on the event, uses the client''s token to demand an API key from the Service B (3A), then saves the API key internal with the metadata. In parallel the Client uses the upload URL to upload a file data to the storage of the Service A (3B). This fires an event containing the file metadata (4). On the event reacts the Adapter by looking up the API key connected to the metadata (5). The Adapter uses then the API key to upload the file data to the Service B (6).</p> \r\n<h4>What about asynchrony?</h4> \r\n<p>One problem could be the absense of order of the received events (that is natural for event-driven systems). It means, the event &quot;file uploaded&quot; can come before the API key retreiving is done or even (but very unlikely) before the &quot;upload requested&quot; event is caught by the Adapter. A solution here is not to consume the &quot;file uploaded&quot; event to be received again and again until the look-up is successful.</p> \r\n<p>Security first!</p>', 1, 'admin', 1, 'false', 'false', 1531583081, 'false'),
(117, 'Function Separation in a Microservice', 1538199748, '<p>Talking about serverless microservices, functions are the basic building blocks of the service functionality. How to design them from the code and deployment perspektive?</p>', 0, 0, '<h2>Microservices Anatomy</h2>\r\n<p>Let''s simply define a microservice as an <strong>autonom service built from one or more resources</strong>. The resource mean functionality (functions*), storage (database), communication (message topic), etc. All the service needs must be included in the stack or given as a parameter (environment variable), API is exposed and besides are all the resource private for the microservice. One microservice &hArr; one stack &hArr; one deployment pipeline.</p>\r\n\r\n<p>According the Single Responsibility Principle a component should do one and only one thing. Applying this rule to the functions level we get a function for an action. Let''s consider a simple CRUD microservice; all the CRUD operation are represented by simple functions:</p>\r\n\r\n<p><img src="https://raw.githubusercontent.com/ttulka/blog-code-samples/master/nodejs-crud-microservice/doc/FunctionSeparation-Product-Service-Overview.png" width="50%" /></p>\r\n\r\n<p>How does this look like from the dev-ops point of view? We can create a new project artifact for every function. Such code is <strong>easy to reason about, easy to test and deploy</strong>. The last one could be written with a question mark, of course it''s easy to deploy a function, but don''t forget there must be pipeline actions for build, deploy and test execution which is really only doing, but it''s a strenuous and boring job and brings additional complexity.</p>\r\n                                                                                                                                                                               \r\n<p><img src="https://raw.githubusercontent.com/ttulka/blog-assets/master/FunctionSeparation-pipeline.png" width="100%" /></p>\r\n\r\n<p>Similar for the codebase. Take a look at this simple AWS Lambda function in Node.js:</p>\r\n\r\n<pre>\r\n.gitignore\r\ngruntfile.js\r\njasmine.json\r\npackage.json\r\npackage-lock.json\r\nREADME.md\r\n</pre>\r\n\r\n<p>As you can see there several files only to set up the module. This must be multiplied for every function.</p>\r\n\r\n<p>So, a function for an action sounds well in theory but in practise it could be an overkill.</p>\r\n\r\n<h2>Modularization ''till the last step</h2>\r\n<p><strong>Decoupling</strong> is propably the most important concept in the design of software systems. So we never surrender this principle. Anyway we can distinguish between logical and physical coupling. <strong>Two modules can be perfectly decoupled even while physically existing in a same artifact</strong> - when they have no shared code and dependencies only to APIs (following principles of hexagonal architecture).</p>\r\n\r\n<p>Let''s consider the following implementation of the CRUD microservice:</p>\r\n\r\n<pre>\r\nsrc/\r\n   index.js\r\n   list-products.js\r\n   get-product.js\r\n   create-product.js\r\n   update-product.js\r\n   remove-product.js\r\n</pre>              \r\n\r\n<p><code>index.js</code></p>\r\n<pre class="brush: javascript">\r\nconst list = require(''./list-products'').handler\r\nconst get = require(''./get-product'').handler\r\nconst create = require(''./create-product'').handler\r\nconst update = require(''./update-product'').handler\r\nconst remove = require(''./remove-product'').handler\r\n\r\nexports.handler = async function(event) {\r\n    if (!event || !event.resource || !event.httpMethod) {\r\n        return buildResponse(400, {error: ''Wrong request format.''})\r\n    }\r\n\r\n    if (event.resource === ''/'') {\r\n\r\n        switch (event.httpMethod) {\r\n            case ''GET'':\r\n                return await list(event)\r\n            case ''POST'':\r\n                return await create(event)\r\n            default:\r\n                return buildResponse(405, {error: ''Wrong request method.''})\r\n        }\r\n    }\r\n    else if (event.resource === ''/{id}'') {\r\n\r\n        switch (event.httpMethod) {\r\n            case ''GET'':\r\n                return await get(event)\r\n            case ''PUT'':\r\n                return await update(event)\r\n            case ''DELETE'':\r\n                return await remove(event)\r\n            default:\r\n                return buildResponse(405, {error: ''Wrong request method.''})\r\n        }\r\n    } else {\r\n        return buildResponse(404, {error: ''Resource does not exist.''})\r\n    }\r\n}\r\n\r\nfunction buildResponse(statusCode, data = null) {\r\n    return {\r\n        isBase64Encoded: false,\r\n        statusCode: statusCode,\r\n        headers: {\r\n            ''Content-Type'': ''application/json''\r\n        },\r\n        body: JSON.stringify(data)\r\n    }\r\n}\r\n</pre>\r\n\r\n<p>As you can see, the main handler is only a router to other functions, which look like following:</p>\r\n\r\n<p><code>get-product.js</code></p>\r\n<pre class="brush: javascript">\r\nconst AWS = require(''aws-sdk'')\r\n\r\nconst PRODUCT_TABLE = process.env.PRODUCT_TABLE\r\n\r\nconst dynamoDb = new AWS.DynamoDB.DocumentClient({apiVersion: ''2012-08-10''})\r\n\r\nexports.handler = async function(event) {\r\n    if (!event || !event.httpMethod) {\r\n        return buildResponse(400, {error: ''Wrong request format.''})\r\n    }\r\n    if (event.httpMethod !== ''GET'') {\r\n        return buildResponse(405, {error: ''Wrong request method - only GET supported.''})\r\n    }\r\n    if (!event.pathParameters || !event.pathParameters.id) {\r\n        return buildResponse(400, {error: ''Wrong request - parameter product ID must be set.''})\r\n    }\r\n\r\n    try {\r\n        const response = await dispatch(event.pathParameters.id)\r\n        if (response) {\r\n            return buildResponse(200, response)\r\n        } else {\r\n            return buildResponse(404, {error: ''Product was not found.''})\r\n        }\r\n        \r\n    } catch (ex) {\r\n        console.error(''ERROR'', JSON.stringify(ex))\r\n    }\r\n}\r\n\r\nasync function dispatch(id) {\r\n    const product = getProduct(id)\r\n    return product\r\n}\r\n\r\nasync function getProduct(id) {\r\n    const params = {\r\n        TableName: PRODUCT_TABLE,\r\n        Key: { productId: id }\r\n    }\r\n    const res = await dynamoDb.get(params).promise()\r\n    \r\n    return (res.Item) \r\n        ? { id: res.Item.productId, \r\n            name: res.Item.name, \r\n            description: res.Item.description, \r\n            price: res.Item.price }\r\n        : null\r\n}\r\n\r\nfunction buildResponse(statusCode, data = null) {\r\n    return {\r\n        isBase64Encoded: false,\r\n        statusCode: statusCode,\r\n        headers: {\r\n            ''Content-Type'': ''application/json''\r\n        },\r\n        body: JSON.stringify(data)\r\n    }\r\n}\r\n</pre>\r\n\r\n<p>The Single Responsibility Principle is applied here. The function has its own handler which takes care of the incoming HTTP request. All the HTTP-related checks and transformations must be done here. The handler is the only one place for such a dirty code. After the request is checked, dispatching is executed. This is something like a main method, an entry point to the business logic. In this case just getting the product details.</p> \r\n\r\n<p>And other functions in the same spirit...</p>\r\n\r\n<p>The actions are decoupled from each other and are ready to be separated into individual functions in the next last step. But staying here we still have a very clear code easy to test and reason about and we don''t need to adapt the pipeline onto this level of granularity.</p>                                       \r\n  \r\n<h2>Test it!</h2>\r\n<p>It''s very easy to test a service built in this way. We write a Unit Test Suite for every action (exported function), an Integration Test Suite for the service API (index.js) and End-to-End Test Suite for the Gateway API facade.</p> \r\n  \r\n<h2>Source Code</h2>\r\n<p>The whole stack could be found on <a href="https://github.com/ttulka/blog-code-samples/tree/master/nodejs-crud-microservice">GitHub</a>.</p>\r\n\r\n<p>Happy coding!</p>  \r\n\r\n<hr/>\r\n<p>* <em>Functions are sometimes called "nanoservices" as they are smaller than microservices. Actually, I don''t even like the term "microservice" because it confuses people regarding its size ("How small should a microservice be?"), so I don''t like to develop this terminology on in the same manner.</em>', 1, 'admin', 1, 'false', 'true', 1539350149, 'false'),
(118, 'Rollback and Microservices', 1538899948, '<p>Thinking about a deployment strategy for a microservices-based system it''s natural to consider a <em>rollback</em>. Before looking for a technical solution, let''s discuss this idea conceptually. <strong>Is it even possible to roll microservices back?</strong></p>', 0, 0, '<h2>Microservices</h2>\r\n<p>One of a plenty definitions of a microservice is an <strong>independently deployable</strong> component. This says actually a pretty lot. To understand this definition we have go back to the very first motivation for the microservices design pattern: <em>We want to deliver our product as soon as possible</em>. A microservice could be in hands of one team and have a completely different and unsynchronous delivery process. A team developing a service A don''t want to be bothered by waiting for a next release of a service B if it doen''t need its new functionality. The service A could be deployed into the production once a day and the service B once a month.</p>\r\n<p>For all this to be possible we have to follow a few basic principles, especially the most important one in our context: <strong>No Breaking Changes</strong>. We may find the same principle under different names like <a href="https://www.allthingsdistributed.com/2016/03/10-lessons-from-10-years-of-aws.html" target="_blank">"APIs are forever"</a> etc., but the idea is the same.</p>\r\n\r\n<h2>No Breaking Changes</h2>\r\n<p>How does this principle makes the microservices deployment independent? Let''s consider two services, A and B. B is calling A via A''s API. In the time of development of a version v1 of the service B, there is a released API of the service A in the version v1. So the service B v1 makes its call against the service A v1:</p>\r\n\r\n<p align="center"><img src="https://raw.githubusercontent.com/ttulka/blog-assets/master/rollback-1.png" width="70%" alt="Service Bv1 calls Av1" /></p>\r\n\r\n<p>During the development of the service B v1 a new version of the service A - v2 - was released. An additional endpoint was added, but it''s okay for the service B because A''s API was not broken (in other words, A v2 is compatible with A v1). Actually, so far there are no breaking changes the service B doesn''t care which newly realeased version of the service A is talking to:</p>\r\n\r\n<p align="center"><img src="https://raw.githubusercontent.com/ttulka/blog-assets/master/rollback-2.png" width="70%" alt="Service Bv1 calls Av2" /></p>\r\n\r\n<h2>What about Rollbacks?</h2>\r\n<p>Now consider that the service B in some future version (let''s say v2) is using an endpoint of the service A added in its release v2:</p>\r\n\r\n<p align="center"><img src="https://raw.githubusercontent.com/ttulka/blog-assets/master/rollback-3.png" width="70%" alt="Service Bv2 calls Av2" /></p>\r\n\r\n<p>After some time the developers of the service A find an error in the v2. They decide to rollback to the previous version (v1). What happens to the system? The service B stops working because it keeps calling the endpoint of the service A v2 which doesn''t exist anymore. The <strong>rollback to a previous version is a potential breaking change</strong>:</p>\r\n\r\n<p align="center"><img src="https://raw.githubusercontent.com/ttulka/blog-assets/master/rollback-4.png" width="70%" alt="Service Bv2 calls Av1" /></p>\r\n\r\n<p>Because it can introduce a breaking change as the rest of the system depends on the current API a <strong>rollback should be avoided in microservices-based systems</strong>.</p>\r\n\r\n<h2>Conclusion</h2>\r\n<p>As long as we can''t rollback microservices, we have to find a confident way how to deploy them into the production. There are a lot good practises like separated deployment stages (development, testing, QA, ...), testing in a production-like environment, blue-green and canary deployment, and so on.</p>\r\n<p>It''s also very important to resist the temptation of hotfixing a bug directly in the production environment. We alywas have to adapt the continuous-delivery principles: Every change, bug-fixes included, must be properly built and tested thru the standard deployment process (delivery pipeline).</p> \r\n<p>Microservices are living organisms and should be treated like that.</p>\r\n\r\n<p>Happy deploying!</p>', 1, 'admin', 1, 'false', 'true', 1538926148, 'false'),
(119, 'Serverless Blue-Green Deployment', 1540023120, '<p>Blue-Green Deployment is a very good technique which has been successfully used for <strong>managing releases of cloud applications</strong>. Now it''s time to rethink it a bit for serverless systems.</p>', 0, 0, '<h2>Blue-Green Deployment</h2>\r\n<p>The concept is pretty easy: We have <strong>two identical production environments</strong> (blue and green), the green is production as default. When we release a new version, we deploy first into the blue environment. There we can perform some tests and then switch routing. The blue enviroment becomes production. If something goes wrong we should be able to <strong>switch back in less than a second</strong>.</p>\r\n   \r\n<h2>Problems with Serverless</h2>\r\n<p>So, why don''t we use the same strategy for serverless deployment? We have several problems to solve:</p>\r\n<ul>\r\n  <li><strong>No database integration</strong> - a service should contain its own data storages as a part of the stack.</li>\r\n  <li><strong>Independent deployment lifecycles</strong> - there is no synchronization between deployments.</li>\r\n  <li><strong>Location transparency</strong> - the topology of serverless systems is dynamic.</li> \r\n</ul>\r\n<p>Is there any solution for those problems? Maybe yes, but the cost of complexity would be too high. On the other hand, this doesn''t mean we have to abandon the blue-green deployment completely. We can still benefit from the idea, just on another level.</p>\r\n\r\n<h2>Blue-Green for Test-Isolation</h2>\r\n<p>Let''s image the following scenario: We have a test stage where all the integration tests are executed in. This stage is shared by all the service deployment pipelines.</p>\r\n<p>What happends when a test of the service A runs at the same time as another test of the service B which uses the service A as an external resource? When the new version of the service A doesn''t work it has a negative impact on the test results. And that''s the point where the blue-green deployment comes to rescue!</p>\r\n\r\n<p><img src="https://raw.githubusercontent.com/ttulka/blog-assets/master/Serverless-BlueGreen-Deployment.png" width="100%" alt="Serverless Blue-Green Deployment" /></p>\r\n\r\n<p>As you can see in the picture above, when a new version of the service A (Av2) is about to be tested it is deployed parallel to the previous version stack (Av1). The "blue" version is integrated in the system as well as the "green" version. If another test comes along it sees only the already tested stack Av1.</p>\r\n\r\n<h2>Source Code</h2>\r\n<p>You can find a simple implementation of the serverless blue-green development for test-isolation in my <a href="https://github.com/ttulka/blog-code-samples/tree/master/serverless-blue-green-deployment">Github account</a>. The example uses AWS CodePipeline</p>\r\n\r\n<p>Be blue-green, be happy!</p>', 1, 'admin', 1, 'false', 'true', 1539593333, 'false');
INSERT INTO `serendipity_entries` (`id`, `title`, `timestamp`, `body`, `comments`, `trackbacks`, `extended`, `exflag`, `author`, `authorid`, `isdraft`, `allow_comments`, `last_modified`, `moderate_comments`) VALUES
(120, 'Use-Case-Driven Testing', 1541155342, '<p>Why shouldn''t we test the implemetation? How to decouple our tests from the code? What is the reason to add a new test? Why is mocking a code smell? In this article I will try to find answers to those questions.</p>', 0, 0, '<p>In <a href="/testing-serverless-systems-116">my previous article</a> I opened the topic and defined some important terms and principles I find good to follow. Let me summarize some of them and continue in the theory how we should design our tests.</p>\r\n\r\n<h2>Contracts Testing vs. Implementation Testing</h2>\r\n<p>We can see a test as a friend of our application but never as its part (tests codebase is never a part of the production application). As a good friend a test must talk to the application via a contract. We can call that contract an API. Every well-defined component offers an API.</p>\r\n<p>If we couple our test with the implementation, we have to adapt the test everytime we refactor the application code, which is not only annoying and impractical but unnecessary and even rude (we don''t snoop around in friend''s wardrobe). After some time people get sick of double work and start to write fewer tests and/or ignore broken tests.</p>\r\n<p>Tests should not care <em>how</em> is a feature implemented, they should care only if the behavior is correct. When we implement a sorting function we should test if the sorting results are correct regardless which sorting algoritm is used.</p>\r\n<p>For example when we test if a record was saved we can use another service to retrieve the record, again via its API. When there is no API to retrieve a record there is no possibility to validate if the record was really save - but such a "black hole" system makes no sense.</p>\r\n\r\n<h2>Code-Drive Testing vs. Use-Case-Driven Testing</h2>\r\n<p>It''s a very popular practice to have a test per class, in Java like following:</p>\r\n<pre>\r\n/src/main/java/Foo.java\r\n              /Bar.java\r\n/src/test/java/FooTest.java\r\n              /BarTest.java              \r\n</pre>\r\n<p>This is a typical example of code-driven testing design. Here is a new class a reason to add a new test. But a class is just an implementation detail. Maybe after some time you find out the class is too big and should be refactored into two classes. Then you have to refactor your test as well although there is no functional change and the test validates always the same behavior. But if you didn''t do it your test wouldn''t propably compile. An unhappy situation. <strong>Code-driven testing design makes maintenance hard, expensive and boring.</strong></p>\r\n<p>It is much better to <strong>drive your tests by use-cases</strong>. With this strategy not a class or a method is a reason to add a new test but a new requirement is. The structure looks like following:</p>\r\n<pre>\r\n/src/main/java/Foo.java\r\n              /Bar.java\r\n/src/test/java/UseCase1Test.java\r\n              /UseCase2Test.java              \r\n</pre>\r\n<p>When you decided to split a class into two or to remove one, the tests remain without any change:</p>\r\n<pre>\r\n/src/main/java/Foo1.java\r\n              /Foo2.java\r\n/src/test/java/UseCase1Test.java\r\n              /UseCase2Test.java              \r\n</pre>\r\n<p>In fact, there are only two reasons for a test change: 1. the requirement has changed, 2. there was a bug in the test self.</p>\r\n<p>The design of the test has the following pattern:</p>\r\n<pre class="brush: java">\r\nclass UseCaseTest {\r\n    @Test\r\n    public void requirementOneTest() { \r\n        assert(/* acceptance criterium 1 */);\r\n        assert(/* acceptance criterium 2 */);\r\n        ...\r\n    }\r\n    @Test\r\n    public void requirementTwoTest() { \r\n        assert(/* acceptance criterium 1 */);\r\n        assert(/* acceptance criterium 2 */);\r\n        ...\r\n    }\r\n    ...\r\n}\r\n</pre>\r\n<p>The API is defined by an inteface (each public method of a class should implement an interface) and the implementation should be initialized via a factory, for example:</p>\r\n<pre class="brush: java">\r\n/** src/main/java/MyUseCase.java */\r\npublic interface MyUseCase {\r\n    int func1(String param);\r\n    String func2(int param);\r\n}\r\n\r\n/** src/main/java/Foo.java */\r\nclass Foo implement MyUseCase {\r\n    private Bar bar = new Bar();\r\n    \r\n    public int func1(String param) {\r\n        ...\r\n    }\r\n    public String func2(int param) {\r\n        ...\r\n        return bar.func();\r\n    } \r\n}\r\n\r\n/** src/main/java/Bar.java */\r\nclass Bar {\r\n    String func(int param) {\r\n        ...\r\n    }\r\n}\r\n\r\n/** src/test/java/MyUseCaseTest.java */\r\nclass MyUseCaseTest {\r\n    private MyUseCase myUseCase;\r\n    \r\n    @Before\r\n    public void initialize() {\r\n        myUseCase = new MyDefaultUseCaseFactory().createMyUseCase();\r\n    }    \r\n    @Test\r\n    public void func1Test() { \r\n        assertEquals(/* expected */, myUseCase.func1(...));\r\n        assertEquals(/* expected */, myUseCase.func1(...));\r\n        ...\r\n    }\r\n    @Test\r\n    public void func2Test() { \r\n        assertEquals(/* expected */, myUseCase.func2(...));\r\n        assertEquals(/* expected */, myUseCase.func2(...));\r\n        ...\r\n    }\r\n    ...\r\n}\r\n</pre>\r\n \r\n<h2>Code Coverage vs. Use-Case Coverage</h2>\r\n<p>Another popular practice is code coverage. In some companies there is a code coverage check as a part of the build pipeline and a commit is rejected if its code coverage is less than a particular percentage. <strong>Code coverage is a wrong metric</strong> - you can have 100% code coverage without actually to test anything.</p>\r\n<p>Much more important is <strong>use-case coverage</strong>, telling us how much of our requirements are covered with test. <strong>We should always try to achive 100% use-case coverage</strong>, because satisfaction of use-cases determine the product quality.</p>  \r\n\r\n<h2>Test Categories</h2>\r\n<p>We distinguish several test categories based on the level of granularity the test operates on.</p>\r\n\r\n<p><img src="https://raw.githubusercontent.com/ttulka/blog-assets/master/TestingGranularity.png" width="80%" /></p>\r\n\r\n<p>As showned in the picture, the <strong>unit testing</strong> operates on the level of functions, it can access the functionality of the smallest components via their APIs defined by public methods or exported function. <strong>Integration testing</strong> sees a service as a black box as well as <strong>system testing</strong>* has no idea about the services structure hidden behind the system''s facade (gateway).</p>\r\n\r\n<h3>Unit Testing</h3>\r\n<p>Unit tests operate on the level of functions and should test only business functionality. If there is no business logic and a requirement is implemented only with composition of another resources (like saving into a database or calling another function/service) there''s no reason for a unit test and the testing should be done as a part of integration testing (otherwise we write unit test as integrations test where all resources are mocked - such tests have no value).</p>\r\n<p>To make unit testing possible we should always follow the Single Responsibility Principle by writting our code. If more responsibilities are mixed into one component, for example when a function transforms the input and saves it into a database, there is no other way how to test the transformation function but to mock the database.</p>\r\n<p>Another thing which makes writting tests much easier is to avoid side-effects. A function with side-effects cannot be easily tested as a black box with inputs and outputs (both can be absent) and need a knowledge about its interns resp. implementation details. Use pure functions as much as possible.</p>\r\n\r\n<h3>Integration Testing</h3>\r\n<p>Integration Testing operates on the level of services, it means autonomous components, and tests their interactions.</p>\r\n<p>Integration tests must run in the system environment so all the needed resources are available (and we don''t have to mock anything).</p>\r\n<p>Integration tests as well as unit tests belong to a service and should access only the service''s API. If a test needs to access more services we call it a system test and it should run accross services (e.g. in a separate testing pipeline).</p>\r\n\r\n<h3>System Testing</h3>\r\n<p>System testing sees the entire system as a black box with a facase (gateway) API. Whole scenarios accross services are under the test.</p>\r\n\r\n<h2>Mocking is a Code Smell</h2>\r\n<p>If we follow the principles above we don''t need to mock anything in our tests. If we can''t test without mocking there must be something "smelly" in our design.</p>\r\n<p>Of course, there could be exceptions like when a resource is too expensive or slow, but we should avoid mocking as much as possible, because it always removes a value from the tests.</p>\r\n<p>We should avoid using mocks in our tests, but it''s okay to use fakes (simple implementations with business behavior). Read more about <a href="https://blog.cleancoder.com/uncle-bob/2014/05/14/TheLittleMocker.html" target="_blank">test doubles</a> and <a href="https://martinfowler.com/articles/mocksArentStubs.html" target="_blank">mocks vs. stubs</a> to understand the difference.</p>\r\n\r\n<h2>Example: Money</h2>\r\n<p>Do you remember the Money example from Kent Beck''s <a href="https://www.oreilly.com/library/view/test-driven-development/0321146530/" target="_blank">Test-Driven Development By Example</a>? Let''s use it as a base for our simple Money microservices system implemented with <a href="https://aws.amazon.com" target="_blank">AWS</a>.</p>\r\n<p>The Money service offers an API for multiplication of money amounts and reduction into different currencies. The Exchange service provides information about the actual rate; we can implement it for example as pulling the data from the New York Stock Exchange via its API.</p>\r\n\r\n<p><img src="https://raw.githubusercontent.com/ttulka/blog-assets/master/MoneyExampleMicroservices.png" width="80%" /></p>\r\n\r\n<p>The source code could be found on <a href="https://github.com/ttulka/blog-code-samples/tree/master/money" target="_blank">GitHub</a>. The implementation is far from perfect, but the idea is clear. Handlers (<code>index.js</code>) are separeted from the business (<code>money.js</code> and <code>exchange.js</code>), unit tests focus on the business, integration tests on handlers (which make APIs of the services) and system tests on the facade.</p>\r\n\r\n<p>Each tests have a different place in the build pipeline. Unit tests are executed for every function, integration tests for every service (a bunch of functions) and system tests for the entire system (a bunch of services).</p>\r\n<p>In our example there is only one function per service, but in a real-world scenario there would be much more. We can even think of a function per use-case. In such a case we would have two function in the Money service: <code>times</code> function and <code>reduce</code> function.</p>\r\n\r\n<p>Happy testing!</p>\r\n\r\n<hr />\r\n<p><strong>*</strong>) <em>System testing belongs together with GUI and manual testing into the group End-to-end testing which all operate on the same level of granularity. By system testing is in this article meant automatic testing of back-end functionality e.g. via system''s REST API.</em></p> ', 1, 'admin', 1, 'false', 'true', 1540552188, 'false'),
(121, 'JavaScript async/await in a Loop', 1541241720, '<p>Async/await syntax is a great technique how to deal with promises in modern JavaScript. Unfortunately it''s not always easy to understand how it works which can lead to strange bugs. Let''s investigate one of them.</p>', 0, 0, '<p>There is a service in our system cleaning up unused resources. Those resources are grouped upon an ID. So the request looks like "remove all the resources for the ID 123".</p>\r\n<p>In the service code I have found the following line:</p>\r\n\r\n<pre class="brush: javascript">\r\nentryKeys.forEach(async key => await removeResource(key))\r\n</pre>\r\n\r\n<p>Why this doesn''t work? Let''s analyse the code a bit. The <code>forEach</code> is just a stream variant of the <code>for</code> loop and it''s definitely synchronous. So, there shouldn''t be the problem even when it''s a bit ineffective. Inside the <code>forEach</code> there is a call of the <code>removeResource</code> function with <code>await</code>. The <code>await</code> tells us that the function returns a promise. The <code>await</code> can be used only within an <code>async</code> function which is fulfilled because the inline (lambda) function is really marked with the <code>async</code> keyword (we can rewrite the same function as <code>async function(key){ await removeReource(key) }</code>). The point is a function declared with <code>async</code> returns always a promise. It means, the <code>forEach</code> fires several <b>asynchronous</b> calls but <b>doesn''t wait for them</b> (<code>await removeResource(key)</code> is another asynchronous call inside that asynchronous call).</p>\r\n\r\n<p>Now, when we understand why the code doesn''t work, we can fix it:</p>\r\n\r\n<pre class="brush: javascript">\r\nfor (const key of entryKeys) { await removeResource(key) } \r\n</pre>\r\n\r\n<p>This works fine, the only problem is, it''s synchronous and slow. The loop is waiting for an execution to finish before starting a new one even when it is possible to run them all in parallel.</p>\r\n<p>Can we fix it? Sure!</p>\r\n\r\n<pre class="brush: javascript">\r\nawait Promise.all(entryKeys.map(key => removeResource(key))) \r\n</pre>\r\n\r\n<p>We have changed <code>forEach</code> to <code>map</code>, so we map an array of IDs into an array of promises. Then we pack the promises into a one big promise via <code>Promise.all()</code>. Now we wait for the big promise (and that''s exactly what we missed before) to be completed. All the call are executed in parallel. Well done.</p>\r\n\r\n<p>You can play with the different variants via the following snippet:</p> \r\n\r\n<pre class="brush: javascript">\r\n(async function(){\r\n    console.log("START")\r\n    \r\n    // doesn''t work\r\n    //["A","B","C"].forEach(async key => await doSomethingAsync(key))\r\n    \r\n    await Promise.all(["D","E","F"].map(key => doSomethingAsync(key)))\r\n    \r\n    // synchronous\r\n    //for (const key of ["G","H","I"]) { await doSomethingAsync(key) }   \r\n    \r\n    console.log("END")  \r\n})()\r\n\r\nfunction doSomethingAsync(key) {\r\n    return new Promise(function (resolve, reject) {\r\n        setTimeout(() => {\r\n            console.log("RESOLVED " + key)\r\n            resolve(key)\r\n        }, 1000)\r\n    })\r\n}\r\n</pre>\r\n\r\n<h2>What about Reduce?</h2>\r\n\r\n<p>How could we reduce the value from the promises? Well, of course the reduce needs the already resolved values:</p>\r\n\r\n<pre class="brush: javascript">\r\n// "JKL"\r\nvar result = await ["J","K","L"]\r\n      .map(key => doSomethingAsync(key))\r\n      .reduce(async (sum,v) => await sum + await v)\r\n</pre>\r\n\r\n<p>Because the whole reduce function is <code>async</code> we have to use <code>await</code> as well to retrieve the value of <code>sum</code>.</p>\r\n\r\n<p>Happy promising!</p>', 0, 'admin', 1, 'false', 'true', 1541155721, 'false'),
(122, 'Package by Component with Clean Modules in Java', 1546336680, '<p>Software architecting is about tradeoffs. Even when the theory is good the implementation details can break it. In this article I try to find the best from two architectural approaches: <strong>Package by component</strong> and <strong>Clean architecture</strong> (a variety of Ports and adapters).</p>', 0, 0, '<p>Package by component, as proposed by Simon Brown in his <a href="https://www.oreilly.com/library/view/clean-architecture-a/9780134494272/" target="_blank">Missing chapter</a>, is an architectural approach <strong>organizing code based by bundling together everything related to a component</strong>. If done properly (only the component entry point is marked as public) enforces architectural rules, like not bypassing the busines logic in the infrastructure layer - problematic in the Ports and adaptes -, using only the standard Java compiler mechanism.</p> \r\n<h2>Enforced Separation of Concepts</h2> \r\n<p>In my experience it is very important to have such a strict mechanism, because otherwise the temptation to skip the rules is too strong, especially when working under time pressure (don''t forget - the stress-driven architecture is the <em>big ball of mud</em>).</p> \r\n<p><img src="https://raw.githubusercontent.com/ttulka/blog-assets/master/Package-by-component.png" alt="Package by component" width="30%" /> </p> \r\n<p>Package by component hides code under a package and so makes them inaccessible from another packages (components). There is no way to access the <code>OrderRepository</code> from the <code>OrderController</code> anymore and that''s great. </p> \r\n<p>The problem here is that there is no mechanism to&nbsp;prevent the access the <code>OrderRepositoryJdbc</code> (infrastructure) from the <code>OrderServiceImpl</code> (domain). The ease of using the implementation directly instead of the interface is still too high. It seems even <strong>in the Package by component approach is the separation of concepts enforced not enough</strong>.</p> \r\n<h2>Modules to Rescue</h2> \r\n<p>Fortunately we have more than only Java packages - we can configure separate modules or projects in a build tool (eg. Maven, Gradle, ...). We can use these artifacts as dependencies and hide so the &quot;outside&quot; from the &quot;inside&quot;.</p> \r\n<p><img src="https://raw.githubusercontent.com/ttulka/blog-assets/master/Package-by-component_modules.png" alt="Package by component with modules" width="50%" /> </p> \r\n<p>As you can see in the picture, there are <strong>no changes in the packages</strong> structure, we''re still following the Package by component architecture, but this time the <strong>domain and infrastructure parts are both separated into modules</strong>. Because the domain artifact has no dependencies to the infrastructure artifact, accessing the <code>OrderRepositoryJdbc</code> from the <code>OderServiceImpl</code> would now cause a compilation error.</p> \r\n<p>We don''t have to stick with only two modules and can create a finer structure, for example modules like <code>web</code>, <code>database</code>, etc.</p> \r\n<h2>Working Example</h2> \r\n<p>We extend the &quot;MyShop&quot; application shown in the pictures above. We create a simple web application with products to add into a shopping cart and then to order.</p> \r\n<p>As a glue we use the Spring framework (context) and for the web part the Spring Web/MVC all together with the Spring Boot.</p> \r\n<p><img src="https://raw.githubusercontent.com/ttulka/blog-assets/master/Package-by-component-with-clean-modules.png" alt="Package by component with clean modules" width="70%" /></p> \r\n<p>Modules creates an <strong>onion structure</strong>:</p> \r\n<ul> \r\n<li>On the top there is the Spring Boot application layer - it represents a <strong>deployment scenario</strong> (alternatively there could be a WAR module for a web-container like WildFly etc.).</li> \r\n<li>Spring configurations, web UI and a database implementation create the second infrastructure layer - <strong>technical details</strong>.</li> \r\n<li>The domain layer sits always on the bottom - it provides the <strong>business API</strong> as well as implementation of the <strong>business logic</strong>.</li> \r\n</ul> \r\n<p><img src="https://raw.githubusercontent.com/ttulka/blog-assets/master/Clean-modules_MyShop.png" alt="Clean modules - MyShop" width="70%" /></p> \r\n<p>Another benefit of using modules is that we can <strong>get rid of unnecessary dependencies in a declarative way</strong>. For example, if we want to add another implementation of the <code>OrderRepository</code>, like <code>OrderRepositoryInmem</code>, we can do it in two ways: 1. adding a new class into the <code>db</code> module, 2. creating two separate modules <code>db-jdbc</code> and <code>db-inmem</code>. Then we can exclude the dependencies in the <code>spring</code> module, or just declare one of them respectively. With the second approach the <strong>implementation can be easily changed just by adding/removing a dependency</strong>, on the other hand the maintenance of an additional module is needed and in some cases this could lead to an explosion of modules.</p> \r\n<p>The source code could be found on <a href="https://github.com/ttulka/blog-code-samples/tree/master/myshop" target="_blank" title="MyShop on Github">GitHub</a>.</p> \r\n<p><i>Note on the implementation:</i> The purpose of the code is to show the Package by component with modules approach, nevertheless it is not a perfect Domain-driven design example. Following the DDD principles seriously, we should see a package <code>cz.net21.ttulka.myshop.cart</code>, classes like <code>ShoppingCart</code>, <code>OrderItem</code>, proper factories for domain objects and, of course, tests!</p>\r\n<p>Happy architecting!</p> \r\n<p> </p>', 1, 'admin', 1, 'false', 'true', 1546337539, 'false');

/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;
/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;
/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;
